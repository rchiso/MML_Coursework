{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Type\n",
    "n=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data and convert to tensor\n",
    "binary = True\n",
    "\n",
    "X = np.load(\"Datasets/kryptonite-%s-X.npy\"%(n))\n",
    "y = np.load(\"Datasets/kryptonite-%s-y.npy\"%(n))\n",
    "if binary:\n",
    "    X = np.where(X>0.5, 1, 0)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 20% test\n",
    "\n",
    "X_temp = torch.tensor(X_temp.astype(np.float32)).to(device)\n",
    "y_temp = torch.tensor(y_temp.astype(np.float32)).unsqueeze(1).to(device)\n",
    "\n",
    "X_test = torch.tensor(X_test.astype(np.float32)).to(device)\n",
    "y_test = torch.tensor(y_test.astype(np.float32)).unsqueeze(1).to(device)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layer_size, num_hidden_layers):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_layer_size),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        for _ in range(num_hidden_layers-1):\n",
    "            layers.append(nn.Linear(hidden_layer_size, hidden_layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        layers.append(nn.Linear(hidden_layer_size, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenise(lists):\n",
    "    max_length = max(len(sublist) for sublist in lists)  # Find the length of the longest list\n",
    "    for sublist in lists:\n",
    "        sublist.extend([sublist[-1]] * (max_length - len(sublist)))  # Extend with last element\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path(\"Plots/HyperparameterTuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_acc_list, val_acc_list, id=None):\n",
    "    # Mean and std across each each kth fold of validation\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    for i in range(5):\n",
    "        train_acc.append(train_acc_list[i])\n",
    "        val_acc.append(val_acc_list[i])\n",
    "\n",
    "    train_acc = np.array(homogenise(train_acc))\n",
    "    val_acc = np.array(homogenise(val_acc))\n",
    "\n",
    "    train_mean = np.mean(train_acc, axis=0)\n",
    "    val_mean = np.mean(val_acc, axis=0)\n",
    "\n",
    "    train_std = np.std(train_acc, axis=0)\n",
    "    val_std = np.std(val_acc, axis=0)\n",
    "\n",
    "    plt.plot(train_mean)\n",
    "    plt.fill_between(range(len(train_mean)),train_mean-train_std,train_mean+train_std,alpha=.6)\n",
    "    plt.title(\"Training Accuracy per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/train_acc_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/train_acc.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(val_mean)\n",
    "    plt.fill_between(range(len(val_mean)),val_mean-val_std,val_mean+val_std,alpha=.6)\n",
    "    plt.title(\"Validation Accuracy per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/val_acc_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/val_acc.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Training accuracy (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_acc[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Validation accuracy (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_acc[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    print(\"Training accuracy (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_acc[i].max())\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    average_best_validation_accuracy = 0\n",
    "    print(\"Validation accuracy (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_acc[i].max())\n",
    "        average_best_validation_accuracy += val_acc[i].max()\n",
    "    print(\"---------------------------------\")\n",
    "    average_best_validation_accuracy /= 5\n",
    "    \n",
    "    print(f\"Average best validation accuracy: {average_best_validation_accuracy}\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    return average_best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss_list, val_loss_list, id=None):\n",
    "    # Mean and std across each each kth fold of validation\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for i in range(5):\n",
    "        train_loss.append(train_loss_list[i])\n",
    "        val_loss.append(val_loss_list[i])\n",
    "\n",
    "    train_loss = np.array(homogenise(train_loss))\n",
    "    val_loss = np.array(homogenise(val_loss))\n",
    "\n",
    "    train_mean = np.mean(train_loss, axis=0)\n",
    "    val_mean = np.mean(val_loss, axis=0)\n",
    "\n",
    "    train_std = np.std(train_loss, axis=0)\n",
    "    val_std = np.std(val_loss, axis=0)\n",
    "\n",
    "    plt.plot(train_mean)\n",
    "    plt.fill_between(range(len(train_mean)),train_mean-train_std,train_mean+train_std,alpha=.6)\n",
    "    plt.title(\"Training Loss per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/train_loss_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/train_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(val_mean)\n",
    "    plt.fill_between(range(len(val_mean)),val_mean-val_std,val_mean+val_std,alpha=.6)\n",
    "    plt.title(\"Validation Loss per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/val_loss_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/val_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Training loss (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_loss[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Validation loss (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_loss[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    print(\"Training loss best\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_loss[i].min())\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    avg_best_validation_loss = 0\n",
    "    print(\"Validation loss (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_loss[i].min())\n",
    "        avg_best_validation_loss += val_loss[i].min()\n",
    "    print(\"---------------------------------\")\n",
    "    avg_best_validation_loss /= 5\n",
    "    \n",
    "    print(f\"Average best validation loss: {avg_best_validation_loss}\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    return avg_best_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(hyperparameters):\n",
    "    \n",
    "    # Store all the models and return the model with best val loss\n",
    "    # models = []\n",
    "    \n",
    "    # Store loss and accuracy for each K-fold \n",
    "    train_acc_list={0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    val_acc_list = {0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "\n",
    "    train_loss_list={0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    val_loss_list = {0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    \n",
    "    # Enable or disable early stopping\n",
    "    early_stopping_enabled = False\n",
    "\n",
    "    # K-fold training loop\n",
    "    count=0\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train_index, val_index in kf.split(X_temp):\n",
    "        X_train_tensor, X_val_tensor = X_temp[train_index], X_temp[val_index]\n",
    "        y_train_tensor, y_val_tensor = y_temp[train_index], y_temp[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=hyperparameters[\"batch_size\"])\n",
    "\n",
    "        model = NeuralNet(n, hyperparameters[\"hidden_size\"], hyperparameters[\"num_hidden\"]).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparameters[\"lr\"], weight_decay=hyperparameters[\"alpha\"])\n",
    "\n",
    "        num_epochs = hyperparameters[\"num_epochs\"]\n",
    "        \n",
    "        # Variables required for early stopping\n",
    "        early_stopping_counter = 0\n",
    "        patience = 5\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for _ in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0 # accuracy cal\n",
    "            for input, label in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                correct += (outputs.round()==label).float().sum().item()\n",
    "                running_loss+=loss.item()\n",
    "\n",
    "            avg_loss = running_loss/len(train_loader)\n",
    "            accuracy = 100*correct/len(X_train_tensor)\n",
    "            train_loss_list[count].append(avg_loss)\n",
    "            train_acc_list[count].append(accuracy)\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss = 0.0\n",
    "            correct = 0\n",
    "            for input, label in val_loader:\n",
    "                target = model(input)\n",
    "                loss = criterion(target, label)\n",
    "                valid_loss += loss.item()\n",
    "                correct += (target.round()==label).float().sum().item()\n",
    "            avg_loss = valid_loss/len(val_loader)\n",
    "            accuracy = 100*correct/len(X_val_tensor)\n",
    "            val_loss_list[count].append(avg_loss)\n",
    "            val_acc_list[count].append(accuracy)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if early_stopping_enabled:\n",
    "                if avg_loss < best_val_loss:\n",
    "                    best_val_loss = avg_loss\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                if early_stopping_counter > patience:\n",
    "                    break\n",
    "                \n",
    "        count+=1\n",
    "\n",
    "    file_id_for_plot = f\"n_{n}\"\n",
    "    for key, val in hyperparameters.items():\n",
    "        file_id_for_plot += f\"_{key}_{val}\"\n",
    "    file_id_for_plot = file_id_for_plot.replace(\".\", \"-\")\n",
    "    \n",
    "    print(\"---------------------------------\")\n",
    "    print(file_id_for_plot)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    average_best_validation_accuracy = plot_accuracy(train_acc_list, val_acc_list, id=file_id_for_plot)\n",
    "    avg_best_validation_loss = plot_losses(train_loss_list, val_loss_list, id=file_id_for_plot)\n",
    "    \n",
    "    return average_best_validation_accuracy, avg_best_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter combinations\n",
    "lr_values = [0.001, 0.01, 0.05, 0.1]\n",
    "alpha_values = [0.0001, 0.001, 0.01, 0.1]\n",
    "hidden_layer_sizes = [2*n, 4*n, 8*n, 16*n]\n",
    "num_hidden_layers = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to store results\n",
    "csv_file_path = f\"hyperparameter_tuning_results-{n}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already processed hyperparameter combination: {'num_hidden': 1, 'hidden_size': 18, 'lr': 0.001, 'alpha': 0.0001, 'batch_size': 128, 'num_epochs': 100}\n",
      "Skipping already processed hyperparameter combination: {'num_hidden': 2, 'hidden_size': 18, 'lr': 0.001, 'alpha': 0.0001, 'batch_size': 128, 'num_epochs': 100}\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.87673611111111\n",
      "K-fold 1 : 95.88541666666667\n",
      "K-fold 2 : 93.66319444444444\n",
      "K-fold 3 : 95.87673611111111\n",
      "K-fold 4 : 88.91493055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.69444444444444\n",
      "K-fold 2 : 93.88888888888889\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 88.99305555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.87673611111111\n",
      "K-fold 1 : 95.88541666666667\n",
      "K-fold 2 : 93.66319444444444\n",
      "K-fold 3 : 95.87673611111111\n",
      "K-fold 4 : 88.92361111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.69444444444444\n",
      "K-fold 2 : 93.92361111111111\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 88.99305555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.01388888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18355834575162994\n",
      "K-fold 1 : 0.2059691069026788\n",
      "K-fold 2 : 0.2496403427587615\n",
      "K-fold 3 : 0.18799831420183183\n",
      "K-fold 4 : 0.31950930655002596\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19679818853088046\n",
      "K-fold 1 : 0.21519396097763724\n",
      "K-fold 2 : 0.2509419464546701\n",
      "K-fold 3 : 0.192742467250513\n",
      "K-fold 4 : 0.3262274654015251\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18355834575162994\n",
      "K-fold 1 : 0.2059691069026788\n",
      "K-fold 2 : 0.2496403427587615\n",
      "K-fold 3 : 0.18799831420183183\n",
      "K-fold 4 : 0.31950930655002596\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.19316801785126977\n",
      "K-fold 1 : 0.21519396097763724\n",
      "K-fold 2 : 0.2509419464546701\n",
      "K-fold 3 : 0.192742467250513\n",
      "K-fold 4 : 0.3262274654015251\n",
      "---------------------------------\n",
      "Average best validation loss: 0.23565477158712303\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.66840277777777\n",
      "K-fold 1 : 95.859375\n",
      "K-fold 2 : 95.859375\n",
      "K-fold 3 : 95.96354166666667\n",
      "K-fold 4 : 95.88541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.5625\n",
      "K-fold 1 : 95.79861111111111\n",
      "K-fold 2 : 95.79861111111111\n",
      "K-fold 3 : 95.38194444444444\n",
      "K-fold 4 : 95.69444444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.66840277777777\n",
      "K-fold 1 : 95.859375\n",
      "K-fold 2 : 95.859375\n",
      "K-fold 3 : 95.96354166666667\n",
      "K-fold 4 : 95.88541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.5625\n",
      "K-fold 1 : 95.79861111111111\n",
      "K-fold 2 : 95.79861111111111\n",
      "K-fold 3 : 95.38194444444444\n",
      "K-fold 4 : 95.69444444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16775687179631657\n",
      "K-fold 1 : 0.1643095873710182\n",
      "K-fold 2 : 0.1606916798899571\n",
      "K-fold 3 : 0.15943371194104353\n",
      "K-fold 4 : 0.1621333105696572\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16132804945759152\n",
      "K-fold 1 : 0.18269123007421909\n",
      "K-fold 2 : 0.17821580365948056\n",
      "K-fold 3 : 0.19601511145415512\n",
      "K-fold 4 : 0.17974137514829636\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16748495466179317\n",
      "K-fold 1 : 0.16333934362563823\n",
      "K-fold 2 : 0.1606916798899571\n",
      "K-fold 3 : 0.159257585182786\n",
      "K-fold 4 : 0.16129369445972971\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15845060445692227\n",
      "K-fold 1 : 0.17804759222528208\n",
      "K-fold 2 : 0.17594514204108197\n",
      "K-fold 3 : 0.18839291677526807\n",
      "K-fold 4 : 0.17750345688799155\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17566794247730916\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.89409722222223\n",
      "K-fold 1 : 95.82465277777777\n",
      "K-fold 2 : 96.03298611111111\n",
      "K-fold 3 : 95.71180555555556\n",
      "K-fold 4 : 95.77256944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.65972222222223\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 95.10416666666667\n",
      "K-fold 3 : 96.38888888888889\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.89409722222223\n",
      "K-fold 1 : 95.83333333333333\n",
      "K-fold 2 : 96.03298611111111\n",
      "K-fold 3 : 95.71180555555556\n",
      "K-fold 4 : 95.77256944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.65972222222223\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 95.10416666666667\n",
      "K-fold 3 : 96.38888888888889\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1802604851623376\n",
      "K-fold 1 : 0.1803114155928294\n",
      "K-fold 2 : 0.17118233897619778\n",
      "K-fold 3 : 0.1860776748922136\n",
      "K-fold 4 : 0.17611922257476384\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18702000379562378\n",
      "K-fold 1 : 0.18689928657334784\n",
      "K-fold 2 : 0.20237943918808646\n",
      "K-fold 3 : 0.17589590309754663\n",
      "K-fold 4 : 0.17002551905486896\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17996081933379174\n",
      "K-fold 1 : 0.1803114155928294\n",
      "K-fold 2 : 0.17077204609910648\n",
      "K-fold 3 : 0.1860776748922136\n",
      "K-fold 4 : 0.17611922257476384\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18702000379562378\n",
      "K-fold 1 : 0.18689928657334784\n",
      "K-fold 2 : 0.2019159612448319\n",
      "K-fold 3 : 0.17589590309754663\n",
      "K-fold 4 : 0.17002551905486896\n",
      "---------------------------------\n",
      "Average best validation loss: 0.18435133475324383\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.02430555555556\n",
      "K-fold 1 : 95.90277777777777\n",
      "K-fold 2 : 95.76388888888889\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 95.65972222222223\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.13888888888889\n",
      "K-fold 1 : 95.625\n",
      "K-fold 2 : 96.18055555555556\n",
      "K-fold 3 : 95.69444444444444\n",
      "K-fold 4 : 96.59722222222223\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.03298611111111\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 95.76388888888889\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 95.66840277777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.13888888888889\n",
      "K-fold 1 : 95.625\n",
      "K-fold 2 : 96.18055555555556\n",
      "K-fold 3 : 95.69444444444444\n",
      "K-fold 4 : 96.59722222222223\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.15548161905672814\n",
      "K-fold 1 : 0.15853409758872455\n",
      "K-fold 2 : 0.16381664681765767\n",
      "K-fold 3 : 0.15925750070148045\n",
      "K-fold 4 : 0.16730698438154326\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.212816570116126\n",
      "K-fold 1 : 0.1852211767564649\n",
      "K-fold 2 : 0.16492743628180545\n",
      "K-fold 3 : 0.18391241910664932\n",
      "K-fold 4 : 0.14952532720306647\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15406974901755652\n",
      "K-fold 1 : 0.1571419094171789\n",
      "K-fold 2 : 0.1626434133284622\n",
      "K-fold 3 : 0.15798402047819562\n",
      "K-fold 4 : 0.16662823036313057\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.20313733524602393\n",
      "K-fold 1 : 0.1806940685795701\n",
      "K-fold 2 : 0.15883097052574158\n",
      "K-fold 3 : 0.17887356504797935\n",
      "K-fold 4 : 0.14584305947241577\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17347579977434613\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.9375\n",
      "K-fold 1 : 95.78125\n",
      "K-fold 2 : 95.98090277777777\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 95.77256944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.48611111111111\n",
      "K-fold 1 : 96.11111111111111\n",
      "K-fold 2 : 95.3125\n",
      "K-fold 3 : 96.18055555555556\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.9375\n",
      "K-fold 1 : 95.78125\n",
      "K-fold 2 : 95.98090277777777\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 95.77256944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.48611111111111\n",
      "K-fold 1 : 96.11111111111111\n",
      "K-fold 2 : 95.3125\n",
      "K-fold 3 : 96.18055555555556\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16378957521584298\n",
      "K-fold 1 : 0.16770484430922403\n",
      "K-fold 2 : 0.16085064742300245\n",
      "K-fold 3 : 0.16699421107769014\n",
      "K-fold 4 : 0.1690820480386416\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18381858876217966\n",
      "K-fold 1 : 0.17923003726679346\n",
      "K-fold 2 : 0.19101089886997058\n",
      "K-fold 3 : 0.16884418188229852\n",
      "K-fold 4 : 0.16256017594233804\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16378957521584298\n",
      "K-fold 1 : 0.16770484430922403\n",
      "K-fold 2 : 0.16085064742300245\n",
      "K-fold 3 : 0.16699421107769014\n",
      "K-fold 4 : 0.16879214255346192\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18346657927917398\n",
      "K-fold 1 : 0.1779576446051183\n",
      "K-fold 2 : 0.19072670716306436\n",
      "K-fold 3 : 0.16602520677058594\n",
      "K-fold 4 : 0.16253111543862717\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17614145065131398\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 95.859375\n",
      "K-fold 3 : 95.83333333333333\n",
      "K-fold 4 : 95.91145833333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.76388888888889\n",
      "K-fold 1 : 96.21527777777777\n",
      "K-fold 2 : 95.79861111111111\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.59027777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 95.859375\n",
      "K-fold 3 : 95.84201388888889\n",
      "K-fold 4 : 95.92881944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.76388888888889\n",
      "K-fold 1 : 96.21527777777777\n",
      "K-fold 2 : 95.79861111111111\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.59027777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1596639828963412\n",
      "K-fold 1 : 0.16321811808480158\n",
      "K-fold 2 : 0.16247849588592847\n",
      "K-fold 3 : 0.16183811840083864\n",
      "K-fold 4 : 0.1551839085916678\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18461123303226804\n",
      "K-fold 1 : 0.16162954238445862\n",
      "K-fold 2 : 0.18465486492799676\n",
      "K-fold 3 : 0.17956096387427786\n",
      "K-fold 4 : 0.1925580339587253\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15765101926194297\n",
      "K-fold 1 : 0.16228552651074196\n",
      "K-fold 2 : 0.15924896345370346\n",
      "K-fold 3 : 0.15921138044860628\n",
      "K-fold 4 : 0.1551839085916678\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17838547249203143\n",
      "K-fold 1 : 0.15763708042061847\n",
      "K-fold 2 : 0.1781888691627461\n",
      "K-fold 3 : 0.17234369982843814\n",
      "K-fold 4 : 0.18405515052702115\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17412205448617107\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 81.37152777777777\n",
      "K-fold 1 : 92.44791666666667\n",
      "K-fold 2 : 75.52951388888889\n",
      "K-fold 3 : 85.29513888888889\n",
      "K-fold 4 : 93.48958333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 81.18055555555556\n",
      "K-fold 1 : 93.50694444444444\n",
      "K-fold 2 : 75.24305555555556\n",
      "K-fold 3 : 87.1875\n",
      "K-fold 4 : 93.29861111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 81.75347222222223\n",
      "K-fold 1 : 92.44791666666667\n",
      "K-fold 2 : 76.12847222222223\n",
      "K-fold 3 : 85.42534722222223\n",
      "K-fold 4 : 93.63715277777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 82.22222222222223\n",
      "K-fold 1 : 93.50694444444444\n",
      "K-fold 2 : 76.00694444444444\n",
      "K-fold 3 : 87.1875\n",
      "K-fold 4 : 93.57638888888889\n",
      "---------------------------------\n",
      "Average best validation accuracy: 86.5\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.45268757939338683\n",
      "K-fold 1 : 0.31808318462636737\n",
      "K-fold 2 : 0.5364524400896497\n",
      "K-fold 3 : 0.40794897079467773\n",
      "K-fold 4 : 0.2596907718314065\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.4660948722258858\n",
      "K-fold 1 : 0.3041226293729699\n",
      "K-fold 2 : 0.5430105030536652\n",
      "K-fold 3 : 0.40319228172302246\n",
      "K-fold 4 : 0.26476983790812286\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.45268757939338683\n",
      "K-fold 1 : 0.31808318462636737\n",
      "K-fold 2 : 0.5364524400896497\n",
      "K-fold 3 : 0.40794897079467773\n",
      "K-fold 4 : 0.2596907718314065\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.46576199712960614\n",
      "K-fold 1 : 0.3041226293729699\n",
      "K-fold 2 : 0.5430105030536652\n",
      "K-fold 3 : 0.40319228172302246\n",
      "K-fold 4 : 0.26476983790812286\n",
      "---------------------------------\n",
      "Average best validation loss: 0.3961714498374773\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.77256944444444\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 95.92881944444444\n",
      "K-fold 3 : 94.96527777777777\n",
      "K-fold 4 : 95.80729166666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.14583333333333\n",
      "K-fold 1 : 96.18055555555556\n",
      "K-fold 2 : 95.52083333333333\n",
      "K-fold 3 : 94.65277777777777\n",
      "K-fold 4 : 96.00694444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.77256944444444\n",
      "K-fold 1 : 95.76388888888889\n",
      "K-fold 2 : 95.92881944444444\n",
      "K-fold 3 : 94.96527777777777\n",
      "K-fold 4 : 95.80729166666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.14583333333333\n",
      "K-fold 1 : 96.18055555555556\n",
      "K-fold 2 : 95.52083333333333\n",
      "K-fold 3 : 94.82638888888889\n",
      "K-fold 4 : 96.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.73611111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1836094973815812\n",
      "K-fold 1 : 0.19873460547791588\n",
      "K-fold 2 : 0.1780015115936597\n",
      "K-fold 3 : 0.19196684782703718\n",
      "K-fold 4 : 0.17743610954946942\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16936867781307385\n",
      "K-fold 1 : 0.18368824862915537\n",
      "K-fold 2 : 0.19374483273081158\n",
      "K-fold 3 : 0.21477240550777185\n",
      "K-fold 4 : 0.17170371341964472\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1810644977622562\n",
      "K-fold 1 : 0.19873460547791588\n",
      "K-fold 2 : 0.17706583051217928\n",
      "K-fold 3 : 0.19196684782703718\n",
      "K-fold 4 : 0.17680329084396362\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16846839111784231\n",
      "K-fold 1 : 0.1831571132592533\n",
      "K-fold 2 : 0.19247649610042572\n",
      "K-fold 3 : 0.21225856795259143\n",
      "K-fold 4 : 0.17155833801497583\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1855837812890177\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.84201388888889\n",
      "K-fold 1 : 94.21006944444444\n",
      "K-fold 2 : 95.85069444444444\n",
      "K-fold 3 : 95.81597222222223\n",
      "K-fold 4 : 94.41840277777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 94.30555555555556\n",
      "K-fold 2 : 95.76388888888889\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 93.29861111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.84201388888889\n",
      "K-fold 1 : 94.21006944444444\n",
      "K-fold 2 : 95.85069444444444\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 94.41840277777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 94.30555555555556\n",
      "K-fold 2 : 95.76388888888889\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 93.92361111111111\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.21474077386988533\n",
      "K-fold 1 : 0.248384676542547\n",
      "K-fold 2 : 0.23000160687499577\n",
      "K-fold 3 : 0.22442556106381947\n",
      "K-fold 4 : 0.2511808627181583\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.21539975832337918\n",
      "K-fold 1 : 0.2528385668992996\n",
      "K-fold 2 : 0.23940832200257675\n",
      "K-fold 3 : 0.23241478463877802\n",
      "K-fold 4 : 0.25620675864426984\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.21474077386988533\n",
      "K-fold 1 : 0.248384676542547\n",
      "K-fold 2 : 0.23000160687499577\n",
      "K-fold 3 : 0.22442556106381947\n",
      "K-fold 4 : 0.2511808627181583\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.21539975832337918\n",
      "K-fold 1 : 0.2528385668992996\n",
      "K-fold 2 : 0.23940832200257675\n",
      "K-fold 3 : 0.23241478463877802\n",
      "K-fold 4 : 0.25620675864426984\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2392536381016607\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.80729166666667\n",
      "K-fold 2 : 95.9375\n",
      "K-fold 3 : 95.75520833333333\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 96.00694444444444\n",
      "K-fold 2 : 95.48611111111111\n",
      "K-fold 3 : 96.21527777777777\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.80729166666667\n",
      "K-fold 2 : 95.9375\n",
      "K-fold 3 : 95.75520833333333\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 96.00694444444444\n",
      "K-fold 2 : 95.48611111111111\n",
      "K-fold 3 : 96.21527777777777\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17154762289590306\n",
      "K-fold 1 : 0.17432600491576725\n",
      "K-fold 2 : 0.17045219250851207\n",
      "K-fold 3 : 0.1752454546590646\n",
      "K-fold 4 : 0.17342753907044728\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.185154947573724\n",
      "K-fold 1 : 0.17311187606790793\n",
      "K-fold 2 : 0.19324724440989288\n",
      "K-fold 3 : 0.17302915972212088\n",
      "K-fold 4 : 0.1763538909347161\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17116709649562836\n",
      "K-fold 1 : 0.17282106619742182\n",
      "K-fold 2 : 0.1697681093381511\n",
      "K-fold 3 : 0.1752454546590646\n",
      "K-fold 4 : 0.1728872718082534\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18106615349002506\n",
      "K-fold 1 : 0.17208100563806036\n",
      "K-fold 2 : 0.19129875302314758\n",
      "K-fold 3 : 0.17110127518358437\n",
      "K-fold 4 : 0.17499006895915323\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17810745125879412\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.82465277777777\n",
      "K-fold 2 : 95.82465277777777\n",
      "K-fold 3 : 95.89409722222223\n",
      "K-fold 4 : 95.859375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 95.9375\n",
      "K-fold 3 : 95.65972222222223\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.82465277777777\n",
      "K-fold 2 : 95.82465277777777\n",
      "K-fold 3 : 95.89409722222223\n",
      "K-fold 4 : 95.859375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 95.9375\n",
      "K-fold 3 : 95.65972222222223\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1957214845551385\n",
      "K-fold 1 : 0.2003805410530832\n",
      "K-fold 2 : 0.19633058061202366\n",
      "K-fold 3 : 0.19688732880685064\n",
      "K-fold 4 : 0.1901674041317569\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19632200767164645\n",
      "K-fold 1 : 0.2052436338170715\n",
      "K-fold 2 : 0.2016238813167033\n",
      "K-fold 3 : 0.20109960728365442\n",
      "K-fold 4 : 0.1982083284984464\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.19568770966596075\n",
      "K-fold 1 : 0.2003805410530832\n",
      "K-fold 2 : 0.19633058061202366\n",
      "K-fold 3 : 0.19688732880685064\n",
      "K-fold 4 : 0.1901674041317569\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1959123572577601\n",
      "K-fold 1 : 0.20427953937779303\n",
      "K-fold 2 : 0.2015313823585925\n",
      "K-fold 3 : 0.20089211930399356\n",
      "K-fold 4 : 0.1950442428174226\n",
      "---------------------------------\n",
      "Average best validation loss: 0.19953192822311233\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 95.85069444444444\n",
      "K-fold 2 : 95.85069444444444\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.76388888888889\n",
      "K-fold 1 : 95.83333333333333\n",
      "K-fold 2 : 95.83333333333333\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 95.85069444444444\n",
      "K-fold 2 : 95.85069444444444\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.76388888888889\n",
      "K-fold 1 : 95.83333333333333\n",
      "K-fold 2 : 95.83333333333333\n",
      "K-fold 3 : 95.76388888888889\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1705070017112626\n",
      "K-fold 1 : 0.16973358020186424\n",
      "K-fold 2 : 0.17199524607923294\n",
      "K-fold 3 : 0.1720646892570787\n",
      "K-fold 4 : 0.17550542246964243\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1832627793369086\n",
      "K-fold 1 : 0.18703640738259192\n",
      "K-fold 2 : 0.17801216892574145\n",
      "K-fold 3 : 0.1783759814241658\n",
      "K-fold 4 : 0.17541228769266087\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17013857869638338\n",
      "K-fold 1 : 0.16973358020186424\n",
      "K-fold 2 : 0.1708996312485801\n",
      "K-fold 3 : 0.17027333867218758\n",
      "K-fold 4 : 0.17058293206824196\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1792274253523868\n",
      "K-fold 1 : 0.17702402401229608\n",
      "K-fold 2 : 0.1758143215075783\n",
      "K-fold 3 : 0.1743207774732424\n",
      "K-fold 4 : 0.16905903362709543\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1750891163945198\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.99826388888889\n",
      "K-fold 1 : 95.74652777777777\n",
      "K-fold 2 : 95.80729166666667\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.74652777777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.24305555555556\n",
      "K-fold 1 : 96.25\n",
      "K-fold 2 : 96.00694444444444\n",
      "K-fold 3 : 95.48611111111111\n",
      "K-fold 4 : 96.25\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.99826388888889\n",
      "K-fold 1 : 95.74652777777777\n",
      "K-fold 2 : 95.80729166666667\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.74652777777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.24305555555556\n",
      "K-fold 1 : 96.25\n",
      "K-fold 2 : 96.00694444444444\n",
      "K-fold 3 : 95.48611111111111\n",
      "K-fold 4 : 96.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18098506869541275\n",
      "K-fold 1 : 0.1914849266409874\n",
      "K-fold 2 : 0.18839149963524607\n",
      "K-fold 3 : 0.18423754100998244\n",
      "K-fold 4 : 0.19375258816613092\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.20462407625239828\n",
      "K-fold 1 : 0.17491724082957144\n",
      "K-fold 2 : 0.18390002781930176\n",
      "K-fold 3 : 0.19977197115835937\n",
      "K-fold 4 : 0.1865264540133269\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18085001599457529\n",
      "K-fold 1 : 0.19069612936841118\n",
      "K-fold 2 : 0.1883286522494422\n",
      "K-fold 3 : 0.18384607939256561\n",
      "K-fold 4 : 0.19324316622482407\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.20035926349785016\n",
      "K-fold 1 : 0.1737743117239164\n",
      "K-fold 2 : 0.18219535376714624\n",
      "K-fold 3 : 0.19977197115835937\n",
      "K-fold 4 : 0.1865264540133269\n",
      "---------------------------------\n",
      "Average best validation loss: 0.18852547083211985\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.87673611111111\n",
      "K-fold 2 : 95.98090277777777\n",
      "K-fold 3 : 95.73784722222223\n",
      "K-fold 4 : 95.73784722222223\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 95.3125\n",
      "K-fold 3 : 96.28472222222223\n",
      "K-fold 4 : 96.28472222222223\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.87673611111111\n",
      "K-fold 2 : 95.98090277777777\n",
      "K-fold 3 : 95.73784722222223\n",
      "K-fold 4 : 95.73784722222223\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 95.3125\n",
      "K-fold 3 : 96.28472222222223\n",
      "K-fold 4 : 96.28472222222223\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16834416629539595\n",
      "K-fold 1 : 0.1698538529376189\n",
      "K-fold 2 : 0.16647775322198868\n",
      "K-fold 3 : 0.17346693699558577\n",
      "K-fold 4 : 0.17280688691470358\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18140331785316052\n",
      "K-fold 1 : 0.1807840628468472\n",
      "K-fold 2 : 0.19905188290969186\n",
      "K-fold 3 : 0.16256066768065744\n",
      "K-fold 4 : 0.1684256238134011\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16647936412029796\n",
      "K-fold 1 : 0.16827807186378374\n",
      "K-fold 2 : 0.16511657362182935\n",
      "K-fold 3 : 0.17159267564614614\n",
      "K-fold 4 : 0.17075700494978163\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17923598639343097\n",
      "K-fold 1 : 0.17484764981528986\n",
      "K-fold 2 : 0.18932689823534177\n",
      "K-fold 3 : 0.1614257288367852\n",
      "K-fold 4 : 0.16149906166221784\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17326706498861313\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 61.302083333333336\n",
      "K-fold 1 : 68.75868055555556\n",
      "K-fold 2 : 75.00868055555556\n",
      "K-fold 3 : 68.35069444444444\n",
      "K-fold 4 : 69.73958333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 58.99305555555556\n",
      "K-fold 1 : 65.13888888888889\n",
      "K-fold 2 : 75.79861111111111\n",
      "K-fold 3 : 66.00694444444444\n",
      "K-fold 4 : 67.91666666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 67.76909722222223\n",
      "K-fold 1 : 73.02083333333333\n",
      "K-fold 2 : 75.69444444444444\n",
      "K-fold 3 : 71.14583333333333\n",
      "K-fold 4 : 69.73958333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 67.1875\n",
      "K-fold 1 : 73.33333333333333\n",
      "K-fold 2 : 75.79861111111111\n",
      "K-fold 3 : 69.93055555555556\n",
      "K-fold 4 : 67.91666666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 70.83333333333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6524062196413676\n",
      "K-fold 1 : 0.6520488858222961\n",
      "K-fold 2 : 0.6156964467631446\n",
      "K-fold 3 : 0.6195483346780141\n",
      "K-fold 4 : 0.6760428130626679\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.658390822617904\n",
      "K-fold 1 : 0.6551718219466831\n",
      "K-fold 2 : 0.6154799824175627\n",
      "K-fold 3 : 0.6278685409089794\n",
      "K-fold 4 : 0.6801268432451331\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6524062196413676\n",
      "K-fold 1 : 0.6520488858222961\n",
      "K-fold 2 : 0.6156964467631446\n",
      "K-fold 3 : 0.6195483346780141\n",
      "K-fold 4 : 0.6760216587119632\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.658390822617904\n",
      "K-fold 1 : 0.6549417039622432\n",
      "K-fold 2 : 0.6154799824175627\n",
      "K-fold 3 : 0.6278685409089794\n",
      "K-fold 4 : 0.6801268432451331\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6473615786303645\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.217013888888886\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 50.494791666666664\n",
      "K-fold 3 : 49.41840277777778\n",
      "K-fold 4 : 50.564236111111114\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.65972222222222\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 49.548611111111114\n",
      "K-fold 3 : 47.951388888888886\n",
      "K-fold 4 : 49.270833333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.58159722222222\n",
      "K-fold 1 : 50.71180555555556\n",
      "K-fold 2 : 50.53819444444444\n",
      "K-fold 3 : 51.59722222222222\n",
      "K-fold 4 : 50.564236111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.65972222222222\n",
      "K-fold 1 : 53.263888888888886\n",
      "K-fold 2 : 49.96527777777778\n",
      "K-fold 3 : 52.361111111111114\n",
      "K-fold 4 : 49.270833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.10416666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931442883279588\n",
      "K-fold 1 : 0.6931324978669484\n",
      "K-fold 2 : 0.6931204497814178\n",
      "K-fold 3 : 0.6931677586502499\n",
      "K-fold 4 : 0.693090373939938\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930900449338167\n",
      "K-fold 1 : 0.6932047475939211\n",
      "K-fold 2 : 0.6932930479878965\n",
      "K-fold 3 : 0.6932023297185483\n",
      "K-fold 4 : 0.6933510018431622\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930594470765855\n",
      "K-fold 1 : 0.693123914135827\n",
      "K-fold 2 : 0.6931049525737762\n",
      "K-fold 3 : 0.6930175556076897\n",
      "K-fold 4 : 0.6930547283755408\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930831178374912\n",
      "K-fold 1 : 0.6930248737335205\n",
      "K-fold 2 : 0.6931398122206979\n",
      "K-fold 3 : 0.6924908446229022\n",
      "K-fold 4 : 0.6933083430580471\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930093982945318\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 82.44791666666667\n",
      "K-fold 1 : 75.42534722222223\n",
      "K-fold 2 : 82.69097222222223\n",
      "K-fold 3 : 68.39409722222223\n",
      "K-fold 4 : 72.75173611111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 80.03472222222223\n",
      "K-fold 1 : 75.24305555555556\n",
      "K-fold 2 : 83.36805555555556\n",
      "K-fold 3 : 66.73611111111111\n",
      "K-fold 4 : 71.80555555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 82.44791666666667\n",
      "K-fold 1 : 80.67708333333333\n",
      "K-fold 2 : 82.84722222222223\n",
      "K-fold 3 : 77.76909722222223\n",
      "K-fold 4 : 72.76909722222223\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 81.5625\n",
      "K-fold 1 : 81.77083333333333\n",
      "K-fold 2 : 83.50694444444444\n",
      "K-fold 3 : 78.29861111111111\n",
      "K-fold 4 : 72.46527777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 79.52083333333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.5767359720336066\n",
      "K-fold 1 : 0.5733295308219062\n",
      "K-fold 2 : 0.5545530087418027\n",
      "K-fold 3 : 0.6209601276450687\n",
      "K-fold 4 : 0.6368617686960433\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.5838546545609183\n",
      "K-fold 1 : 0.5754707403804945\n",
      "K-fold 2 : 0.55376245405363\n",
      "K-fold 3 : 0.6262361485025157\n",
      "K-fold 4 : 0.6406969842703446\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.5767359720336066\n",
      "K-fold 1 : 0.5733295308219062\n",
      "K-fold 2 : 0.5545530087418027\n",
      "K-fold 3 : 0.6209601276450687\n",
      "K-fold 4 : 0.6368617686960433\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.5838546545609183\n",
      "K-fold 1 : 0.5754707403804945\n",
      "K-fold 2 : 0.55376245405363\n",
      "K-fold 3 : 0.6262361485025157\n",
      "K-fold 4 : 0.6406969842703446\n",
      "---------------------------------\n",
      "Average best validation loss: 0.5960041963535806\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 50.329861111111114\n",
      "K-fold 2 : 50.46875\n",
      "K-fold 3 : 49.84375\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.65277777777778\n",
      "K-fold 1 : 50.208333333333336\n",
      "K-fold 2 : 49.65277777777778\n",
      "K-fold 3 : 51.31944444444444\n",
      "K-fold 4 : 50.69444444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.651041666666664\n",
      "K-fold 1 : 50.329861111111114\n",
      "K-fold 2 : 50.529513888888886\n",
      "K-fold 3 : 50.94618055555556\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.59027777777778\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 51.31944444444444\n",
      "K-fold 4 : 50.69444444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.770833333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931201967928144\n",
      "K-fold 1 : 0.6931345383326213\n",
      "K-fold 2 : 0.6931309004624685\n",
      "K-fold 3 : 0.6931690143214332\n",
      "K-fold 4 : 0.6931595146656037\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693239916925845\n",
      "K-fold 1 : 0.6931517616562222\n",
      "K-fold 2 : 0.6932418735130973\n",
      "K-fold 3 : 0.6931003383968187\n",
      "K-fold 4 : 0.693068019721819\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930791046884325\n",
      "K-fold 1 : 0.6931320163938735\n",
      "K-fold 2 : 0.6931055764357249\n",
      "K-fold 3 : 0.6931457658608754\n",
      "K-fold 4 : 0.6930866758028666\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693133628886679\n",
      "K-fold 1 : 0.6929468020148899\n",
      "K-fold 2 : 0.6930701473484868\n",
      "K-fold 3 : 0.6929254583690477\n",
      "K-fold 4 : 0.6929343394611193\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930020752160446\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.87326388888889\n",
      "K-fold 1 : 86.54513888888889\n",
      "K-fold 2 : 79.18402777777777\n",
      "K-fold 3 : 85.42534722222223\n",
      "K-fold 4 : 80.60763888888889\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 93.64583333333333\n",
      "K-fold 1 : 84.375\n",
      "K-fold 2 : 78.19444444444444\n",
      "K-fold 3 : 84.02777777777777\n",
      "K-fold 4 : 79.20138888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.22048611111111\n",
      "K-fold 1 : 86.54513888888889\n",
      "K-fold 2 : 79.34895833333333\n",
      "K-fold 3 : 88.35069444444444\n",
      "K-fold 4 : 81.875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.64583333333333\n",
      "K-fold 1 : 86.07638888888889\n",
      "K-fold 2 : 79.23611111111111\n",
      "K-fold 3 : 87.5\n",
      "K-fold 4 : 81.77083333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 85.64583333333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.4910751541455587\n",
      "K-fold 1 : 0.5165020489030414\n",
      "K-fold 2 : 0.6047075125906203\n",
      "K-fold 3 : 0.5326929622226291\n",
      "K-fold 4 : 0.5750673426522149\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.48995020726452704\n",
      "K-fold 1 : 0.5240461748579274\n",
      "K-fold 2 : 0.6088738337807034\n",
      "K-fold 3 : 0.534398369167162\n",
      "K-fold 4 : 0.5766347594883131\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.4910751541455587\n",
      "K-fold 1 : 0.5165020489030414\n",
      "K-fold 2 : 0.6047075125906203\n",
      "K-fold 3 : 0.5326929622226291\n",
      "K-fold 4 : 0.5750673426522149\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.48995020726452704\n",
      "K-fold 1 : 0.5224139794059421\n",
      "K-fold 2 : 0.6088738337807034\n",
      "K-fold 3 : 0.534398369167162\n",
      "K-fold 4 : 0.5766347594883131\n",
      "---------------------------------\n",
      "Average best validation loss: 0.5464542298213295\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.38194444444444\n",
      "K-fold 1 : 49.53993055555556\n",
      "K-fold 2 : 50.46006944444444\n",
      "K-fold 3 : 49.392361111111114\n",
      "K-fold 4 : 50.572916666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.0\n",
      "K-fold 1 : 48.4375\n",
      "K-fold 2 : 49.6875\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 49.236111111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.38194444444444\n",
      "K-fold 1 : 50.138888888888886\n",
      "K-fold 2 : 50.58159722222222\n",
      "K-fold 3 : 50.12152777777778\n",
      "K-fold 4 : 50.598958333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.34722222222222\n",
      "K-fold 1 : 51.5625\n",
      "K-fold 2 : 49.6875\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 49.236111111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931319872538249\n",
      "K-fold 1 : 0.6931581291887495\n",
      "K-fold 2 : 0.693117207288742\n",
      "K-fold 3 : 0.6931630326641931\n",
      "K-fold 4 : 0.6930980722109477\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931845934494681\n",
      "K-fold 1 : 0.6931484108385833\n",
      "K-fold 2 : 0.6932860586954199\n",
      "K-fold 3 : 0.6931219100952148\n",
      "K-fold 4 : 0.6934212109316951\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930882407559289\n",
      "K-fold 1 : 0.6931406319141388\n",
      "K-fold 2 : 0.6931116296185388\n",
      "K-fold 3 : 0.6931518938806321\n",
      "K-fold 4 : 0.6930228975084093\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693151030851447\n",
      "K-fold 1 : 0.6931027588636979\n",
      "K-fold 2 : 0.693241518476735\n",
      "K-fold 3 : 0.6930555053379225\n",
      "K-fold 4 : 0.6933349370956421\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6931771501250888\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.85069444444444\n",
      "K-fold 1 : 91.76215277777777\n",
      "K-fold 2 : 89.54861111111111\n",
      "K-fold 3 : 93.359375\n",
      "K-fold 4 : 86.61458333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 91.25\n",
      "K-fold 2 : 89.0625\n",
      "K-fold 3 : 93.09027777777777\n",
      "K-fold 4 : 86.5625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.85069444444444\n",
      "K-fold 1 : 92.03125\n",
      "K-fold 2 : 89.54861111111111\n",
      "K-fold 3 : 93.359375\n",
      "K-fold 4 : 86.61458333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 92.22222222222223\n",
      "K-fold 2 : 89.13194444444444\n",
      "K-fold 3 : 93.09027777777777\n",
      "K-fold 4 : 86.84027777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 91.42361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.45999444988038807\n",
      "K-fold 1 : 0.49839283857080674\n",
      "K-fold 2 : 0.5224243299828635\n",
      "K-fold 3 : 0.4673930595318476\n",
      "K-fold 4 : 0.5142533149984148\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.4618418838666833\n",
      "K-fold 1 : 0.4960159763045933\n",
      "K-fold 2 : 0.5204011875650157\n",
      "K-fold 3 : 0.47002450149992236\n",
      "K-fold 4 : 0.5169532065806182\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.45999444988038807\n",
      "K-fold 1 : 0.49839283857080674\n",
      "K-fold 2 : 0.5224243299828635\n",
      "K-fold 3 : 0.4673930595318476\n",
      "K-fold 4 : 0.5141712599330478\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.4618418838666833\n",
      "K-fold 1 : 0.4960159763045933\n",
      "K-fold 2 : 0.5201097182605577\n",
      "K-fold 3 : 0.47002450149992236\n",
      "K-fold 4 : 0.5169532065806182\n",
      "---------------------------------\n",
      "Average best validation loss: 0.492989057302475\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.138888888888886\n",
      "K-fold 1 : 50.442708333333336\n",
      "K-fold 2 : 50.30381944444444\n",
      "K-fold 3 : 50.58159722222222\n",
      "K-fold 4 : 49.80034722222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.97222222222222\n",
      "K-fold 1 : 49.75694444444444\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 49.201388888888886\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.138888888888886\n",
      "K-fold 1 : 50.442708333333336\n",
      "K-fold 2 : 50.30381944444444\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.84027777777778\n",
      "K-fold 1 : 49.75694444444444\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 53.19444444444444\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.277777777777786\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931641856829326\n",
      "K-fold 1 : 0.6931258228090075\n",
      "K-fold 2 : 0.6931595106919607\n",
      "K-fold 3 : 0.6930993934472401\n",
      "K-fold 4 : 0.693156800005171\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930882671604985\n",
      "K-fold 1 : 0.6932276124539583\n",
      "K-fold 2 : 0.6931432666985885\n",
      "K-fold 3 : 0.6933625988338304\n",
      "K-fold 4 : 0.6931024426999299\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931500044133928\n",
      "K-fold 1 : 0.6930848525630103\n",
      "K-fold 2 : 0.6931323991881476\n",
      "K-fold 3 : 0.6929343442122141\n",
      "K-fold 4 : 0.6931188477410211\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929969709852467\n",
      "K-fold 1 : 0.6931020202844039\n",
      "K-fold 2 : 0.6931370082108871\n",
      "K-fold 3 : 0.6929525862569395\n",
      "K-fold 4 : 0.6930690666903621\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930515304855678\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.373263888888886\n",
      "K-fold 1 : 50.625\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 50.19965277777778\n",
      "K-fold 4 : 50.12152777777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.03472222222222\n",
      "K-fold 1 : 49.02777777777778\n",
      "K-fold 2 : 50.69444444444444\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.720486111111114\n",
      "K-fold 1 : 50.625\n",
      "K-fold 2 : 50.416666666666664\n",
      "K-fold 3 : 50.19965277777778\n",
      "K-fold 4 : 50.12152777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.354166666666664\n",
      "K-fold 1 : 50.97222222222222\n",
      "K-fold 2 : 51.18055555555556\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.05555555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931305852201249\n",
      "K-fold 1 : 0.6930928058094449\n",
      "K-fold 2 : 0.6931550204753876\n",
      "K-fold 3 : 0.6931609061029222\n",
      "K-fold 4 : 0.6931508090760973\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931555711704752\n",
      "K-fold 1 : 0.6933638375738392\n",
      "K-fold 2 : 0.693126626636671\n",
      "K-fold 3 : 0.6931334112001502\n",
      "K-fold 4 : 0.6931129668069922\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931258777777354\n",
      "K-fold 1 : 0.6930771463447147\n",
      "K-fold 2 : 0.6931442803806729\n",
      "K-fold 3 : 0.6931459963321686\n",
      "K-fold 4 : 0.6931479831536611\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928649130074874\n",
      "K-fold 1 : 0.69293779393901\n",
      "K-fold 2 : 0.6931103727091914\n",
      "K-fold 3 : 0.6930303962334342\n",
      "K-fold 4 : 0.6928533419318821\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929593635642011\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.15625\n",
      "K-fold 1 : 50.286458333333336\n",
      "K-fold 2 : 50.26909722222222\n",
      "K-fold 3 : 50.295138888888886\n",
      "K-fold 4 : 50.520833333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.90277777777778\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 50.451388888888886\n",
      "K-fold 3 : 50.34722222222222\n",
      "K-fold 4 : 49.44444444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.15625\n",
      "K-fold 1 : 50.286458333333336\n",
      "K-fold 2 : 50.26909722222222\n",
      "K-fold 3 : 50.295138888888886\n",
      "K-fold 4 : 50.63368055555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.90277777777778\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 50.451388888888886\n",
      "K-fold 3 : 50.34722222222222\n",
      "K-fold 4 : 49.44444444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.30555555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931653360525767\n",
      "K-fold 1 : 0.6931494931379955\n",
      "K-fold 2 : 0.6931571973694696\n",
      "K-fold 3 : 0.6931392047140333\n",
      "K-fold 4 : 0.6931205491224924\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931037902832031\n",
      "K-fold 1 : 0.6931338802627895\n",
      "K-fold 2 : 0.6931258984234022\n",
      "K-fold 3 : 0.693127093107804\n",
      "K-fold 4 : 0.693215346854666\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931481613053216\n",
      "K-fold 1 : 0.6931357873810662\n",
      "K-fold 2 : 0.6931376847955916\n",
      "K-fold 3 : 0.6931347999307844\n",
      "K-fold 4 : 0.6930981040000915\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930660009384155\n",
      "K-fold 1 : 0.693128518436266\n",
      "K-fold 2 : 0.693124084368996\n",
      "K-fold 3 : 0.6931244782779528\n",
      "K-fold 4 : 0.6931909918785095\n",
      "---------------------------------\n",
      "Average best validation loss: 0.693126814780028\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.48784722222222\n",
      "K-fold 1 : 50.26909722222222\n",
      "K-fold 2 : 50.529513888888886\n",
      "K-fold 3 : 49.64409722222222\n",
      "K-fold 4 : 50.50347222222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 50.451388888888886\n",
      "K-fold 2 : 49.40972222222222\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 49.513888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.182291666666664\n",
      "K-fold 1 : 50.390625\n",
      "K-fold 2 : 50.685763888888886\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 50.50347222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.31944444444444\n",
      "K-fold 1 : 50.451388888888886\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 50.65972222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.63888888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931723409228855\n",
      "K-fold 1 : 0.6931586649682787\n",
      "K-fold 2 : 0.6931005352073245\n",
      "K-fold 3 : 0.6931609955098894\n",
      "K-fold 4 : 0.6931309627162086\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931266240451647\n",
      "K-fold 1 : 0.6931206428486368\n",
      "K-fold 2 : 0.6932789553766665\n",
      "K-fold 3 : 0.6931277098863021\n",
      "K-fold 4 : 0.6932151550832002\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931518680519528\n",
      "K-fold 1 : 0.6931389066908095\n",
      "K-fold 2 : 0.6930966324276394\n",
      "K-fold 3 : 0.6931480997138553\n",
      "K-fold 4 : 0.6931044671270582\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929753111756366\n",
      "K-fold 1 : 0.6931156619735386\n",
      "K-fold 2 : 0.6931946199873219\n",
      "K-fold 3 : 0.6930726973906808\n",
      "K-fold 4 : 0.6929966833280481\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930709947710453\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 50.00868055555556\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.43402777777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.44444444444444\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 51.49305555555556\n",
      "K-fold 3 : 50.798611111111114\n",
      "K-fold 4 : 49.791666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 50.00868055555556\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.43402777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 49.93055555555556\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 51.49305555555556\n",
      "K-fold 3 : 52.25694444444444\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.77777777777778\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931115210056304\n",
      "K-fold 1 : 0.693143195576138\n",
      "K-fold 2 : 0.69316326379776\n",
      "K-fold 3 : 0.693152004480362\n",
      "K-fold 4 : 0.6931204762723711\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932482693506323\n",
      "K-fold 1 : 0.6931486414826434\n",
      "K-fold 2 : 0.6931212233460468\n",
      "K-fold 3 : 0.6931209149567977\n",
      "K-fold 4 : 0.6932116461836774\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930988636281755\n",
      "K-fold 1 : 0.6931261830859714\n",
      "K-fold 2 : 0.69315358599027\n",
      "K-fold 3 : 0.6931466658910116\n",
      "K-fold 4 : 0.6931183841493395\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6932240491328032\n",
      "K-fold 1 : 0.6931451248086017\n",
      "K-fold 2 : 0.6930816173553467\n",
      "K-fold 3 : 0.6930877644082775\n",
      "K-fold 4 : 0.6931046273397363\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6931286366089531\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.3125\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 50.286458333333336\n",
      "K-fold 3 : 50.338541666666664\n",
      "K-fold 4 : 50.173611111111114\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.27777777777778\n",
      "K-fold 1 : 49.861111111111114\n",
      "K-fold 2 : 50.38194444444444\n",
      "K-fold 3 : 50.173611111111114\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.373263888888886\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 50.286458333333336\n",
      "K-fold 3 : 50.407986111111114\n",
      "K-fold 4 : 50.607638888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 50.97222222222222\n",
      "K-fold 2 : 50.86805555555556\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.78472222222222\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931454519430796\n",
      "K-fold 1 : 0.6931284778647953\n",
      "K-fold 2 : 0.6931522382630242\n",
      "K-fold 3 : 0.6931345495912764\n",
      "K-fold 4 : 0.6931772689024608\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931389466575955\n",
      "K-fold 1 : 0.6931788973186327\n",
      "K-fold 2 : 0.6931264555972555\n",
      "K-fold 3 : 0.6931683395219885\n",
      "K-fold 4 : 0.6931294436040132\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931340389781528\n",
      "K-fold 1 : 0.6931178794966804\n",
      "K-fold 2 : 0.6931370933850606\n",
      "K-fold 3 : 0.6931093527211083\n",
      "K-fold 4 : 0.6931467162238227\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931373295576676\n",
      "K-fold 1 : 0.6931629129078077\n",
      "K-fold 2 : 0.6931143117987592\n",
      "K-fold 3 : 0.692827556444251\n",
      "K-fold 4 : 0.6930673822112705\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930618985839512\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.50347222222222\n",
      "K-fold 1 : 50.30381944444444\n",
      "K-fold 2 : 50.407986111111114\n",
      "K-fold 3 : 50.373263888888886\n",
      "K-fold 4 : 50.060763888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.513888888888886\n",
      "K-fold 1 : 50.3125\n",
      "K-fold 2 : 49.895833333333336\n",
      "K-fold 3 : 50.03472222222222\n",
      "K-fold 4 : 48.229166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.50347222222222\n",
      "K-fold 1 : 50.30381944444444\n",
      "K-fold 2 : 50.407986111111114\n",
      "K-fold 3 : 50.373263888888886\n",
      "K-fold 4 : 50.060763888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.486111111111114\n",
      "K-fold 1 : 50.3125\n",
      "K-fold 2 : 49.895833333333336\n",
      "K-fold 3 : 50.03472222222222\n",
      "K-fold 4 : 51.770833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.50000000000001\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931292831897735\n",
      "K-fold 1 : 0.6931496507591671\n",
      "K-fold 2 : 0.6931513773070441\n",
      "K-fold 3 : 0.6931372152434455\n",
      "K-fold 4 : 0.6931587431165908\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932688174040421\n",
      "K-fold 1 : 0.6931319107180056\n",
      "K-fold 2 : 0.693187977956689\n",
      "K-fold 3 : 0.693154962166496\n",
      "K-fold 4 : 0.6931991317997808\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931035439173381\n",
      "K-fold 1 : 0.6931352085537381\n",
      "K-fold 2 : 0.6931187080012428\n",
      "K-fold 3 : 0.6931253208054436\n",
      "K-fold 4 : 0.6931523270077176\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930704350056855\n",
      "K-fold 1 : 0.6931284666061401\n",
      "K-fold 2 : 0.6931612102881722\n",
      "K-fold 3 : 0.693150608435921\n",
      "K-fold 4 : 0.6931192874908447\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6931260015653528\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.02777777777778\n",
      "K-fold 1 : 50.69444444444444\n",
      "K-fold 2 : 50.59027777777778\n",
      "K-fold 3 : 50.234375\n",
      "K-fold 4 : 48.91493055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.888888888888886\n",
      "K-fold 1 : 48.75\n",
      "K-fold 2 : 49.166666666666664\n",
      "K-fold 3 : 50.59027777777778\n",
      "K-fold 4 : 48.09027777777778\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.78993055555556\n",
      "K-fold 1 : 50.69444444444444\n",
      "K-fold 2 : 51.232638888888886\n",
      "K-fold 3 : 50.451388888888886\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.736111111111114\n",
      "K-fold 1 : 49.166666666666664\n",
      "K-fold 2 : 49.166666666666664\n",
      "K-fold 3 : 50.69444444444444\n",
      "K-fold 4 : 51.90972222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.534722222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931747164991167\n",
      "K-fold 1 : 0.6930837545129988\n",
      "K-fold 2 : 0.6930948184596167\n",
      "K-fold 3 : 0.6931468751695421\n",
      "K-fold 4 : 0.6931615398989783\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931516579959703\n",
      "K-fold 1 : 0.6934396313584369\n",
      "K-fold 2 : 0.6932915189991826\n",
      "K-fold 3 : 0.6931245871212172\n",
      "K-fold 4 : 0.6931587172591168\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931478765275744\n",
      "K-fold 1 : 0.693059919277827\n",
      "K-fold 2 : 0.6930692745579614\n",
      "K-fold 3 : 0.6930871513154772\n",
      "K-fold 4 : 0.6931514395607843\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928755900134211\n",
      "K-fold 1 : 0.6932173371315002\n",
      "K-fold 2 : 0.6931836112685825\n",
      "K-fold 3 : 0.6930661097816799\n",
      "K-fold 4 : 0.6929579480834629\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930601192557294\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.592013888888886\n",
      "K-fold 1 : 49.60069444444444\n",
      "K-fold 2 : 50.416666666666664\n",
      "K-fold 3 : 50.442708333333336\n",
      "K-fold 4 : 50.34722222222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.076388888888886\n",
      "K-fold 1 : 50.69444444444444\n",
      "K-fold 2 : 49.861111111111114\n",
      "K-fold 3 : 49.75694444444444\n",
      "K-fold 4 : 50.138888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.234375\n",
      "K-fold 1 : 50.208333333333336\n",
      "K-fold 2 : 50.50347222222222\n",
      "K-fold 3 : 50.442708333333336\n",
      "K-fold 4 : 50.34722222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.076388888888886\n",
      "K-fold 1 : 50.69444444444444\n",
      "K-fold 2 : 49.861111111111114\n",
      "K-fold 3 : 50.24305555555556\n",
      "K-fold 4 : 50.138888888888886\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.40277777777778\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931639002429114\n",
      "K-fold 1 : 0.6931637499067519\n",
      "K-fold 2 : 0.6931364642249214\n",
      "K-fold 3 : 0.6931224524974823\n",
      "K-fold 4 : 0.693135079410341\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931309959162837\n",
      "K-fold 1 : 0.6931118498677793\n",
      "K-fold 2 : 0.6931924249814905\n",
      "K-fold 3 : 0.6931975691214852\n",
      "K-fold 4 : 0.6931541769400887\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931504117117988\n",
      "K-fold 1 : 0.6931454943286048\n",
      "K-fold 2 : 0.6931172589461009\n",
      "K-fold 3 : 0.6931145621670617\n",
      "K-fold 4 : 0.6931273440519968\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930899853291719\n",
      "K-fold 1 : 0.6930790802706843\n",
      "K-fold 2 : 0.6931646051614181\n",
      "K-fold 3 : 0.6931429246197576\n",
      "K-fold 4 : 0.6931497972944508\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6931252785350965\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.80729166666667\n",
      "K-fold 1 : 95.79861111111111\n",
      "K-fold 2 : 95.78125\n",
      "K-fold 3 : 95.859375\n",
      "K-fold 4 : 95.98958333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.00694444444444\n",
      "K-fold 1 : 96.04166666666667\n",
      "K-fold 2 : 96.11111111111111\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.27777777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.80729166666667\n",
      "K-fold 1 : 95.80729166666667\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 95.859375\n",
      "K-fold 4 : 95.98958333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.00694444444444\n",
      "K-fold 1 : 96.04166666666667\n",
      "K-fold 2 : 96.11111111111111\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.27777777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17693065636687808\n",
      "K-fold 1 : 0.18470567725598813\n",
      "K-fold 2 : 0.17838751383953624\n",
      "K-fold 3 : 0.17867082556088765\n",
      "K-fold 4 : 0.17002441494001283\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17196148698744568\n",
      "K-fold 1 : 0.18391866641847984\n",
      "K-fold 2 : 0.17725995798473773\n",
      "K-fold 3 : 0.18924991883661435\n",
      "K-fold 4 : 0.19670290921045386\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17678331376777756\n",
      "K-fold 1 : 0.18405139396588008\n",
      "K-fold 2 : 0.17518009369572005\n",
      "K-fold 3 : 0.1784503313402335\n",
      "K-fold 4 : 0.16862020790576934\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16940208977979163\n",
      "K-fold 1 : 0.1801294370189957\n",
      "K-fold 2 : 0.16877105022254196\n",
      "K-fold 3 : 0.18193993134343106\n",
      "K-fold 4 : 0.19577284124882324\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1792030699227167\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.81597222222223\n",
      "K-fold 1 : 95.81597222222223\n",
      "K-fold 2 : 95.88541666666667\n",
      "K-fold 3 : 95.94618055555556\n",
      "K-fold 4 : 95.74652777777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.97222222222223\n",
      "K-fold 1 : 95.97222222222223\n",
      "K-fold 2 : 95.625\n",
      "K-fold 3 : 95.41666666666667\n",
      "K-fold 4 : 96.25\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.82465277777777\n",
      "K-fold 1 : 95.82465277777777\n",
      "K-fold 2 : 95.91145833333333\n",
      "K-fold 3 : 95.95486111111111\n",
      "K-fold 4 : 95.74652777777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.97222222222223\n",
      "K-fold 1 : 95.97222222222223\n",
      "K-fold 2 : 95.625\n",
      "K-fold 3 : 95.41666666666667\n",
      "K-fold 4 : 96.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17011971436440945\n",
      "K-fold 1 : 0.16913017978270847\n",
      "K-fold 2 : 0.17018908626503415\n",
      "K-fold 3 : 0.16519119863708814\n",
      "K-fold 4 : 0.17176583682497343\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1716543682243513\n",
      "K-fold 1 : 0.17458405669616617\n",
      "K-fold 2 : 0.19224484102881473\n",
      "K-fold 3 : 0.18391215282937753\n",
      "K-fold 4 : 0.16593493715576504\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16830137959784933\n",
      "K-fold 1 : 0.16644647436009513\n",
      "K-fold 2 : 0.16815445216165648\n",
      "K-fold 3 : 0.16426534859670533\n",
      "K-fold 4 : 0.17024251512355273\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1694660134937452\n",
      "K-fold 1 : 0.16973420232534409\n",
      "K-fold 2 : 0.18047293081231738\n",
      "K-fold 3 : 0.18076944739922232\n",
      "K-fold 4 : 0.16257245547097662\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17260300990032112\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.78993055555556\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 95.96354166666667\n",
      "K-fold 3 : 95.89409722222223\n",
      "K-fold 4 : 95.82465277777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 96.21527777777777\n",
      "K-fold 2 : 95.38194444444444\n",
      "K-fold 3 : 95.65972222222223\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.80729166666667\n",
      "K-fold 1 : 95.76388888888889\n",
      "K-fold 2 : 95.96354166666667\n",
      "K-fold 3 : 95.89409722222223\n",
      "K-fold 4 : 95.82465277777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 96.21527777777777\n",
      "K-fold 2 : 95.38194444444444\n",
      "K-fold 3 : 95.65972222222223\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1748738040112787\n",
      "K-fold 1 : 0.17478292344344987\n",
      "K-fold 2 : 0.17175972933570544\n",
      "K-fold 3 : 0.17373419950405758\n",
      "K-fold 4 : 0.1742474993897809\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17435024419556494\n",
      "K-fold 1 : 0.17446177549984143\n",
      "K-fold 2 : 0.19124918657800424\n",
      "K-fold 3 : 0.18399177847997003\n",
      "K-fold 4 : 0.1803174025338629\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17109183967113495\n",
      "K-fold 1 : 0.17478292344344987\n",
      "K-fold 2 : 0.168759090701739\n",
      "K-fold 3 : 0.17191735973788633\n",
      "K-fold 4 : 0.17292668422063193\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17196932694186334\n",
      "K-fold 1 : 0.1666279652196428\n",
      "K-fold 2 : 0.1895534538704416\n",
      "K-fold 3 : 0.17851084146810614\n",
      "K-fold 4 : 0.1762880916180818\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17658993582362711\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.69444444444444\n",
      "K-fold 1 : 95.88541666666667\n",
      "K-fold 2 : 95.84201388888889\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.28472222222223\n",
      "K-fold 1 : 95.59027777777777\n",
      "K-fold 2 : 95.86805555555556\n",
      "K-fold 3 : 95.97222222222223\n",
      "K-fold 4 : 95.52083333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.74652777777777\n",
      "K-fold 1 : 95.92013888888889\n",
      "K-fold 2 : 95.84201388888889\n",
      "K-fold 3 : 95.82465277777777\n",
      "K-fold 4 : 95.94618055555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.28472222222223\n",
      "K-fold 1 : 95.59027777777777\n",
      "K-fold 2 : 95.86805555555556\n",
      "K-fold 3 : 95.97222222222223\n",
      "K-fold 4 : 95.52083333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16909260290364425\n",
      "K-fold 1 : 0.16536696785026125\n",
      "K-fold 2 : 0.1685205236905151\n",
      "K-fold 3 : 0.1674790322780609\n",
      "K-fold 4 : 0.16453121871583992\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.15937170386314392\n",
      "K-fold 1 : 0.18417369412339252\n",
      "K-fold 2 : 0.17441614166550015\n",
      "K-fold 3 : 0.17610439722952637\n",
      "K-fold 4 : 0.19728368261586066\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16741548362705444\n",
      "K-fold 1 : 0.16391755632228322\n",
      "K-fold 2 : 0.16539265571369066\n",
      "K-fold 3 : 0.16506419711642795\n",
      "K-fold 4 : 0.1620517613987128\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15528336588455283\n",
      "K-fold 1 : 0.18126403767129648\n",
      "K-fold 2 : 0.17004827960677768\n",
      "K-fold 3 : 0.17124585774929627\n",
      "K-fold 4 : 0.1853990303757398\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17264811425753263\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.83333333333333\n",
      "K-fold 2 : 96.00694444444444\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.859375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.31944444444444\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 95.20833333333333\n",
      "K-fold 3 : 96.04166666666667\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.73784722222223\n",
      "K-fold 1 : 95.85069444444444\n",
      "K-fold 2 : 96.00694444444444\n",
      "K-fold 3 : 95.80729166666667\n",
      "K-fold 4 : 95.86805555555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.31944444444444\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 95.20833333333333\n",
      "K-fold 3 : 96.04166666666667\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17622799227635066\n",
      "K-fold 1 : 0.17293831180367206\n",
      "K-fold 2 : 0.1687338039278984\n",
      "K-fold 3 : 0.17339906576606962\n",
      "K-fold 4 : 0.17060873102810648\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16135889065006506\n",
      "K-fold 1 : 0.18444360241941785\n",
      "K-fold 2 : 0.19627617898842561\n",
      "K-fold 3 : 0.17326265670683072\n",
      "K-fold 4 : 0.19377548701089362\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17312016176680725\n",
      "K-fold 1 : 0.1714272292951743\n",
      "K-fold 2 : 0.16545715158184368\n",
      "K-fold 3 : 0.17171062173114882\n",
      "K-fold 4 : 0.17039320713116063\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15924678354159646\n",
      "K-fold 1 : 0.17327885848024618\n",
      "K-fold 2 : 0.19161547526069309\n",
      "K-fold 3 : 0.17002111543779788\n",
      "K-fold 4 : 0.18247475863798804\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17532739827166433\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.76388888888889\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 95.90277777777777\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.18055555555556\n",
      "K-fold 1 : 96.14583333333333\n",
      "K-fold 2 : 95.625\n",
      "K-fold 3 : 95.38194444444444\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.77256944444444\n",
      "K-fold 1 : 95.77256944444444\n",
      "K-fold 2 : 95.90277777777777\n",
      "K-fold 3 : 95.98090277777777\n",
      "K-fold 4 : 95.84201388888889\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.18055555555556\n",
      "K-fold 1 : 96.14583333333333\n",
      "K-fold 2 : 95.625\n",
      "K-fold 3 : 95.38194444444444\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1681923706498411\n",
      "K-fold 1 : 0.16695373836490843\n",
      "K-fold 2 : 0.1632150888442993\n",
      "K-fold 3 : 0.16369594732920328\n",
      "K-fold 4 : 0.16457113160027398\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17059972606923268\n",
      "K-fold 1 : 0.1723080915601357\n",
      "K-fold 2 : 0.18804590566002805\n",
      "K-fold 3 : 0.18754348579956137\n",
      "K-fold 4 : 0.1748199803025826\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16679960841106045\n",
      "K-fold 1 : 0.16564881164166662\n",
      "K-fold 2 : 0.16151870381500985\n",
      "K-fold 3 : 0.1630316258304649\n",
      "K-fold 4 : 0.16405576070149738\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16190589057362598\n",
      "K-fold 1 : 0.1691728885407033\n",
      "K-fold 2 : 0.18390465689742047\n",
      "K-fold 3 : 0.18088326667961868\n",
      "K-fold 4 : 0.17260189937508624\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17369372041329095\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.98958333333333\n",
      "K-fold 1 : 95.73784722222223\n",
      "K-fold 2 : 95.703125\n",
      "K-fold 3 : 95.84201388888889\n",
      "K-fold 4 : 95.94618055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.27777777777777\n",
      "K-fold 1 : 96.28472222222223\n",
      "K-fold 2 : 96.35416666666667\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.45138888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.99826388888889\n",
      "K-fold 1 : 95.73784722222223\n",
      "K-fold 2 : 95.72048611111111\n",
      "K-fold 3 : 95.84201388888889\n",
      "K-fold 4 : 95.95486111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.27777777777777\n",
      "K-fold 1 : 96.28472222222223\n",
      "K-fold 2 : 96.35416666666667\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.45138888888889\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16794262222117848\n",
      "K-fold 1 : 0.17585566076967452\n",
      "K-fold 2 : 0.17634950739641983\n",
      "K-fold 3 : 0.17099626896282036\n",
      "K-fold 4 : 0.16843234996000925\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19750023276909537\n",
      "K-fold 1 : 0.16656965373650842\n",
      "K-fold 2 : 0.16250699207834576\n",
      "K-fold 3 : 0.17919395928797516\n",
      "K-fold 4 : 0.18702924705069998\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16718158370090855\n",
      "K-fold 1 : 0.17295794321431054\n",
      "K-fold 2 : 0.1738081409699387\n",
      "K-fold 3 : 0.16948253164688745\n",
      "K-fold 4 : 0.166260777744982\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.19148816945760147\n",
      "K-fold 1 : 0.16519030021584552\n",
      "K-fold 2 : 0.1590057119079258\n",
      "K-fold 3 : 0.17298608694387518\n",
      "K-fold 4 : 0.18671689279701398\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17507743226445238\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 95.66840277777777\n",
      "K-fold 3 : 95.99826388888889\n",
      "K-fold 4 : 95.85069444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.11111111111111\n",
      "K-fold 1 : 95.48611111111111\n",
      "K-fold 2 : 96.5625\n",
      "K-fold 3 : 95.24305555555556\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 95.94618055555556\n",
      "K-fold 2 : 95.66840277777777\n",
      "K-fold 3 : 96.00694444444444\n",
      "K-fold 4 : 95.859375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.11111111111111\n",
      "K-fold 1 : 95.48611111111111\n",
      "K-fold 2 : 96.5625\n",
      "K-fold 3 : 95.24305555555556\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16621627522011598\n",
      "K-fold 1 : 0.16153672995666662\n",
      "K-fold 2 : 0.1694889370765951\n",
      "K-fold 3 : 0.16032444710532825\n",
      "K-fold 4 : 0.16607884135511186\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1740139395646427\n",
      "K-fold 1 : 0.1957681078625762\n",
      "K-fold 2 : 0.15681153859781183\n",
      "K-fold 3 : 0.1895008511517359\n",
      "K-fold 4 : 0.1764505320917005\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16621627522011598\n",
      "K-fold 1 : 0.16133435583776898\n",
      "K-fold 2 : 0.1694889370765951\n",
      "K-fold 3 : 0.16032444710532825\n",
      "K-fold 4 : 0.1647462799317307\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16435362722562707\n",
      "K-fold 1 : 0.19208818447330725\n",
      "K-fold 2 : 0.15350003087002298\n",
      "K-fold 3 : 0.18759414650823758\n",
      "K-fold 4 : 0.1740411999432937\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1743154378040977\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 93.40277777777777\n",
      "K-fold 1 : 94.95659722222223\n",
      "K-fold 2 : 95.84201388888889\n",
      "K-fold 3 : 93.49826388888889\n",
      "K-fold 4 : 95.94618055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 92.67361111111111\n",
      "K-fold 1 : 94.65277777777777\n",
      "K-fold 2 : 95.86805555555556\n",
      "K-fold 3 : 91.73611111111111\n",
      "K-fold 4 : 95.41666666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.44618055555556\n",
      "K-fold 1 : 95.47743055555556\n",
      "K-fold 2 : 95.85069444444444\n",
      "K-fold 3 : 93.78472222222223\n",
      "K-fold 4 : 95.96354166666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.0\n",
      "K-fold 1 : 96.14583333333333\n",
      "K-fold 2 : 95.86805555555556\n",
      "K-fold 3 : 94.27083333333333\n",
      "K-fold 4 : 95.41666666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.34027777777777\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2520177284876505\n",
      "K-fold 1 : 0.23070493108696408\n",
      "K-fold 2 : 0.1959157912267579\n",
      "K-fold 3 : 0.28099970204962627\n",
      "K-fold 4 : 0.2075361295706696\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.24722925411618274\n",
      "K-fold 1 : 0.22598759311696756\n",
      "K-fold 2 : 0.1926335705363232\n",
      "K-fold 3 : 0.28729944125465723\n",
      "K-fold 4 : 0.2195969470169233\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2520177284876505\n",
      "K-fold 1 : 0.22824350347121555\n",
      "K-fold 2 : 0.19570199830664528\n",
      "K-fold 3 : 0.27968332949611874\n",
      "K-fold 4 : 0.20576058253645896\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.24419257239155148\n",
      "K-fold 1 : 0.21407374415708624\n",
      "K-fold 2 : 0.190456325593202\n",
      "K-fold 3 : 0.28631526231765747\n",
      "K-fold 4 : 0.2195969470169233\n",
      "---------------------------------\n",
      "Average best validation loss: 0.23092697029528408\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.87673611111111\n",
      "K-fold 1 : 95.81597222222223\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 95.86805555555556\n",
      "K-fold 4 : 95.86805555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.97222222222223\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 95.69444444444444\n",
      "K-fold 4 : 95.76388888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.88541666666667\n",
      "K-fold 1 : 95.81597222222223\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 95.89409722222223\n",
      "K-fold 4 : 95.87673611111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.97222222222223\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 95.69444444444444\n",
      "K-fold 4 : 95.76388888888889\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222224\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17492101478079955\n",
      "K-fold 1 : 0.17716252754131953\n",
      "K-fold 2 : 0.17947315321200424\n",
      "K-fold 3 : 0.1814296414454778\n",
      "K-fold 4 : 0.18319548749261433\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17960424721240997\n",
      "K-fold 1 : 0.1728542230051497\n",
      "K-fold 2 : 0.16512558123339777\n",
      "K-fold 3 : 0.18223654252031576\n",
      "K-fold 4 : 0.19524392582800076\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17266423561506802\n",
      "K-fold 1 : 0.17700149458315637\n",
      "K-fold 2 : 0.17879141055875356\n",
      "K-fold 3 : 0.1796382365955247\n",
      "K-fold 4 : 0.17779109122024642\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17583190682141678\n",
      "K-fold 1 : 0.1728542230051497\n",
      "K-fold 2 : 0.16466861574546152\n",
      "K-fold 3 : 0.1781517928061278\n",
      "K-fold 4 : 0.17941632057013718\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17418457178965857\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 95.76388888888889\n",
      "K-fold 2 : 95.92013888888889\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.13020833333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 96.14583333333333\n",
      "K-fold 2 : 95.55555555555556\n",
      "K-fold 3 : 96.04166666666667\n",
      "K-fold 4 : 95.24305555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.82465277777777\n",
      "K-fold 1 : 95.78125\n",
      "K-fold 2 : 95.92013888888889\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.390625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 96.14583333333333\n",
      "K-fold 2 : 95.55555555555556\n",
      "K-fold 3 : 96.04166666666667\n",
      "K-fold 4 : 95.59027777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.21831898043553036\n",
      "K-fold 1 : 0.20238642113076316\n",
      "K-fold 2 : 0.19688712474372652\n",
      "K-fold 3 : 0.20703460880451732\n",
      "K-fold 4 : 0.2131708398461342\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2285194500632908\n",
      "K-fold 1 : 0.19727572410003\n",
      "K-fold 2 : 0.20937808765017468\n",
      "K-fold 3 : 0.20180456664251245\n",
      "K-fold 4 : 0.221436795981034\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.21786293668879403\n",
      "K-fold 1 : 0.19719069103399914\n",
      "K-fold 2 : 0.19680023872190053\n",
      "K-fold 3 : 0.2054959513247013\n",
      "K-fold 4 : 0.2131708398461342\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2194549551476603\n",
      "K-fold 1 : 0.1918412226697673\n",
      "K-fold 2 : 0.2059332391490107\n",
      "K-fold 3 : 0.19294617163098376\n",
      "K-fold 4 : 0.22098955576834473\n",
      "---------------------------------\n",
      "Average best validation loss: 0.20623302887315337\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.79861111111111\n",
      "K-fold 1 : 95.81597222222223\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 95.90277777777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 95.625\n",
      "K-fold 4 : 95.625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.80729166666667\n",
      "K-fold 1 : 95.84201388888889\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 95.91145833333333\n",
      "K-fold 4 : 95.91145833333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 95.625\n",
      "K-fold 4 : 95.625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18008855515056185\n",
      "K-fold 1 : 0.18068842300110394\n",
      "K-fold 2 : 0.18521043244335386\n",
      "K-fold 3 : 0.17600286619530783\n",
      "K-fold 4 : 0.17875836317737898\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18027792287909467\n",
      "K-fold 1 : 0.18000717266746188\n",
      "K-fold 2 : 0.1716986656512903\n",
      "K-fold 3 : 0.18939720385748407\n",
      "K-fold 4 : 0.18611847155767938\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17910260889265273\n",
      "K-fold 1 : 0.17751765275994938\n",
      "K-fold 2 : 0.18208382237288687\n",
      "K-fold 3 : 0.1727651263276736\n",
      "K-fold 4 : 0.17772143971588877\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16988675911789355\n",
      "K-fold 1 : 0.17745267049126004\n",
      "K-fold 2 : 0.16819645189072774\n",
      "K-fold 3 : 0.18018807665161465\n",
      "K-fold 4 : 0.18532135369985\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1762090623702692\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.74652777777777\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 95.92013888888889\n",
      "K-fold 3 : 95.87673611111111\n",
      "K-fold 4 : 95.82465277777777\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.25\n",
      "K-fold 1 : 95.76388888888889\n",
      "K-fold 2 : 95.55555555555556\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.74652777777777\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 95.92881944444444\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 95.82465277777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.25\n",
      "K-fold 1 : 95.76388888888889\n",
      "K-fold 2 : 95.55555555555556\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.19712760804427995\n",
      "K-fold 1 : 0.19537633773353363\n",
      "K-fold 2 : 0.19645394302076763\n",
      "K-fold 3 : 0.19493704297476344\n",
      "K-fold 4 : 0.19387528705928062\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18423437229965045\n",
      "K-fold 1 : 0.20345073290493176\n",
      "K-fold 2 : 0.20618215008922244\n",
      "K-fold 3 : 0.20351781404536703\n",
      "K-fold 4 : 0.19024914470703705\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.19474071868591838\n",
      "K-fold 1 : 0.1927510437866052\n",
      "K-fold 2 : 0.19513106420636178\n",
      "K-fold 3 : 0.19272159180707402\n",
      "K-fold 4 : 0.19090713817212318\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18349930060946423\n",
      "K-fold 1 : 0.19105561207170071\n",
      "K-fold 2 : 0.20296525210142136\n",
      "K-fold 3 : 0.19391416920268018\n",
      "K-fold 4 : 0.18503545159878937\n",
      "---------------------------------\n",
      "Average best validation loss: 0.19129395711681116\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 95.92881944444444\n",
      "K-fold 2 : 95.77256944444444\n",
      "K-fold 3 : 95.83333333333333\n",
      "K-fold 4 : 95.86805555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.41666666666667\n",
      "K-fold 2 : 96.14583333333333\n",
      "K-fold 3 : 95.90277777777777\n",
      "K-fold 4 : 95.72916666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.79861111111111\n",
      "K-fold 1 : 95.95486111111111\n",
      "K-fold 2 : 95.78125\n",
      "K-fold 3 : 95.84201388888889\n",
      "K-fold 4 : 95.88541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.41666666666667\n",
      "K-fold 2 : 96.14583333333333\n",
      "K-fold 3 : 95.90277777777777\n",
      "K-fold 4 : 95.72916666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17821583251158396\n",
      "K-fold 1 : 0.17761236263646019\n",
      "K-fold 2 : 0.17969445428914493\n",
      "K-fold 3 : 0.18173143226239416\n",
      "K-fold 4 : 0.1786786417166392\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1951360767302306\n",
      "K-fold 1 : 0.18980224657317865\n",
      "K-fold 2 : 0.18086740374565125\n",
      "K-fold 3 : 0.1787584741478381\n",
      "K-fold 4 : 0.18569619127589723\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.176530615074767\n",
      "K-fold 1 : 0.17448588468962245\n",
      "K-fold 2 : 0.17950157134069336\n",
      "K-fold 3 : 0.17765992656350135\n",
      "K-fold 4 : 0.1760514673259523\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16772427085949027\n",
      "K-fold 1 : 0.18306720321593078\n",
      "K-fold 2 : 0.16557433132244193\n",
      "K-fold 3 : 0.1753481088773064\n",
      "K-fold 4 : 0.18183971066837726\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17471072498870932\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.859375\n",
      "K-fold 2 : 95.703125\n",
      "K-fold 3 : 95.97222222222223\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 95.79861111111111\n",
      "K-fold 2 : 96.42361111111111\n",
      "K-fold 3 : 95.34722222222223\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 95.86805555555556\n",
      "K-fold 2 : 95.703125\n",
      "K-fold 3 : 95.97222222222223\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 95.79861111111111\n",
      "K-fold 2 : 96.42361111111111\n",
      "K-fold 3 : 95.34722222222223\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18818767873777284\n",
      "K-fold 1 : 0.19506258881754346\n",
      "K-fold 2 : 0.19841592146290674\n",
      "K-fold 3 : 0.18705700321329966\n",
      "K-fold 4 : 0.1981854162282414\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19070793364358984\n",
      "K-fold 1 : 0.18922372356705044\n",
      "K-fold 2 : 0.18548806821522507\n",
      "K-fold 3 : 0.2077576485664948\n",
      "K-fold 4 : 0.19648190361002218\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18692134535974927\n",
      "K-fold 1 : 0.18993538783656227\n",
      "K-fold 2 : 0.19515556875202392\n",
      "K-fold 3 : 0.18425913924972218\n",
      "K-fold 4 : 0.19565062705013486\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18967423231705374\n",
      "K-fold 1 : 0.1857609282369199\n",
      "K-fold 2 : 0.17579667205395905\n",
      "K-fold 3 : 0.2028095433893411\n",
      "K-fold 4 : 0.18712520988091177\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1882333171756371\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.78993055555556\n",
      "K-fold 1 : 95.87673611111111\n",
      "K-fold 2 : 95.66840277777777\n",
      "K-fold 3 : 95.87673611111111\n",
      "K-fold 4 : 95.96354166666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.07638888888889\n",
      "K-fold 1 : 95.65972222222223\n",
      "K-fold 2 : 96.38888888888889\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.38194444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.79861111111111\n",
      "K-fold 1 : 95.89409722222223\n",
      "K-fold 2 : 95.72048611111111\n",
      "K-fold 3 : 95.87673611111111\n",
      "K-fold 4 : 95.96354166666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.07638888888889\n",
      "K-fold 1 : 95.65972222222223\n",
      "K-fold 2 : 96.38888888888889\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.38194444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17481992277834152\n",
      "K-fold 1 : 0.17706869906849332\n",
      "K-fold 2 : 0.185254900654157\n",
      "K-fold 3 : 0.1757439259853628\n",
      "K-fold 4 : 0.17607986885640356\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17186144447844962\n",
      "K-fold 1 : 0.18578867679056915\n",
      "K-fold 2 : 0.16201867973027023\n",
      "K-fold 3 : 0.18471796551476355\n",
      "K-fold 4 : 0.19348957033261008\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17283110212948588\n",
      "K-fold 1 : 0.17567287153667874\n",
      "K-fold 2 : 0.18225638427668148\n",
      "K-fold 3 : 0.17533673354321055\n",
      "K-fold 4 : 0.17185543154676755\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16799039490844891\n",
      "K-fold 1 : 0.17680955062741818\n",
      "K-fold 2 : 0.15895171852215476\n",
      "K-fold 3 : 0.18015163618585336\n",
      "K-fold 4 : 0.18505680820216303\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17379202168920765\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 64.78298611111111\n",
      "K-fold 1 : 49.69618055555556\n",
      "K-fold 2 : 49.939236111111114\n",
      "K-fold 3 : 49.61805555555556\n",
      "K-fold 4 : 49.861111111111114\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 63.15972222222222\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 50.24305555555556\n",
      "K-fold 3 : 49.548611111111114\n",
      "K-fold 4 : 49.93055555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 64.81770833333333\n",
      "K-fold 1 : 50.598958333333336\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 50.885416666666664\n",
      "K-fold 4 : 50.989583333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 63.15972222222222\n",
      "K-fold 1 : 52.395833333333336\n",
      "K-fold 2 : 50.24305555555556\n",
      "K-fold 3 : 51.076388888888886\n",
      "K-fold 4 : 50.625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 53.5\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6891499062379202\n",
      "K-fold 1 : 0.693339553144243\n",
      "K-fold 2 : 0.6932602451907264\n",
      "K-fold 3 : 0.6932488527562883\n",
      "K-fold 4 : 0.6932271904415555\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6900535951489988\n",
      "K-fold 1 : 0.6930383599322775\n",
      "K-fold 2 : 0.6931576158689416\n",
      "K-fold 3 : 0.6931649239166923\n",
      "K-fold 4 : 0.6932216649470122\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6886375910705991\n",
      "K-fold 1 : 0.6930893884764777\n",
      "K-fold 2 : 0.693034381336636\n",
      "K-fold 3 : 0.6930564529365963\n",
      "K-fold 4 : 0.6931164827611711\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6893833383269932\n",
      "K-fold 1 : 0.69299650710562\n",
      "K-fold 2 : 0.6931225787038389\n",
      "K-fold 3 : 0.6931009448092916\n",
      "K-fold 4 : 0.6931450859360073\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6923496909763502\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.11284722222222\n",
      "K-fold 1 : 49.46180555555556\n",
      "K-fold 2 : 50.46006944444444\n",
      "K-fold 3 : 50.53819444444444\n",
      "K-fold 4 : 49.791666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.270833333333336\n",
      "K-fold 1 : 48.40277777777778\n",
      "K-fold 2 : 49.6875\n",
      "K-fold 3 : 49.861111111111114\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 50.607638888888886\n",
      "K-fold 2 : 50.73784722222222\n",
      "K-fold 3 : 50.71180555555556\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.729166666666664\n",
      "K-fold 1 : 51.59722222222222\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 50.138888888888886\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.72222222222222\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693225978480445\n",
      "K-fold 1 : 0.6933096296257443\n",
      "K-fold 2 : 0.693244974480735\n",
      "K-fold 3 : 0.6932020882765452\n",
      "K-fold 4 : 0.6932614167531331\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6935053700986116\n",
      "K-fold 1 : 0.6932727694511414\n",
      "K-fold 2 : 0.693159422148829\n",
      "K-fold 3 : 0.6932154893875122\n",
      "K-fold 4 : 0.6929745337237483\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930666320853763\n",
      "K-fold 1 : 0.6931266784667969\n",
      "K-fold 2 : 0.693118213944965\n",
      "K-fold 3 : 0.6931272586186726\n",
      "K-fold 4 : 0.6929424709743923\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930554250012273\n",
      "K-fold 1 : 0.6927154323329097\n",
      "K-fold 2 : 0.693128562491873\n",
      "K-fold 3 : 0.693143507708674\n",
      "K-fold 4 : 0.6929662668186686\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930018388706706\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 63.78472222222222\n",
      "K-fold 1 : 49.826388888888886\n",
      "K-fold 2 : 57.717013888888886\n",
      "K-fold 3 : 64.30555555555556\n",
      "K-fold 4 : 49.85243055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 64.79166666666667\n",
      "K-fold 1 : 50.24305555555556\n",
      "K-fold 2 : 56.52777777777778\n",
      "K-fold 3 : 64.89583333333333\n",
      "K-fold 4 : 51.423611111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 63.958333333333336\n",
      "K-fold 1 : 51.015625\n",
      "K-fold 2 : 57.838541666666664\n",
      "K-fold 3 : 64.33159722222223\n",
      "K-fold 4 : 50.73784722222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 64.79166666666667\n",
      "K-fold 1 : 50.625\n",
      "K-fold 2 : 56.52777777777778\n",
      "K-fold 3 : 64.89583333333333\n",
      "K-fold 4 : 52.77777777777778\n",
      "---------------------------------\n",
      "Average best validation accuracy: 57.92361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6901278257369995\n",
      "K-fold 1 : 0.6932094746165806\n",
      "K-fold 2 : 0.6905868874655829\n",
      "K-fold 3 : 0.689266613456938\n",
      "K-fold 4 : 0.693359719382392\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6899094607519067\n",
      "K-fold 1 : 0.6931962241297183\n",
      "K-fold 2 : 0.6909443451010663\n",
      "K-fold 3 : 0.6884454436924147\n",
      "K-fold 4 : 0.69269692638646\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6896069725354512\n",
      "K-fold 1 : 0.6930793994002872\n",
      "K-fold 2 : 0.6901078939437866\n",
      "K-fold 3 : 0.6885619077417585\n",
      "K-fold 4 : 0.6931000212828319\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6895400829937147\n",
      "K-fold 1 : 0.6931307056675786\n",
      "K-fold 2 : 0.6905500474183456\n",
      "K-fold 3 : 0.6880607890046161\n",
      "K-fold 4 : 0.6926546433697576\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6907872536908025\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.61631944444444\n",
      "K-fold 1 : 50.364583333333336\n",
      "K-fold 2 : 49.704861111111114\n",
      "K-fold 3 : 49.91319444444444\n",
      "K-fold 4 : 50.130208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.826388888888886\n",
      "K-fold 1 : 50.06944444444444\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 49.826388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.94618055555556\n",
      "K-fold 1 : 51.00694444444444\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.12847222222222\n",
      "K-fold 4 : 50.842013888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.173611111111114\n",
      "K-fold 1 : 50.06944444444444\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 50.173611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.44444444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693176023165385\n",
      "K-fold 1 : 0.693344513575236\n",
      "K-fold 2 : 0.6932443598906199\n",
      "K-fold 3 : 0.693270480632782\n",
      "K-fold 4 : 0.6931955913702647\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932134006334387\n",
      "K-fold 1 : 0.6931485974270365\n",
      "K-fold 2 : 0.6930569902710293\n",
      "K-fold 3 : 0.6930182653924694\n",
      "K-fold 4 : 0.6932342467100724\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931352688206567\n",
      "K-fold 1 : 0.6930035816298591\n",
      "K-fold 2 : 0.6930966860718197\n",
      "K-fold 3 : 0.6929568741056654\n",
      "K-fold 4 : 0.6931315256489647\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931451325831206\n",
      "K-fold 1 : 0.693143507708674\n",
      "K-fold 2 : 0.6929396002188973\n",
      "K-fold 3 : 0.6930029262667117\n",
      "K-fold 4 : 0.6931284821551779\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930719297865162\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 62.66493055555556\n",
      "K-fold 1 : 49.14930555555556\n",
      "K-fold 2 : 73.55034722222223\n",
      "K-fold 3 : 61.197916666666664\n",
      "K-fold 4 : 63.359375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 64.75694444444444\n",
      "K-fold 1 : 50.798611111111114\n",
      "K-fold 2 : 72.32638888888889\n",
      "K-fold 3 : 64.375\n",
      "K-fold 4 : 64.58333333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 64.80902777777777\n",
      "K-fold 1 : 50.73784722222222\n",
      "K-fold 2 : 77.50868055555556\n",
      "K-fold 3 : 64.47048611111111\n",
      "K-fold 4 : 64.23611111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 64.75694444444444\n",
      "K-fold 1 : 52.395833333333336\n",
      "K-fold 2 : 79.79166666666667\n",
      "K-fold 3 : 64.86111111111111\n",
      "K-fold 4 : 64.61805555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 65.28472222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6884548683961232\n",
      "K-fold 1 : 0.6933861407968733\n",
      "K-fold 2 : 0.6310769809616936\n",
      "K-fold 3 : 0.6894336018297408\n",
      "K-fold 4 : 0.6899575836128659\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6889045445815377\n",
      "K-fold 1 : 0.6930981718975565\n",
      "K-fold 2 : 0.6313751262167225\n",
      "K-fold 3 : 0.6894150739130767\n",
      "K-fold 4 : 0.6906442305316096\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6877263300948673\n",
      "K-fold 1 : 0.6931659115685357\n",
      "K-fold 2 : 0.6299632264508142\n",
      "K-fold 3 : 0.6886840456061893\n",
      "K-fold 4 : 0.6895209279325273\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6884627394054247\n",
      "K-fold 1 : 0.6929937601089478\n",
      "K-fold 2 : 0.6311909141747848\n",
      "K-fold 3 : 0.6875584773395372\n",
      "K-fold 4 : 0.6899253363194673\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6780262454696324\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.26215277777778\n",
      "K-fold 1 : 50.572916666666664\n",
      "K-fold 2 : 50.04340277777778\n",
      "K-fold 3 : 49.479166666666664\n",
      "K-fold 4 : 50.052083333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.50694444444444\n",
      "K-fold 1 : 50.763888888888886\n",
      "K-fold 2 : 50.38194444444444\n",
      "K-fold 3 : 50.27777777777778\n",
      "K-fold 4 : 50.138888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.66840277777778\n",
      "K-fold 1 : 50.885416666666664\n",
      "K-fold 2 : 50.92881944444444\n",
      "K-fold 3 : 50.642361111111114\n",
      "K-fold 4 : 50.954861111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.49305555555556\n",
      "K-fold 1 : 50.763888888888886\n",
      "K-fold 2 : 50.38194444444444\n",
      "K-fold 3 : 50.27777777777778\n",
      "K-fold 4 : 50.138888888888886\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.61111111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933061321576436\n",
      "K-fold 1 : 0.6931415319442749\n",
      "K-fold 2 : 0.6933903733889262\n",
      "K-fold 3 : 0.6932530211077796\n",
      "K-fold 4 : 0.693190293179618\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932240854138914\n",
      "K-fold 1 : 0.6931440182354139\n",
      "K-fold 2 : 0.6932369911152384\n",
      "K-fold 3 : 0.6931758756222932\n",
      "K-fold 4 : 0.6931697985400325\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931090831756592\n",
      "K-fold 1 : 0.6930556767516666\n",
      "K-fold 2 : 0.6930907620324029\n",
      "K-fold 3 : 0.6931038697560629\n",
      "K-fold 4 : 0.6930423458417256\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926800790040389\n",
      "K-fold 1 : 0.6930071789285411\n",
      "K-fold 2 : 0.6931359197782434\n",
      "K-fold 3 : 0.6931388404058374\n",
      "K-fold 4 : 0.6931413930395375\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930206822312398\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.173611111111114\n",
      "K-fold 1 : 61.52777777777778\n",
      "K-fold 2 : 50.217013888888886\n",
      "K-fold 3 : 57.395833333333336\n",
      "K-fold 4 : 50.90277777777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.138888888888886\n",
      "K-fold 1 : 63.541666666666664\n",
      "K-fold 2 : 49.479166666666664\n",
      "K-fold 3 : 64.82638888888889\n",
      "K-fold 4 : 51.354166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.920138888888886\n",
      "K-fold 1 : 64.12326388888889\n",
      "K-fold 2 : 50.755208333333336\n",
      "K-fold 3 : 64.30555555555556\n",
      "K-fold 4 : 50.90277777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.666666666666664\n",
      "K-fold 1 : 63.541666666666664\n",
      "K-fold 2 : 51.49305555555556\n",
      "K-fold 3 : 66.07638888888889\n",
      "K-fold 4 : 53.47222222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 57.25\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933613114886814\n",
      "K-fold 1 : 0.6892704248428345\n",
      "K-fold 2 : 0.6932461301485697\n",
      "K-fold 3 : 0.6911756760544248\n",
      "K-fold 4 : 0.693419928683175\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933676470880923\n",
      "K-fold 1 : 0.689527330191239\n",
      "K-fold 2 : 0.6932178217431774\n",
      "K-fold 3 : 0.6902296180310457\n",
      "K-fold 4 : 0.6928878633872323\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930891984038883\n",
      "K-fold 1 : 0.6883288774225447\n",
      "K-fold 2 : 0.6931242677900527\n",
      "K-fold 3 : 0.6903134657277001\n",
      "K-fold 4 : 0.6929647233751085\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930928515351337\n",
      "K-fold 1 : 0.6888735138851664\n",
      "K-fold 2 : 0.693040352800618\n",
      "K-fold 3 : 0.6896717755690865\n",
      "K-fold 4 : 0.6927959944890894\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6914948976558188\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.80034722222222\n",
      "K-fold 1 : 50.47743055555556\n",
      "K-fold 2 : 49.895833333333336\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 50.138888888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.96527777777778\n",
      "K-fold 1 : 49.61805555555556\n",
      "K-fold 2 : 50.34722222222222\n",
      "K-fold 3 : 51.18055555555556\n",
      "K-fold 4 : 49.583333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.82465277777778\n",
      "K-fold 1 : 50.82465277777778\n",
      "K-fold 2 : 50.85069444444444\n",
      "K-fold 3 : 50.97222222222222\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.03472222222222\n",
      "K-fold 1 : 51.21527777777778\n",
      "K-fold 2 : 50.34722222222222\n",
      "K-fold 3 : 51.18055555555556\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.638888888888886\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932387716240354\n",
      "K-fold 1 : 0.6931302441491021\n",
      "K-fold 2 : 0.6932296209865146\n",
      "K-fold 3 : 0.6932572225729624\n",
      "K-fold 4 : 0.6933089607291751\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931787314622299\n",
      "K-fold 1 : 0.6931942312613778\n",
      "K-fold 2 : 0.6931485818779987\n",
      "K-fold 3 : 0.692887904851333\n",
      "K-fold 4 : 0.6932478598926378\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930905037456089\n",
      "K-fold 1 : 0.6930647770563761\n",
      "K-fold 2 : 0.6930489440759023\n",
      "K-fold 3 : 0.6930729945500692\n",
      "K-fold 4 : 0.6931336561838786\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693146957003552\n",
      "K-fold 1 : 0.6930640132530875\n",
      "K-fold 2 : 0.6931383039640344\n",
      "K-fold 3 : 0.692865278409875\n",
      "K-fold 4 : 0.6930805677952974\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930590240851693\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.85243055555556\n",
      "K-fold 1 : 50.03472222222222\n",
      "K-fold 2 : 50.138888888888886\n",
      "K-fold 3 : 49.861111111111114\n",
      "K-fold 4 : 50.026041666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.24305555555556\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 49.375\n",
      "K-fold 3 : 51.736111111111114\n",
      "K-fold 4 : 51.00694444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 50.920138888888886\n",
      "K-fold 2 : 50.954861111111114\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 50.98090277777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.24305555555556\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.736111111111114\n",
      "K-fold 4 : 51.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.80555555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932351979944441\n",
      "K-fold 1 : 0.6932024379571279\n",
      "K-fold 2 : 0.6932114150789049\n",
      "K-fold 3 : 0.6932128575113085\n",
      "K-fold 4 : 0.6932432247532738\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932023089864979\n",
      "K-fold 1 : 0.6931304335594177\n",
      "K-fold 2 : 0.6932074427604675\n",
      "K-fold 3 : 0.6930972182232401\n",
      "K-fold 4 : 0.6931019373562025\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929173363579644\n",
      "K-fold 1 : 0.693068081802792\n",
      "K-fold 2 : 0.6930037061373393\n",
      "K-fold 3 : 0.6930139899253845\n",
      "K-fold 4 : 0.6929576456546783\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931450911190199\n",
      "K-fold 1 : 0.6931241051010464\n",
      "K-fold 2 : 0.6930554016776707\n",
      "K-fold 3 : 0.6927071680193362\n",
      "K-fold 4 : 0.6928472467090773\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929758025252302\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.661458333333336\n",
      "K-fold 1 : 49.939236111111114\n",
      "K-fold 2 : 49.83506944444444\n",
      "K-fold 3 : 50.22569444444444\n",
      "K-fold 4 : 50.234375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.86805555555556\n",
      "K-fold 1 : 50.173611111111114\n",
      "K-fold 2 : 50.03472222222222\n",
      "K-fold 3 : 49.65277777777778\n",
      "K-fold 4 : 49.201388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.171875\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.86805555555556\n",
      "K-fold 1 : 50.173611111111114\n",
      "K-fold 2 : 50.03472222222222\n",
      "K-fold 3 : 50.34722222222222\n",
      "K-fold 4 : 50.798611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.44444444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933477540810903\n",
      "K-fold 1 : 0.6933169437779321\n",
      "K-fold 2 : 0.6931447539064619\n",
      "K-fold 3 : 0.6932878467771743\n",
      "K-fold 4 : 0.6931690990924835\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693096759526626\n",
      "K-fold 1 : 0.6932826638221741\n",
      "K-fold 2 : 0.6938338305639185\n",
      "K-fold 3 : 0.6932531776635543\n",
      "K-fold 4 : 0.6933834293614263\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930732799900903\n",
      "K-fold 1 : 0.6930634717146555\n",
      "K-fold 2 : 0.6930673711829716\n",
      "K-fold 3 : 0.693004145887163\n",
      "K-fold 4 : 0.6931152118576898\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693002972913825\n",
      "K-fold 1 : 0.693147185056106\n",
      "K-fold 2 : 0.6931469725525897\n",
      "K-fold 3 : 0.6931359197782434\n",
      "K-fold 4 : 0.6930724045504695\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6931010909702466\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.765625\n",
      "K-fold 1 : 50.74652777777778\n",
      "K-fold 2 : 50.286458333333336\n",
      "K-fold 3 : 49.77430555555556\n",
      "K-fold 4 : 50.39930555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.479166666666664\n",
      "K-fold 1 : 48.68055555555556\n",
      "K-fold 2 : 49.61805555555556\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 50.06944444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.345486111111114\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 50.92881944444444\n",
      "K-fold 3 : 50.677083333333336\n",
      "K-fold 4 : 50.90277777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 51.31944444444444\n",
      "K-fold 2 : 50.38194444444444\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 50.06944444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.666666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932108918825786\n",
      "K-fold 1 : 0.693103043238322\n",
      "K-fold 2 : 0.6932448890474108\n",
      "K-fold 3 : 0.693313142326143\n",
      "K-fold 4 : 0.6932128369808197\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934442364651224\n",
      "K-fold 1 : 0.6938102634056754\n",
      "K-fold 2 : 0.6932119001512942\n",
      "K-fold 3 : 0.6927825393884078\n",
      "K-fold 4 : 0.6933681057847064\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929330819182926\n",
      "K-fold 1 : 0.6930133097701603\n",
      "K-fold 2 : 0.6930250492360857\n",
      "K-fold 3 : 0.6931409974892934\n",
      "K-fold 4 : 0.6930486983723111\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930699348449707\n",
      "K-fold 1 : 0.692848669446033\n",
      "K-fold 2 : 0.6931140267330668\n",
      "K-fold 3 : 0.6927798390388489\n",
      "K-fold 4 : 0.6931287283482759\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929882396822391\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.17534722222222\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 50.217013888888886\n",
      "K-fold 3 : 50.26909722222222\n",
      "K-fold 4 : 50.607638888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.36805555555556\n",
      "K-fold 1 : 48.923611111111114\n",
      "K-fold 2 : 49.895833333333336\n",
      "K-fold 3 : 49.826388888888886\n",
      "K-fold 4 : 48.75\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.572916666666664\n",
      "K-fold 1 : 51.08506944444444\n",
      "K-fold 2 : 50.92881944444444\n",
      "K-fold 3 : 50.94618055555556\n",
      "K-fold 4 : 50.81597222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.63194444444444\n",
      "K-fold 1 : 51.076388888888886\n",
      "K-fold 2 : 50.104166666666664\n",
      "K-fold 3 : 50.173611111111114\n",
      "K-fold 4 : 51.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.84722222222222\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932727992534637\n",
      "K-fold 1 : 0.6931529376241896\n",
      "K-fold 2 : 0.6932348350683848\n",
      "K-fold 3 : 0.6931696818934546\n",
      "K-fold 4 : 0.6931508759657542\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931522333103678\n",
      "K-fold 1 : 0.6933951040972834\n",
      "K-fold 2 : 0.6931577117546744\n",
      "K-fold 3 : 0.6931606582973314\n",
      "K-fold 4 : 0.6938126579574917\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931583331690894\n",
      "K-fold 1 : 0.6929484109083811\n",
      "K-fold 2 : 0.6930220305919648\n",
      "K-fold 3 : 0.6930924541420407\n",
      "K-fold 4 : 0.6930690275298225\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927806164907373\n",
      "K-fold 1 : 0.6929662849592126\n",
      "K-fold 2 : 0.693141450052676\n",
      "K-fold 3 : 0.6931358549905859\n",
      "K-fold 4 : 0.6928482729455699\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929744958877564\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.390625\n",
      "K-fold 1 : 50.017361111111114\n",
      "K-fold 2 : 49.392361111111114\n",
      "K-fold 3 : 50.295138888888886\n",
      "K-fold 4 : 50.26909722222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.96527777777778\n",
      "K-fold 1 : 50.763888888888886\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.520833333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.067708333333336\n",
      "K-fold 1 : 50.85069444444444\n",
      "K-fold 2 : 50.876736111111114\n",
      "K-fold 3 : 50.61631944444444\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.03472222222222\n",
      "K-fold 1 : 50.763888888888886\n",
      "K-fold 2 : 50.24305555555556\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.520833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.41666666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932106779681312\n",
      "K-fold 1 : 0.6932145867082807\n",
      "K-fold 2 : 0.6931612326039208\n",
      "K-fold 3 : 0.6932573172781202\n",
      "K-fold 4 : 0.693204445971383\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931580823400746\n",
      "K-fold 1 : 0.6930336407993151\n",
      "K-fold 2 : 0.6938174004140107\n",
      "K-fold 3 : 0.6930841725805531\n",
      "K-fold 4 : 0.6930953989858213\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930709044138591\n",
      "K-fold 1 : 0.6930922355916765\n",
      "K-fold 2 : 0.6929584542910258\n",
      "K-fold 3 : 0.6930824531449212\n",
      "K-fold 4 : 0.6930977662404378\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693147185056106\n",
      "K-fold 1 : 0.6930135721745698\n",
      "K-fold 2 : 0.6930807621582694\n",
      "K-fold 3 : 0.6930790802706843\n",
      "K-fold 4 : 0.6930952720020128\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930831743323285\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.973958333333336\n",
      "K-fold 1 : 50.15625\n",
      "K-fold 2 : 49.83506944444444\n",
      "K-fold 3 : 50.260416666666664\n",
      "K-fold 4 : 49.91319444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.96527777777778\n",
      "K-fold 1 : 51.59722222222222\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 49.583333333333336\n",
      "K-fold 4 : 50.625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 50.55555555555556\n",
      "K-fold 2 : 50.94618055555556\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 50.97222222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.03472222222222\n",
      "K-fold 1 : 51.59722222222222\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 50.416666666666664\n",
      "K-fold 4 : 50.625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.59722222222222\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932340913348728\n",
      "K-fold 1 : 0.6932305143939124\n",
      "K-fold 2 : 0.6932464414172702\n",
      "K-fold 3 : 0.6931631644566854\n",
      "K-fold 4 : 0.6932271175914341\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931665280590886\n",
      "K-fold 1 : 0.6929552451423977\n",
      "K-fold 2 : 0.6931249706641488\n",
      "K-fold 3 : 0.6932120323181152\n",
      "K-fold 4 : 0.6929918035216953\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.692957646979226\n",
      "K-fold 1 : 0.693136618534724\n",
      "K-fold 2 : 0.6930920958518982\n",
      "K-fold 3 : 0.6929960012435913\n",
      "K-fold 4 : 0.6930692354838054\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931451066680576\n",
      "K-fold 1 : 0.6926406906998676\n",
      "K-fold 2 : 0.6931020487909731\n",
      "K-fold 3 : 0.6930251847142759\n",
      "K-fold 4 : 0.692991220432779\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929808502611907\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.24305555555556\n",
      "K-fold 1 : 50.47743055555556\n",
      "K-fold 2 : 48.70659722222222\n",
      "K-fold 3 : 49.973958333333336\n",
      "K-fold 4 : 49.748263888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.236111111111114\n",
      "K-fold 1 : 49.895833333333336\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 50.173611111111114\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.920138888888886\n",
      "K-fold 1 : 50.703125\n",
      "K-fold 2 : 50.651041666666664\n",
      "K-fold 3 : 50.807291666666664\n",
      "K-fold 4 : 51.189236111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.763888888888886\n",
      "K-fold 1 : 53.15972222222222\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 50.173611111111114\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.222222222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932347549332513\n",
      "K-fold 1 : 0.6932346065839131\n",
      "K-fold 2 : 0.6933193802833557\n",
      "K-fold 3 : 0.6932578994168176\n",
      "K-fold 4 : 0.6933021154668596\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934223511944646\n",
      "K-fold 1 : 0.6931880557018778\n",
      "K-fold 2 : 0.6931347613749297\n",
      "K-fold 3 : 0.693174862343332\n",
      "K-fold 4 : 0.69303072794624\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.692953097820282\n",
      "K-fold 1 : 0.6930588576528761\n",
      "K-fold 2 : 0.6930930515130361\n",
      "K-fold 3 : 0.6930094659328461\n",
      "K-fold 4 : 0.6929148601161109\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930914702622787\n",
      "K-fold 1 : 0.6931446246478868\n",
      "K-fold 2 : 0.6930995168893234\n",
      "K-fold 3 : 0.693142408910005\n",
      "K-fold 4 : 0.6928679683934087\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930691978205805\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.713541666666664\n",
      "K-fold 1 : 50.138888888888886\n",
      "K-fold 2 : 49.99131944444444\n",
      "K-fold 3 : 49.13194444444444\n",
      "K-fold 4 : 49.40972222222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.0625\n",
      "K-fold 1 : 49.375\n",
      "K-fold 2 : 49.548611111111114\n",
      "K-fold 3 : 48.40277777777778\n",
      "K-fold 4 : 48.958333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.755208333333336\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.71180555555556\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 50.625\n",
      "K-fold 2 : 50.451388888888886\n",
      "K-fold 3 : 51.59722222222222\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.93055555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932255592611101\n",
      "K-fold 1 : 0.6932024187511868\n",
      "K-fold 2 : 0.6931733157899644\n",
      "K-fold 3 : 0.693317727247874\n",
      "K-fold 4 : 0.6932350463337369\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934245798898779\n",
      "K-fold 1 : 0.6937293539876523\n",
      "K-fold 2 : 0.6931846115900122\n",
      "K-fold 3 : 0.6934646393941797\n",
      "K-fold 4 : 0.6931662766829781\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930150575107998\n",
      "K-fold 1 : 0.6929647061559889\n",
      "K-fold 2 : 0.6930159992641873\n",
      "K-fold 3 : 0.6930800292227003\n",
      "K-fold 4 : 0.6930472903781467\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929995884066042\n",
      "K-fold 1 : 0.6930143496264582\n",
      "K-fold 2 : 0.6931285106617472\n",
      "K-fold 3 : 0.6925186514854431\n",
      "K-fold 4 : 0.6929535347482433\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929229269856992\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 93.15104166666667\n",
      "K-fold 1 : 92.77777777777777\n",
      "K-fold 2 : 71.10243055555556\n",
      "K-fold 3 : 87.38715277777777\n",
      "K-fold 4 : 94.27083333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 93.05555555555556\n",
      "K-fold 1 : 93.64583333333333\n",
      "K-fold 2 : 66.14583333333333\n",
      "K-fold 3 : 86.38888888888889\n",
      "K-fold 4 : 94.61805555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.15104166666667\n",
      "K-fold 1 : 93.88020833333333\n",
      "K-fold 2 : 74.51388888888889\n",
      "K-fold 3 : 88.18576388888889\n",
      "K-fold 4 : 94.27083333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.40277777777777\n",
      "K-fold 1 : 93.64583333333333\n",
      "K-fold 2 : 83.75\n",
      "K-fold 3 : 90.0\n",
      "K-fold 4 : 94.61805555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 91.08333333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.24188255005412632\n",
      "K-fold 1 : 0.26470193117856977\n",
      "K-fold 2 : 0.44550766481293574\n",
      "K-fold 3 : 0.3364033281803131\n",
      "K-fold 4 : 0.2647591499818696\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.23917237053746762\n",
      "K-fold 1 : 0.28154482271360315\n",
      "K-fold 2 : 0.4471784013768901\n",
      "K-fold 3 : 0.342978338184564\n",
      "K-fold 4 : 0.25366688746473065\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2396389577123854\n",
      "K-fold 1 : 0.25623498376872805\n",
      "K-fold 2 : 0.4453106618589825\n",
      "K-fold 3 : 0.3314090425769488\n",
      "K-fold 4 : 0.2647591499818696\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2340749301340269\n",
      "K-fold 1 : 0.27927183845768805\n",
      "K-fold 2 : 0.4435115521368773\n",
      "K-fold 3 : 0.33399153792339825\n",
      "K-fold 4 : 0.25366688746473065\n",
      "---------------------------------\n",
      "Average best validation loss: 0.3089033492233442\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 58.81944444444444\n",
      "K-fold 2 : 49.861111111111114\n",
      "K-fold 3 : 69.16666666666667\n",
      "K-fold 4 : 95.78993055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.11111111111111\n",
      "K-fold 1 : 58.40277777777778\n",
      "K-fold 2 : 50.27777777777778\n",
      "K-fold 3 : 85.3125\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 58.854166666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 71.23263888888889\n",
      "K-fold 4 : 95.79861111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.11111111111111\n",
      "K-fold 1 : 58.40277777777778\n",
      "K-fold 2 : 50.27777777777778\n",
      "K-fold 3 : 85.72916666666667\n",
      "K-fold 4 : 96.04166666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 77.3125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.182917836556832\n",
      "K-fold 1 : 0.6311174564891391\n",
      "K-fold 2 : 0.6940904988182915\n",
      "K-fold 3 : 0.4756482395860884\n",
      "K-fold 4 : 0.18189621691902477\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17183121261389359\n",
      "K-fold 1 : 0.6315573298412821\n",
      "K-fold 2 : 0.6931400817373524\n",
      "K-fold 3 : 0.48749910489372583\n",
      "K-fold 4 : 0.17453390262697055\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17584794155425496\n",
      "K-fold 1 : 0.6303161872757805\n",
      "K-fold 2 : 0.6931222809685601\n",
      "K-fold 3 : 0.4732513080040614\n",
      "K-fold 4 : 0.1793556582596567\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15861366073722424\n",
      "K-fold 1 : 0.6302442706149557\n",
      "K-fold 2 : 0.6931388870529507\n",
      "K-fold 3 : 0.4787780188995859\n",
      "K-fold 4 : 0.16874131301174994\n",
      "---------------------------------\n",
      "Average best validation loss: 0.42590323006329334\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 93.18576388888889\n",
      "K-fold 1 : 77.54340277777777\n",
      "K-fold 2 : 95.57291666666667\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 92.12673611111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 94.86111111111111\n",
      "K-fold 1 : 77.15277777777777\n",
      "K-fold 2 : 96.18055555555556\n",
      "K-fold 3 : 95.34722222222223\n",
      "K-fold 4 : 94.0625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.515625\n",
      "K-fold 1 : 78.10763888888889\n",
      "K-fold 2 : 95.69444444444444\n",
      "K-fold 3 : 95.94618055555556\n",
      "K-fold 4 : 94.08854166666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 94.86111111111111\n",
      "K-fold 1 : 80.55555555555556\n",
      "K-fold 2 : 96.18055555555556\n",
      "K-fold 3 : 95.34722222222223\n",
      "K-fold 4 : 94.51388888888889\n",
      "---------------------------------\n",
      "Average best validation accuracy: 92.29166666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.26194839576880136\n",
      "K-fold 1 : 0.43402449819776745\n",
      "K-fold 2 : 0.19276305023166868\n",
      "K-fold 3 : 0.17792786781986555\n",
      "K-fold 4 : 0.2512188824514548\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2418603054855181\n",
      "K-fold 1 : 0.4359576831693235\n",
      "K-fold 2 : 0.1699071273855541\n",
      "K-fold 3 : 0.1937473422807196\n",
      "K-fold 4 : 0.25715072453022003\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2580986724959479\n",
      "K-fold 1 : 0.43402449819776745\n",
      "K-fold 2 : 0.18782892343070773\n",
      "K-fold 3 : 0.17792786781986555\n",
      "K-fold 4 : 0.24887530240747663\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.23777314502259958\n",
      "K-fold 1 : 0.4282662104005399\n",
      "K-fold 2 : 0.16811247834044954\n",
      "K-fold 3 : 0.1867226452931114\n",
      "K-fold 4 : 0.24744904235653256\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2536647042826466\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.52951388888889\n",
      "K-fold 1 : 96.02430555555556\n",
      "K-fold 2 : 95.859375\n",
      "K-fold 3 : 49.49652777777778\n",
      "K-fold 4 : 89.81770833333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.63194444444444\n",
      "K-fold 1 : 95.13888888888889\n",
      "K-fold 2 : 95.69444444444444\n",
      "K-fold 3 : 50.55555555555556\n",
      "K-fold 4 : 90.24305555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.65104166666667\n",
      "K-fold 1 : 96.02430555555556\n",
      "K-fold 2 : 95.88541666666667\n",
      "K-fold 3 : 51.02430555555556\n",
      "K-fold 4 : 90.15625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.63194444444444\n",
      "K-fold 1 : 95.13888888888889\n",
      "K-fold 2 : 95.69444444444444\n",
      "K-fold 3 : 50.55555555555556\n",
      "K-fold 4 : 90.24305555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 85.65277777777777\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17890086037417252\n",
      "K-fold 1 : 0.16805106980933082\n",
      "K-fold 2 : 0.17090283549494215\n",
      "K-fold 3 : 0.6937337126996782\n",
      "K-fold 4 : 0.25758673714266883\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1587023679976878\n",
      "K-fold 1 : 0.19287675100824106\n",
      "K-fold 2 : 0.1774670177179834\n",
      "K-fold 3 : 0.6931300007778666\n",
      "K-fold 4 : 0.2598429011261981\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1759573264254464\n",
      "K-fold 1 : 0.1663239365650548\n",
      "K-fold 2 : 0.17034768118626542\n",
      "K-fold 3 : 0.6931851201587254\n",
      "K-fold 4 : 0.2556516102618641\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.14541042563707932\n",
      "K-fold 1 : 0.1897786852458249\n",
      "K-fold 2 : 0.170736958961124\n",
      "K-fold 3 : 0.6931082191674606\n",
      "K-fold 4 : 0.2482355165740718\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2894539611171121\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.65104166666667\n",
      "K-fold 1 : 95.65972222222223\n",
      "K-fold 2 : 94.33159722222223\n",
      "K-fold 3 : 95.81597222222223\n",
      "K-fold 4 : 95.56423611111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.59027777777777\n",
      "K-fold 2 : 93.50694444444444\n",
      "K-fold 3 : 94.89583333333333\n",
      "K-fold 4 : 95.76388888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.77256944444444\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 94.51388888888889\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.78125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 95.59027777777777\n",
      "K-fold 2 : 95.27777777777777\n",
      "K-fold 3 : 95.41666666666667\n",
      "K-fold 4 : 96.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.66666666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.19152805647916263\n",
      "K-fold 1 : 0.18323330233494442\n",
      "K-fold 2 : 0.21413756824202007\n",
      "K-fold 3 : 0.18386465716693137\n",
      "K-fold 4 : 0.1921895234949059\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17640110105276108\n",
      "K-fold 1 : 0.19746221342812414\n",
      "K-fold 2 : 0.2146609516247459\n",
      "K-fold 3 : 0.19212675548118094\n",
      "K-fold 4 : 0.18659085035324097\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18279165758026972\n",
      "K-fold 1 : 0.1815767974489265\n",
      "K-fold 2 : 0.21013902260197534\n",
      "K-fold 3 : 0.1809237921403514\n",
      "K-fold 4 : 0.18522416485680473\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16926643252372742\n",
      "K-fold 1 : 0.18939464992803076\n",
      "K-fold 2 : 0.19542418290739474\n",
      "K-fold 3 : 0.19017631204231925\n",
      "K-fold 4 : 0.17376392205124316\n",
      "---------------------------------\n",
      "Average best validation loss: 0.18360509989054305\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 71.08506944444444\n",
      "K-fold 2 : 94.16666666666667\n",
      "K-fold 3 : 95.77256944444444\n",
      "K-fold 4 : 95.33854166666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.17361111111111\n",
      "K-fold 1 : 72.01388888888889\n",
      "K-fold 2 : 94.58333333333333\n",
      "K-fold 3 : 96.00694444444444\n",
      "K-fold 4 : 95.17361111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.90277777777777\n",
      "K-fold 1 : 71.29340277777777\n",
      "K-fold 2 : 94.27951388888889\n",
      "K-fold 3 : 95.80729166666667\n",
      "K-fold 4 : 95.72916666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.59027777777777\n",
      "K-fold 1 : 72.01388888888889\n",
      "K-fold 2 : 94.58333333333333\n",
      "K-fold 3 : 96.00694444444444\n",
      "K-fold 4 : 96.21527777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 90.88194444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17568890526890754\n",
      "K-fold 1 : 0.5219688180420133\n",
      "K-fold 2 : 0.2084612126979563\n",
      "K-fold 3 : 0.18289151390393574\n",
      "K-fold 4 : 0.19356669824984338\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.18762374604525772\n",
      "K-fold 1 : 0.5063989058784817\n",
      "K-fold 2 : 0.19264184618773667\n",
      "K-fold 3 : 0.18530291772407034\n",
      "K-fold 4 : 0.17565879193337067\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17217008297642072\n",
      "K-fold 1 : 0.5185258583890067\n",
      "K-fold 2 : 0.2084612126979563\n",
      "K-fold 3 : 0.18017402088476553\n",
      "K-fold 4 : 0.1814629818002383\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17969149059575537\n",
      "K-fold 1 : 0.5011520787425663\n",
      "K-fold 2 : 0.19264184618773667\n",
      "K-fold 3 : 0.16958227138156476\n",
      "K-fold 4 : 0.1612317354782768\n",
      "---------------------------------\n",
      "Average best validation loss: 0.24085988447717996\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 95.77256944444444\n",
      "K-fold 2 : 93.15104166666667\n",
      "K-fold 3 : 95.703125\n",
      "K-fold 4 : 95.72916666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.52083333333333\n",
      "K-fold 2 : 93.92361111111111\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.69444444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.87673611111111\n",
      "K-fold 2 : 93.71527777777777\n",
      "K-fold 3 : 95.82465277777777\n",
      "K-fold 4 : 95.86805555555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.65972222222223\n",
      "K-fold 2 : 93.92361111111111\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.72916666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.41666666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1854889972342385\n",
      "K-fold 1 : 0.18025147534079022\n",
      "K-fold 2 : 0.262906216416094\n",
      "K-fold 3 : 0.18870565911961926\n",
      "K-fold 4 : 0.1869300686650806\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19484612863996756\n",
      "K-fold 1 : 0.19066930465076282\n",
      "K-fold 2 : 0.26739888735439465\n",
      "K-fold 3 : 0.17923083577467047\n",
      "K-fold 4 : 0.1859790303784868\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1824853224058946\n",
      "K-fold 1 : 0.17654130028353798\n",
      "K-fold 2 : 0.2585595379273097\n",
      "K-fold 3 : 0.18176050873266325\n",
      "K-fold 4 : 0.1814045459859901\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17789561204288318\n",
      "K-fold 1 : 0.1813435146342153\n",
      "K-fold 2 : 0.2580332347880239\n",
      "K-fold 3 : 0.17058293003103006\n",
      "K-fold 4 : 0.18318484432023505\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1942080271632775\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.72916666666667\n",
      "K-fold 1 : 91.60590277777777\n",
      "K-fold 2 : 95.72048611111111\n",
      "K-fold 3 : 93.77604166666667\n",
      "K-fold 4 : 95.72048611111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.00694444444444\n",
      "K-fold 1 : 91.70138888888889\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 94.23611111111111\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.79861111111111\n",
      "K-fold 1 : 91.70138888888889\n",
      "K-fold 2 : 95.78993055555556\n",
      "K-fold 3 : 94.38368055555556\n",
      "K-fold 4 : 95.85069444444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.00694444444444\n",
      "K-fold 1 : 91.70138888888889\n",
      "K-fold 2 : 96.07638888888889\n",
      "K-fold 3 : 94.23611111111111\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.77083333333331\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18025809683733515\n",
      "K-fold 1 : 0.259752082824707\n",
      "K-fold 2 : 0.1814436441494359\n",
      "K-fold 3 : 0.23042718329363399\n",
      "K-fold 4 : 0.18125821778343784\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1748752192310665\n",
      "K-fold 1 : 0.2646167692930802\n",
      "K-fold 2 : 0.16651004552841187\n",
      "K-fold 3 : 0.21865530668393426\n",
      "K-fold 4 : 0.18019243750883185\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17972115191320578\n",
      "K-fold 1 : 0.25830333216322793\n",
      "K-fold 2 : 0.17734627810617287\n",
      "K-fold 3 : 0.20761040821671486\n",
      "K-fold 4 : 0.17525657663742703\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16559138861687286\n",
      "K-fold 1 : 0.2612610867489939\n",
      "K-fold 2 : 0.16260073495947797\n",
      "K-fold 3 : 0.20661303303811862\n",
      "K-fold 4 : 0.17321915956942932\n",
      "---------------------------------\n",
      "Average best validation loss: 0.19385708058657852\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.67361111111111\n",
      "K-fold 1 : 67.93402777777777\n",
      "K-fold 2 : 94.09722222222223\n",
      "K-fold 3 : 90.59027777777777\n",
      "K-fold 4 : 68.10763888888889\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 93.19444444444444\n",
      "K-fold 1 : 77.56944444444444\n",
      "K-fold 2 : 93.54166666666667\n",
      "K-fold 3 : 93.50694444444444\n",
      "K-fold 4 : 66.38888888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 92.67361111111111\n",
      "K-fold 1 : 72.82986111111111\n",
      "K-fold 2 : 94.49652777777777\n",
      "K-fold 3 : 90.88541666666667\n",
      "K-fold 4 : 70.9375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 94.75694444444444\n",
      "K-fold 1 : 87.08333333333333\n",
      "K-fold 2 : 93.54166666666667\n",
      "K-fold 3 : 93.50694444444444\n",
      "K-fold 4 : 86.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 91.02777777777779\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.28903610987795725\n",
      "K-fold 1 : 0.46336542864640556\n",
      "K-fold 2 : 0.2757909546295802\n",
      "K-fold 3 : 0.36070751481586033\n",
      "K-fold 4 : 0.46506901217831503\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2888195566509081\n",
      "K-fold 1 : 0.48111493302428204\n",
      "K-fold 2 : 0.3039164510758027\n",
      "K-fold 3 : 0.3427181833464166\n",
      "K-fold 4 : 0.46097069589988043\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.28903610987795725\n",
      "K-fold 1 : 0.46180216703150007\n",
      "K-fold 2 : 0.269524604247676\n",
      "K-fold 3 : 0.3549771171477106\n",
      "K-fold 4 : 0.4636322882440355\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2744784672623095\n",
      "K-fold 1 : 0.46667075934617414\n",
      "K-fold 2 : 0.28021683122800745\n",
      "K-fold 3 : 0.33632206333720166\n",
      "K-fold 4 : 0.45882822637972626\n",
      "---------------------------------\n",
      "Average best validation loss: 0.3633032695106838\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.078125\n",
      "K-fold 1 : 95.81597222222223\n",
      "K-fold 2 : 49.401041666666664\n",
      "K-fold 3 : 49.09722222222222\n",
      "K-fold 4 : 49.791666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.576388888888886\n",
      "K-fold 1 : 95.52083333333333\n",
      "K-fold 2 : 49.826388888888886\n",
      "K-fold 3 : 50.138888888888886\n",
      "K-fold 4 : 48.75\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.20659722222222\n",
      "K-fold 1 : 95.92881944444444\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 51.197916666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.423611111111114\n",
      "K-fold 1 : 95.52083333333333\n",
      "K-fold 2 : 50.173611111111114\n",
      "K-fold 3 : 50.138888888888886\n",
      "K-fold 4 : 51.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.70138888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934165378411611\n",
      "K-fold 1 : 0.18734852696458498\n",
      "K-fold 2 : 0.6936241547266643\n",
      "K-fold 3 : 0.6940331551763746\n",
      "K-fold 4 : 0.6935223744975196\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.69345063748567\n",
      "K-fold 1 : 0.18820376078719678\n",
      "K-fold 2 : 0.6937411116517108\n",
      "K-fold 3 : 0.693290000376494\n",
      "K-fold 4 : 0.6941112798193226\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931639201111264\n",
      "K-fold 1 : 0.17953258785936568\n",
      "K-fold 2 : 0.6931093083487616\n",
      "K-fold 3 : 0.6931313514709473\n",
      "K-fold 4 : 0.6930476122432285\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6921969678090967\n",
      "K-fold 1 : 0.1838796363900537\n",
      "K-fold 2 : 0.6931369226911793\n",
      "K-fold 3 : 0.6931414008140564\n",
      "K-fold 4 : 0.6928239464759827\n",
      "---------------------------------\n",
      "Average best validation loss: 0.5910357748360737\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 94.53993055555556\n",
      "K-fold 1 : 92.5\n",
      "K-fold 2 : 93.69791666666667\n",
      "K-fold 3 : 94.80902777777777\n",
      "K-fold 4 : 94.32291666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 94.47916666666667\n",
      "K-fold 1 : 94.54861111111111\n",
      "K-fold 2 : 93.85416666666667\n",
      "K-fold 3 : 96.14583333333333\n",
      "K-fold 4 : 95.625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 94.69618055555556\n",
      "K-fold 1 : 93.49826388888889\n",
      "K-fold 2 : 93.88888888888889\n",
      "K-fold 3 : 95.25173611111111\n",
      "K-fold 4 : 94.85243055555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 94.47916666666667\n",
      "K-fold 1 : 94.54861111111111\n",
      "K-fold 2 : 94.54861111111111\n",
      "K-fold 3 : 96.14583333333333\n",
      "K-fold 4 : 95.625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.06944444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.269604040020042\n",
      "K-fold 1 : 0.28517687171697614\n",
      "K-fold 2 : 0.2431711968448427\n",
      "K-fold 3 : 0.2324686528907882\n",
      "K-fold 4 : 0.23975632571511798\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2675078925879105\n",
      "K-fold 1 : 0.28725700080394745\n",
      "K-fold 2 : 0.2341447265251823\n",
      "K-fold 3 : 0.2246474941139636\n",
      "K-fold 4 : 0.23538783581360526\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2682075634598732\n",
      "K-fold 1 : 0.27565872139400904\n",
      "K-fold 2 : 0.24191138926479552\n",
      "K-fold 3 : 0.22680608050690756\n",
      "K-fold 4 : 0.23376036567820443\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.26708683565906854\n",
      "K-fold 1 : 0.26423280783321546\n",
      "K-fold 2 : 0.2266642081996669\n",
      "K-fold 3 : 0.21598035939361737\n",
      "K-fold 4 : 0.22803387628949207\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2403996174750121\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.83506944444444\n",
      "K-fold 1 : 49.87847222222222\n",
      "K-fold 2 : 50.138888888888886\n",
      "K-fold 3 : 49.279513888888886\n",
      "K-fold 4 : 92.13541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.576388888888886\n",
      "K-fold 1 : 50.798611111111114\n",
      "K-fold 2 : 49.548611111111114\n",
      "K-fold 3 : 50.173611111111114\n",
      "K-fold 4 : 92.22222222222223\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.032986111111114\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 50.954861111111114\n",
      "K-fold 4 : 92.36111111111111\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.423611111111114\n",
      "K-fold 1 : 51.979166666666664\n",
      "K-fold 2 : 50.34722222222222\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 92.53472222222223\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.29861111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6957111967934503\n",
      "K-fold 1 : 0.6949807001484765\n",
      "K-fold 2 : 0.6961801628271739\n",
      "K-fold 3 : 0.6937900443871816\n",
      "K-fold 4 : 0.2619570869538519\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6939751479936682\n",
      "K-fold 1 : 0.6933263877163762\n",
      "K-fold 2 : 0.6961987873782283\n",
      "K-fold 3 : 0.6934049414551776\n",
      "K-fold 4 : 0.2629830526269\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693299427959654\n",
      "K-fold 1 : 0.6931353602144453\n",
      "K-fold 2 : 0.6932193067338731\n",
      "K-fold 3 : 0.6931885911358727\n",
      "K-fold 4 : 0.2536224553982417\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928481407787489\n",
      "K-fold 1 : 0.6930155572683915\n",
      "K-fold 2 : 0.6931136820627295\n",
      "K-fold 3 : 0.6930943468342656\n",
      "K-fold 4 : 0.2489550249732059\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6042053503834682\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.86458333333333\n",
      "K-fold 1 : 94.35763888888889\n",
      "K-fold 2 : 93.76736111111111\n",
      "K-fold 3 : 94.47048611111111\n",
      "K-fold 4 : 93.14236111111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 91.31944444444444\n",
      "K-fold 1 : 94.61805555555556\n",
      "K-fold 2 : 93.78472222222223\n",
      "K-fold 3 : 92.91666666666667\n",
      "K-fold 4 : 94.72222222222223\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 92.98611111111111\n",
      "K-fold 1 : 94.51388888888889\n",
      "K-fold 2 : 94.27083333333333\n",
      "K-fold 3 : 95.14756944444444\n",
      "K-fold 4 : 93.87152777777777\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.05555555555556\n",
      "K-fold 1 : 94.61805555555556\n",
      "K-fold 2 : 95.17361111111111\n",
      "K-fold 3 : 96.00694444444444\n",
      "K-fold 4 : 94.72222222222223\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.71527777777779\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.25845203002293904\n",
      "K-fold 1 : 0.23286017146375443\n",
      "K-fold 2 : 0.24005597051646974\n",
      "K-fold 3 : 0.24410540229744382\n",
      "K-fold 4 : 0.2898848555154271\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.28697996748530347\n",
      "K-fold 1 : 0.22701508584229843\n",
      "K-fold 2 : 0.2388360215270001\n",
      "K-fold 3 : 0.2528189427178839\n",
      "K-fold 4 : 0.2722753856493079\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2566795241501596\n",
      "K-fold 1 : 0.2269655997554461\n",
      "K-fold 2 : 0.23506570375627941\n",
      "K-fold 3 : 0.23196207682291667\n",
      "K-fold 4 : 0.2835493996739388\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.26041805355445197\n",
      "K-fold 1 : 0.2171428514563519\n",
      "K-fold 2 : 0.230061416392741\n",
      "K-fold 3 : 0.21723255223554114\n",
      "K-fold 4 : 0.26596066031766974\n",
      "---------------------------------\n",
      "Average best validation loss: 0.23816310679135116\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.60069444444444\n",
      "K-fold 1 : 49.670138888888886\n",
      "K-fold 2 : 48.967013888888886\n",
      "K-fold 3 : 49.93055555555556\n",
      "K-fold 4 : 49.69618055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 49.30555555555556\n",
      "K-fold 2 : 50.173611111111114\n",
      "K-fold 3 : 50.0\n",
      "K-fold 4 : 48.854166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.18055555555556\n",
      "K-fold 2 : 51.29340277777778\n",
      "K-fold 3 : 51.05902777777778\n",
      "K-fold 4 : 51.032986111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.28472222222222\n",
      "K-fold 1 : 51.458333333333336\n",
      "K-fold 2 : 51.423611111111114\n",
      "K-fold 3 : 50.0\n",
      "K-fold 4 : 51.52777777777778\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.13888888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935345437791612\n",
      "K-fold 1 : 0.6934494919247097\n",
      "K-fold 2 : 0.6950596425268385\n",
      "K-fold 3 : 0.6935385704040528\n",
      "K-fold 4 : 0.6936161730024549\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929422824279122\n",
      "K-fold 1 : 0.6933256258135256\n",
      "K-fold 2 : 0.6931647399197454\n",
      "K-fold 3 : 0.6934183369512144\n",
      "K-fold 4 : 0.6934874861136727\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932751946979099\n",
      "K-fold 1 : 0.6930546508895026\n",
      "K-fold 2 : 0.6932603869173262\n",
      "K-fold 3 : 0.6932262705432044\n",
      "K-fold 4 : 0.6932779557175106\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927903942439867\n",
      "K-fold 1 : 0.692903793376425\n",
      "K-fold 2 : 0.6930138909298441\n",
      "K-fold 3 : 0.6930960287218508\n",
      "K-fold 4 : 0.6929884241974872\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929585062939188\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 94.50520833333333\n",
      "K-fold 1 : 91.796875\n",
      "K-fold 2 : 94.15798611111111\n",
      "K-fold 3 : 93.11631944444444\n",
      "K-fold 4 : 93.14236111111111\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.06944444444444\n",
      "K-fold 1 : 91.875\n",
      "K-fold 2 : 94.09722222222223\n",
      "K-fold 3 : 93.57638888888889\n",
      "K-fold 4 : 91.21527777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.48611111111111\n",
      "K-fold 1 : 92.22222222222223\n",
      "K-fold 2 : 94.98263888888889\n",
      "K-fold 3 : 93.68923611111111\n",
      "K-fold 4 : 93.58506944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.65972222222223\n",
      "K-fold 1 : 95.0\n",
      "K-fold 2 : 95.72916666666667\n",
      "K-fold 3 : 94.02777777777777\n",
      "K-fold 4 : 94.20138888888889\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.92361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.22989624655909008\n",
      "K-fold 1 : 0.2861328427990278\n",
      "K-fold 2 : 0.23559521875447698\n",
      "K-fold 3 : 0.2744964647624228\n",
      "K-fold 4 : 0.25950947238339317\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.22276009748811307\n",
      "K-fold 1 : 0.26786286869774695\n",
      "K-fold 2 : 0.23512264438297437\n",
      "K-fold 3 : 0.27776784482209577\n",
      "K-fold 4 : 0.2662849167118902\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.21339160799980164\n",
      "K-fold 1 : 0.2796054830153783\n",
      "K-fold 2 : 0.2254867571923468\n",
      "K-fold 3 : 0.27017456574572457\n",
      "K-fold 4 : 0.25316210918956333\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.20999843789183575\n",
      "K-fold 1 : 0.26315665180268494\n",
      "K-fold 2 : 0.2198451912921408\n",
      "K-fold 3 : 0.2641857130372006\n",
      "K-fold 4 : 0.24961108617160632\n",
      "---------------------------------\n",
      "Average best validation loss: 0.24135941603909367\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.947916666666664\n",
      "K-fold 1 : 95.859375\n",
      "K-fold 2 : 50.598958333333336\n",
      "K-fold 3 : 95.78993055555556\n",
      "K-fold 4 : 49.895833333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.00694444444444\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 50.34722222222222\n",
      "K-fold 3 : 95.83333333333333\n",
      "K-fold 4 : 49.93055555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 95.87673611111111\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 95.85069444444444\n",
      "K-fold 4 : 51.24131944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 54.72222222222222\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 52.25694444444444\n",
      "K-fold 3 : 95.83333333333333\n",
      "K-fold 4 : 51.458333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 69.99999999999999\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6950962543487549\n",
      "K-fold 1 : 0.18315281826588842\n",
      "K-fold 2 : 0.695647515853246\n",
      "K-fold 3 : 0.18565214052796364\n",
      "K-fold 4 : 0.6993487225638495\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928040385246277\n",
      "K-fold 1 : 0.18959768569987753\n",
      "K-fold 2 : 0.6931388844614443\n",
      "K-fold 3 : 0.18866970875988837\n",
      "K-fold 4 : 0.6934060247048087\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931345456176334\n",
      "K-fold 1 : 0.18150420602824952\n",
      "K-fold 2 : 0.693252823750178\n",
      "K-fold 3 : 0.1817866015765402\n",
      "K-fold 4 : 0.6930393788549635\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.684041836987371\n",
      "K-fold 1 : 0.18445600860792657\n",
      "K-fold 2 : 0.6929200343463732\n",
      "K-fold 3 : 0.1786809706169626\n",
      "K-fold 4 : 0.6930058339367742\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4866209368990814\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.390625\n",
      "K-fold 1 : 49.895833333333336\n",
      "K-fold 2 : 50.73784722222222\n",
      "K-fold 3 : 49.87847222222222\n",
      "K-fold 4 : 50.060763888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.6875\n",
      "K-fold 1 : 49.583333333333336\n",
      "K-fold 2 : 49.72222222222222\n",
      "K-fold 3 : 49.375\n",
      "K-fold 4 : 49.65277777777778\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.92881944444444\n",
      "K-fold 1 : 50.989583333333336\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 50.885416666666664\n",
      "K-fold 4 : 50.954861111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.416666666666664\n",
      "K-fold 1 : 52.326388888888886\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.32638888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6945970800187853\n",
      "K-fold 1 : 0.6944730089770423\n",
      "K-fold 2 : 0.6934972935252719\n",
      "K-fold 3 : 0.6936677912871043\n",
      "K-fold 4 : 0.6939438740412395\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693822979927063\n",
      "K-fold 1 : 0.6932373798411825\n",
      "K-fold 2 : 0.6946634365164716\n",
      "K-fold 3 : 0.6938409494317096\n",
      "K-fold 4 : 0.6932530403137207\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931192437807719\n",
      "K-fold 1 : 0.6932324104838901\n",
      "K-fold 2 : 0.6933730403582256\n",
      "K-fold 3 : 0.6933160808351305\n",
      "K-fold 4 : 0.6933104362752702\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930286625157231\n",
      "K-fold 1 : 0.6927324274311895\n",
      "K-fold 2 : 0.6929979713066764\n",
      "K-fold 3 : 0.6929942913677382\n",
      "K-fold 4 : 0.6930019855499268\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929510676342507\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.93055555555556\n",
      "K-fold 1 : 49.96527777777778\n",
      "K-fold 2 : 51.28472222222222\n",
      "K-fold 3 : 49.765625\n",
      "K-fold 4 : 50.46006944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.611111111111114\n",
      "K-fold 1 : 49.30555555555556\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 48.09027777777778\n",
      "K-fold 4 : 49.6875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.954861111111114\n",
      "K-fold 1 : 51.12847222222222\n",
      "K-fold 2 : 51.28472222222222\n",
      "K-fold 3 : 51.310763888888886\n",
      "K-fold 4 : 51.05034722222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.388888888888886\n",
      "K-fold 1 : 50.69444444444444\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.90972222222222\n",
      "K-fold 4 : 50.3125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.98611111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937421222527822\n",
      "K-fold 1 : 0.6933776471349928\n",
      "K-fold 2 : 0.6939632058143616\n",
      "K-fold 3 : 0.6936331199275123\n",
      "K-fold 4 : 0.6934090614318847\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6939106298529584\n",
      "K-fold 1 : 0.6933525619299515\n",
      "K-fold 2 : 0.693337795527085\n",
      "K-fold 3 : 0.6940506644870924\n",
      "K-fold 4 : 0.694925087949504\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931080102920533\n",
      "K-fold 1 : 0.6931422942214542\n",
      "K-fold 2 : 0.6931394583649105\n",
      "K-fold 3 : 0.6932460288206737\n",
      "K-fold 4 : 0.6931323687235514\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692700567452804\n",
      "K-fold 1 : 0.6930354807687842\n",
      "K-fold 2 : 0.6931019788203032\n",
      "K-fold 3 : 0.692423517289369\n",
      "K-fold 4 : 0.6931241258330967\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928771340328714\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.635416666666664\n",
      "K-fold 1 : 50.217013888888886\n",
      "K-fold 2 : 49.61805555555556\n",
      "K-fold 3 : 50.078125\n",
      "K-fold 4 : 49.704861111111114\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.895833333333336\n",
      "K-fold 1 : 49.166666666666664\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 49.513888888888886\n",
      "K-fold 4 : 49.826388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.24131944444444\n",
      "K-fold 1 : 51.432291666666664\n",
      "K-fold 2 : 50.73784722222222\n",
      "K-fold 3 : 51.145833333333336\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.53472222222222\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 52.291666666666664\n",
      "K-fold 3 : 51.63194444444444\n",
      "K-fold 4 : 51.59722222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.791666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6941112538178762\n",
      "K-fold 1 : 0.6940369367599487\n",
      "K-fold 2 : 0.6936077541775174\n",
      "K-fold 3 : 0.693431693315506\n",
      "K-fold 4 : 0.6939060045613183\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932427468507186\n",
      "K-fold 1 : 0.6933630886285201\n",
      "K-fold 2 : 0.6931861042976379\n",
      "K-fold 3 : 0.6933317080787991\n",
      "K-fold 4 : 0.693389918493188\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932554317845239\n",
      "K-fold 1 : 0.6931350754366981\n",
      "K-fold 2 : 0.6933533132076264\n",
      "K-fold 3 : 0.6931874348057641\n",
      "K-fold 4 : 0.6933358861340417\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927085752072542\n",
      "K-fold 1 : 0.6930548781933992\n",
      "K-fold 2 : 0.6927161320396091\n",
      "K-fold 3 : 0.6928473607353542\n",
      "K-fold 4 : 0.6930374606795933\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692872881371042\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.982638888888886\n",
      "K-fold 1 : 49.80902777777778\n",
      "K-fold 2 : 50.052083333333336\n",
      "K-fold 3 : 49.453125\n",
      "K-fold 4 : 49.84375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.93055555555556\n",
      "K-fold 1 : 49.65277777777778\n",
      "K-fold 2 : 50.763888888888886\n",
      "K-fold 3 : 49.44444444444444\n",
      "K-fold 4 : 49.513888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.267361111111114\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 51.354166666666664\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 51.40625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.625\n",
      "K-fold 1 : 50.486111111111114\n",
      "K-fold 2 : 51.00694444444444\n",
      "K-fold 3 : 50.55555555555556\n",
      "K-fold 4 : 50.486111111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.63194444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693637717432446\n",
      "K-fold 1 : 0.6935279462072584\n",
      "K-fold 2 : 0.6936767280101777\n",
      "K-fold 3 : 0.6941624952687158\n",
      "K-fold 4 : 0.6937303198708429\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934419248415076\n",
      "K-fold 1 : 0.6937393934830375\n",
      "K-fold 2 : 0.6930128828338955\n",
      "K-fold 3 : 0.6932844519615173\n",
      "K-fold 4 : 0.6932774704435597\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932437227831947\n",
      "K-fold 1 : 0.6930989974074894\n",
      "K-fold 2 : 0.693149118953281\n",
      "K-fold 3 : 0.6932332548830245\n",
      "K-fold 4 : 0.6931689977645874\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693139021811278\n",
      "K-fold 1 : 0.6929444152375926\n",
      "K-fold 2 : 0.6929689386616582\n",
      "K-fold 3 : 0.6930993691734646\n",
      "K-fold 4 : 0.693128624688024\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930560739144036\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.69444444444444\n",
      "K-fold 1 : 49.939236111111114\n",
      "K-fold 2 : 49.49652777777778\n",
      "K-fold 3 : 50.27777777777778\n",
      "K-fold 4 : 49.99131944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.111111111111114\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 50.173611111111114\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 50.34722222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.032986111111114\n",
      "K-fold 1 : 50.94618055555556\n",
      "K-fold 2 : 51.267361111111114\n",
      "K-fold 3 : 50.998263888888886\n",
      "K-fold 4 : 51.223958333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.048611111111114\n",
      "K-fold 1 : 54.02777777777778\n",
      "K-fold 2 : 52.708333333333336\n",
      "K-fold 3 : 52.361111111111114\n",
      "K-fold 4 : 52.25694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.68055555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934909496042464\n",
      "K-fold 1 : 0.694545837243398\n",
      "K-fold 2 : 0.6950480891598596\n",
      "K-fold 3 : 0.6939064058992598\n",
      "K-fold 4 : 0.6940253913402558\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931882500648499\n",
      "K-fold 1 : 0.6930495707885079\n",
      "K-fold 2 : 0.6931037669596465\n",
      "K-fold 3 : 0.693128033824589\n",
      "K-fold 4 : 0.6986421657645184\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933301707108815\n",
      "K-fold 1 : 0.693548481994205\n",
      "K-fold 2 : 0.6932240744431813\n",
      "K-fold 3 : 0.6934346642759112\n",
      "K-fold 4 : 0.6934247811635336\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928848727889683\n",
      "K-fold 1 : 0.6928717468095862\n",
      "K-fold 2 : 0.6927742051041644\n",
      "K-fold 3 : 0.6925919703815294\n",
      "K-fold 4 : 0.6929458509320798\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928137292032657\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.28819444444444\n",
      "K-fold 1 : 49.72222222222222\n",
      "K-fold 2 : 50.138888888888886\n",
      "K-fold 3 : 49.704861111111114\n",
      "K-fold 4 : 49.635416666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.625\n",
      "K-fold 1 : 49.72222222222222\n",
      "K-fold 2 : 50.763888888888886\n",
      "K-fold 3 : 51.52777777777778\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.18055555555556\n",
      "K-fold 1 : 51.00694444444444\n",
      "K-fold 2 : 51.00694444444444\n",
      "K-fold 3 : 50.81597222222222\n",
      "K-fold 4 : 51.18055555555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.625\n",
      "K-fold 1 : 50.27777777777778\n",
      "K-fold 2 : 50.763888888888886\n",
      "K-fold 3 : 51.52777777777778\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.722222222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939090218808915\n",
      "K-fold 1 : 0.6936642573939429\n",
      "K-fold 2 : 0.693416154384613\n",
      "K-fold 3 : 0.6936749365594652\n",
      "K-fold 4 : 0.693886708550983\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693056407182113\n",
      "K-fold 1 : 0.6945272528606913\n",
      "K-fold 2 : 0.6930467175400775\n",
      "K-fold 3 : 0.6934834900109664\n",
      "K-fold 4 : 0.6931178880774457\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932242810726166\n",
      "K-fold 1 : 0.6932056175337897\n",
      "K-fold 2 : 0.6929971171749962\n",
      "K-fold 3 : 0.6932802233431075\n",
      "K-fold 4 : 0.6928563475608825\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930549066999684\n",
      "K-fold 1 : 0.6931148456490558\n",
      "K-fold 2 : 0.6929867008458013\n",
      "K-fold 3 : 0.6927963961725649\n",
      "K-fold 4 : 0.6931083357852438\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930122370305268\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.670138888888886\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 50.15625\n",
      "K-fold 3 : 49.87847222222222\n",
      "K-fold 4 : 50.451388888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.270833333333336\n",
      "K-fold 1 : 48.263888888888886\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 49.236111111111114\n",
      "K-fold 4 : 50.34722222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.423611111111114\n",
      "K-fold 1 : 50.911458333333336\n",
      "K-fold 2 : 51.154513888888886\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 51.40625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.63194444444444\n",
      "K-fold 1 : 51.666666666666664\n",
      "K-fold 2 : 52.013888888888886\n",
      "K-fold 3 : 54.09722222222222\n",
      "K-fold 4 : 50.798611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.04166666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6946199013127221\n",
      "K-fold 1 : 0.6938950035307142\n",
      "K-fold 2 : 0.6948165833950043\n",
      "K-fold 3 : 0.6960545884238349\n",
      "K-fold 4 : 0.6948734058274163\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6935007753579513\n",
      "K-fold 1 : 0.6947303569835165\n",
      "K-fold 2 : 0.6930389559787252\n",
      "K-fold 3 : 0.694099371847899\n",
      "K-fold 4 : 0.6933334210644597\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6936704158782959\n",
      "K-fold 1 : 0.6938473330603705\n",
      "K-fold 2 : 0.6938571804099612\n",
      "K-fold 3 : 0.6937135544088152\n",
      "K-fold 4 : 0.6936209241549174\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929431324419768\n",
      "K-fold 1 : 0.6929691770802373\n",
      "K-fold 2 : 0.6927857554477194\n",
      "K-fold 3 : 0.6925352915473606\n",
      "K-fold 4 : 0.6930722412855729\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928611195605734\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.91319444444444\n",
      "K-fold 1 : 49.77430555555556\n",
      "K-fold 2 : 49.166666666666664\n",
      "K-fold 3 : 50.34722222222222\n",
      "K-fold 4 : 49.765625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.861111111111114\n",
      "K-fold 1 : 48.888888888888886\n",
      "K-fold 2 : 49.65277777777778\n",
      "K-fold 3 : 49.13194444444444\n",
      "K-fold 4 : 48.50694444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.920138888888886\n",
      "K-fold 1 : 50.78125\n",
      "K-fold 2 : 51.09375\n",
      "K-fold 3 : 51.119791666666664\n",
      "K-fold 4 : 51.24131944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.138888888888886\n",
      "K-fold 1 : 51.111111111111114\n",
      "K-fold 2 : 50.34722222222222\n",
      "K-fold 3 : 50.86805555555556\n",
      "K-fold 4 : 51.49305555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.791666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6936545656787024\n",
      "K-fold 1 : 0.6934428883923425\n",
      "K-fold 2 : 0.6937026335133447\n",
      "K-fold 3 : 0.6935552146699694\n",
      "K-fold 4 : 0.693517009417216\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6936927256376847\n",
      "K-fold 1 : 0.6937023634495942\n",
      "K-fold 2 : 0.6934028241945349\n",
      "K-fold 3 : 0.6939094092534936\n",
      "K-fold 4 : 0.6933708424153535\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932248440053728\n",
      "K-fold 1 : 0.6932571980688307\n",
      "K-fold 2 : 0.6929842372735341\n",
      "K-fold 3 : 0.6931273407406278\n",
      "K-fold 4 : 0.6931140820185343\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693146306535472\n",
      "K-fold 1 : 0.6929110599600751\n",
      "K-fold 2 : 0.6931194377982098\n",
      "K-fold 3 : 0.6930142615152441\n",
      "K-fold 4 : 0.6927592236062755\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929900578830553\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.24305555555556\n",
      "K-fold 1 : 50.060763888888886\n",
      "K-fold 2 : 48.776041666666664\n",
      "K-fold 3 : 49.895833333333336\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.513888888888886\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 50.104166666666664\n",
      "K-fold 3 : 49.65277777777778\n",
      "K-fold 4 : 49.65277777777778\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 51.05034722222222\n",
      "K-fold 2 : 51.328125\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 51.388888888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.486111111111114\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 50.104166666666664\n",
      "K-fold 3 : 50.34722222222222\n",
      "K-fold 4 : 51.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.597222222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934003121323056\n",
      "K-fold 1 : 0.693477228615019\n",
      "K-fold 2 : 0.6938168168067932\n",
      "K-fold 3 : 0.693445665968789\n",
      "K-fold 4 : 0.69333868821462\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6952561839767124\n",
      "K-fold 1 : 0.6930612610734027\n",
      "K-fold 2 : 0.6936230348504108\n",
      "K-fold 3 : 0.6931778037029764\n",
      "K-fold 4 : 0.6932390047156293\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.69310638639662\n",
      "K-fold 1 : 0.6930883314874438\n",
      "K-fold 2 : 0.6930498388078478\n",
      "K-fold 3 : 0.6930979410807292\n",
      "K-fold 4 : 0.6930455850230323\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930527453837187\n",
      "K-fold 1 : 0.6930136343707209\n",
      "K-fold 2 : 0.6931412660557291\n",
      "K-fold 3 : 0.6931305994158206\n",
      "K-fold 4 : 0.6931192641672881\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930915018786555\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.00868055555556\n",
      "K-fold 1 : 49.826388888888886\n",
      "K-fold 2 : 49.401041666666664\n",
      "K-fold 3 : 49.427083333333336\n",
      "K-fold 4 : 50.017361111111114\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.0625\n",
      "K-fold 1 : 51.736111111111114\n",
      "K-fold 2 : 51.354166666666664\n",
      "K-fold 3 : 50.55555555555556\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.05034722222222\n",
      "K-fold 1 : 51.16319444444444\n",
      "K-fold 2 : 50.842013888888886\n",
      "K-fold 3 : 51.31944444444444\n",
      "K-fold 4 : 51.197916666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.736111111111114\n",
      "K-fold 2 : 51.354166666666664\n",
      "K-fold 3 : 50.55555555555556\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.99999999999999\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939250826835632\n",
      "K-fold 1 : 0.6936290383338928\n",
      "K-fold 2 : 0.6936323205629985\n",
      "K-fold 3 : 0.6934207247363197\n",
      "K-fold 4 : 0.6933582153585222\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6950182448262754\n",
      "K-fold 1 : 0.6925153369488923\n",
      "K-fold 2 : 0.6929524126260177\n",
      "K-fold 3 : 0.6931169292201167\n",
      "K-fold 4 : 0.6934579248013704\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930387490325504\n",
      "K-fold 1 : 0.6928769012292226\n",
      "K-fold 2 : 0.6931122104326884\n",
      "K-fold 3 : 0.6931721899244521\n",
      "K-fold 4 : 0.6930772198571099\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929789470589679\n",
      "K-fold 1 : 0.6924325020416923\n",
      "K-fold 2 : 0.692796326201895\n",
      "K-fold 3 : 0.6930883578632189\n",
      "K-fold 4 : 0.6930954015773275\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928783069486204\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.078125\n",
      "K-fold 1 : 50.27777777777778\n",
      "K-fold 2 : 49.99131944444444\n",
      "K-fold 3 : 49.64409722222222\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.03472222222222\n",
      "K-fold 1 : 50.451388888888886\n",
      "K-fold 2 : 52.083333333333336\n",
      "K-fold 3 : 49.09722222222222\n",
      "K-fold 4 : 50.34722222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.032986111111114\n",
      "K-fold 1 : 50.92881944444444\n",
      "K-fold 2 : 50.78125\n",
      "K-fold 3 : 51.18055555555556\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.28472222222222\n",
      "K-fold 1 : 50.451388888888886\n",
      "K-fold 2 : 52.11805555555556\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 51.076388888888886\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.16666666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932985643545787\n",
      "K-fold 1 : 0.6934551417827606\n",
      "K-fold 2 : 0.6937858429219987\n",
      "K-fold 3 : 0.6935334881146749\n",
      "K-fold 4 : 0.693408461411794\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6937808964563452\n",
      "K-fold 1 : 0.693115542764249\n",
      "K-fold 2 : 0.6927777917488761\n",
      "K-fold 3 : 0.6936425437097964\n",
      "K-fold 4 : 0.6931478666222614\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931122468577491\n",
      "K-fold 1 : 0.69298578037156\n",
      "K-fold 2 : 0.69315311577585\n",
      "K-fold 3 : 0.6929840167363485\n",
      "K-fold 4 : 0.6930903871854146\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930543573006339\n",
      "K-fold 1 : 0.6931014190549436\n",
      "K-fold 2 : 0.6922322926313981\n",
      "K-fold 3 : 0.6928793554720671\n",
      "K-fold 4 : 0.6929683503897294\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928471549697545\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.373263888888886\n",
      "K-fold 1 : 49.64409722222222\n",
      "K-fold 2 : 50.052083333333336\n",
      "K-fold 3 : 49.895833333333336\n",
      "K-fold 4 : 49.46180555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.104166666666664\n",
      "K-fold 1 : 48.854166666666664\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 48.125\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 51.067708333333336\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 51.16319444444444\n",
      "K-fold 4 : 51.12847222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.104166666666664\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 51.875\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.90277777777778\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934070163302951\n",
      "K-fold 1 : 0.6937517662843068\n",
      "K-fold 2 : 0.6934514356984033\n",
      "K-fold 3 : 0.693453926510281\n",
      "K-fold 4 : 0.693454462952084\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931490042935247\n",
      "K-fold 1 : 0.6932160672934159\n",
      "K-fold 2 : 0.6933931449185247\n",
      "K-fold 3 : 0.6943307596704235\n",
      "K-fold 4 : 0.6931377701137377\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929918819003635\n",
      "K-fold 1 : 0.6930619107352363\n",
      "K-fold 2 : 0.6928664777013991\n",
      "K-fold 3 : 0.6931056678295135\n",
      "K-fold 4 : 0.693053498533037\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931435154831928\n",
      "K-fold 1 : 0.692895902239758\n",
      "K-fold 2 : 0.6928803765255472\n",
      "K-fold 3 : 0.6925469481426737\n",
      "K-fold 4 : 0.6931240714114645\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929181627605272\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.921875\n",
      "K-fold 1 : 50.486111111111114\n",
      "K-fold 2 : 49.765625\n",
      "K-fold 3 : 49.01909722222222\n",
      "K-fold 4 : 50.130208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.86805555555556\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 50.104166666666664\n",
      "K-fold 4 : 49.30555555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.89409722222222\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 51.13715277777778\n",
      "K-fold 3 : 51.111111111111114\n",
      "K-fold 4 : 50.876736111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.875\n",
      "K-fold 1 : 50.55555555555556\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 52.1875\n",
      "K-fold 4 : 51.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.270833333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6936297833919525\n",
      "K-fold 1 : 0.6934497402773963\n",
      "K-fold 2 : 0.6933999154302809\n",
      "K-fold 3 : 0.693600000275506\n",
      "K-fold 4 : 0.6933621181382074\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930531885312952\n",
      "K-fold 1 : 0.6931449226711107\n",
      "K-fold 2 : 0.6939073593720145\n",
      "K-fold 3 : 0.6931790942731111\n",
      "K-fold 4 : 0.6932363484216773\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932043241129981\n",
      "K-fold 1 : 0.6931182947423723\n",
      "K-fold 2 : 0.6930851969454024\n",
      "K-fold 3 : 0.6930754125118256\n",
      "K-fold 4 : 0.6930210610230764\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928700519644696\n",
      "K-fold 1 : 0.6930683514346248\n",
      "K-fold 2 : 0.6930212145266326\n",
      "K-fold 3 : 0.6930997086607892\n",
      "K-fold 4 : 0.6929207314615664\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929960116096165\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.130208333333336\n",
      "K-fold 1 : 50.3125\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 49.61805555555556\n",
      "K-fold 4 : 49.904513888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.548611111111114\n",
      "K-fold 1 : 48.958333333333336\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 49.826388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.94618055555556\n",
      "K-fold 1 : 50.97222222222222\n",
      "K-fold 2 : 51.47569444444444\n",
      "K-fold 3 : 51.05902777777778\n",
      "K-fold 4 : 50.876736111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.451388888888886\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 50.173611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.55555555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933330469661289\n",
      "K-fold 1 : 0.693313945002026\n",
      "K-fold 2 : 0.6940770559840732\n",
      "K-fold 3 : 0.6937318404515584\n",
      "K-fold 4 : 0.6933998194005754\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693321899227474\n",
      "K-fold 1 : 0.6935102162153824\n",
      "K-fold 2 : 0.6934490281602611\n",
      "K-fold 3 : 0.6929333546887273\n",
      "K-fold 4 : 0.6933902735295503\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930722190274132\n",
      "K-fold 1 : 0.6931873864597744\n",
      "K-fold 2 : 0.6928283095359802\n",
      "K-fold 3 : 0.6930572006437513\n",
      "K-fold 4 : 0.6930723541312748\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931082062099291\n",
      "K-fold 1 : 0.6928651229194973\n",
      "K-fold 2 : 0.6931469414545142\n",
      "K-fold 3 : 0.6929254583690477\n",
      "K-fold 4 : 0.6930881712747656\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930267800455508\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.42534722222222\n",
      "K-fold 1 : 49.635416666666664\n",
      "K-fold 2 : 49.77430555555556\n",
      "K-fold 3 : 48.94965277777778\n",
      "K-fold 4 : 49.69618055555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.05555555555556\n",
      "K-fold 1 : 49.513888888888886\n",
      "K-fold 2 : 50.03472222222222\n",
      "K-fold 3 : 49.13194444444444\n",
      "K-fold 4 : 49.236111111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.111111111111114\n",
      "K-fold 3 : 51.28472222222222\n",
      "K-fold 4 : 51.388888888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.1875\n",
      "K-fold 1 : 52.673611111111114\n",
      "K-fold 2 : 50.763888888888886\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 50.763888888888886\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.42361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932316621144613\n",
      "K-fold 1 : 0.693421459197998\n",
      "K-fold 2 : 0.6935568418767717\n",
      "K-fold 3 : 0.6936361385716332\n",
      "K-fold 4 : 0.6936131755510966\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6935622769853343\n",
      "K-fold 1 : 0.6944425883500472\n",
      "K-fold 2 : 0.6931841010632722\n",
      "K-fold 3 : 0.6937344670295715\n",
      "K-fold 4 : 0.6933368936828945\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931223524941339\n",
      "K-fold 1 : 0.6930396689309014\n",
      "K-fold 2 : 0.6930674248271518\n",
      "K-fold 3 : 0.6929189655515883\n",
      "K-fold 4 : 0.693025537331899\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6924494297608085\n",
      "K-fold 1 : 0.6928819184717925\n",
      "K-fold 2 : 0.693111222723256\n",
      "K-fold 3 : 0.6930354548537213\n",
      "K-fold 4 : 0.6929575671320376\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928871185883232\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.755208333333336\n",
      "K-fold 1 : 50.43402777777778\n",
      "K-fold 2 : 49.60069444444444\n",
      "K-fold 3 : 50.85069444444444\n",
      "K-fold 4 : 49.52256944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.451388888888886\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 48.541666666666664\n",
      "K-fold 3 : 48.888888888888886\n",
      "K-fold 4 : 48.50694444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.032986111111114\n",
      "K-fold 1 : 51.16319444444444\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.145833333333336\n",
      "K-fold 4 : 51.20659722222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.451388888888886\n",
      "K-fold 1 : 50.90277777777778\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 51.111111111111114\n",
      "K-fold 4 : 51.49305555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.083333333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931527780161963\n",
      "K-fold 1 : 0.6933703574869368\n",
      "K-fold 2 : 0.693507542875078\n",
      "K-fold 3 : 0.6931056280930837\n",
      "K-fold 4 : 0.6936694714758131\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931618011516073\n",
      "K-fold 1 : 0.6930857482163802\n",
      "K-fold 2 : 0.6939289751260177\n",
      "K-fold 3 : 0.6934085280998893\n",
      "K-fold 4 : 0.6937665939331055\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929461459318796\n",
      "K-fold 1 : 0.693109263976415\n",
      "K-fold 2 : 0.6930917474958632\n",
      "K-fold 3 : 0.6929234431849586\n",
      "K-fold 4 : 0.6930804934766558\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930952901425569\n",
      "K-fold 1 : 0.693014277064282\n",
      "K-fold 2 : 0.6925930173500724\n",
      "K-fold 3 : 0.6928804128066354\n",
      "K-fold 4 : 0.6925470673519633\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692826012943102\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.763888888888886\n",
      "K-fold 1 : 52.404513888888886\n",
      "K-fold 2 : 52.282986111111114\n",
      "K-fold 3 : 73.13368055555556\n",
      "K-fold 4 : 51.47569444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.44444444444444\n",
      "K-fold 1 : 50.798611111111114\n",
      "K-fold 2 : 51.736111111111114\n",
      "K-fold 3 : 72.63888888888889\n",
      "K-fold 4 : 49.236111111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.458333333333336\n",
      "K-fold 1 : 53.89756944444444\n",
      "K-fold 2 : 53.020833333333336\n",
      "K-fold 3 : 73.203125\n",
      "K-fold 4 : 51.935763888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.00694444444444\n",
      "K-fold 1 : 52.74305555555556\n",
      "K-fold 2 : 52.013888888888886\n",
      "K-fold 3 : 72.63888888888889\n",
      "K-fold 4 : 52.916666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 56.26388888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6859357542461819\n",
      "K-fold 1 : 0.6765065848827362\n",
      "K-fold 2 : 0.6774730655882094\n",
      "K-fold 3 : 0.5019485003418392\n",
      "K-fold 4 : 0.6856583191288842\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6897497073463772\n",
      "K-fold 1 : 0.6768822618152784\n",
      "K-fold 2 : 0.6800501994464708\n",
      "K-fold 3 : 0.5042871677357218\n",
      "K-fold 4 : 0.688282733378203\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6850660847293006\n",
      "K-fold 1 : 0.6679869658417172\n",
      "K-fold 2 : 0.6773896820015377\n",
      "K-fold 3 : 0.49872787793477374\n",
      "K-fold 4 : 0.6822128097216288\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6851743770682294\n",
      "K-fold 1 : 0.6694364184918611\n",
      "K-fold 2 : 0.6772682614948439\n",
      "K-fold 3 : 0.4990417814773062\n",
      "K-fold 4 : 0.6841732730036196\n",
      "---------------------------------\n",
      "Average best validation loss: 0.643018822307172\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.486111111111114\n",
      "K-fold 1 : 50.138888888888886\n",
      "K-fold 2 : 50.060763888888886\n",
      "K-fold 3 : 50.63368055555556\n",
      "K-fold 4 : 50.38194444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.833333333333336\n",
      "K-fold 1 : 48.888888888888886\n",
      "K-fold 2 : 49.40972222222222\n",
      "K-fold 3 : 50.24305555555556\n",
      "K-fold 4 : 50.763888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.423611111111114\n",
      "K-fold 1 : 51.02430555555556\n",
      "K-fold 2 : 50.842013888888886\n",
      "K-fold 3 : 51.276041666666664\n",
      "K-fold 4 : 51.232638888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.833333333333336\n",
      "K-fold 1 : 51.111111111111114\n",
      "K-fold 2 : 50.59027777777778\n",
      "K-fold 3 : 50.24305555555556\n",
      "K-fold 4 : 50.763888888888886\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.70833333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937679562303755\n",
      "K-fold 1 : 0.693811297416687\n",
      "K-fold 2 : 0.69415994948811\n",
      "K-fold 3 : 0.693957801659902\n",
      "K-fold 4 : 0.6940093404716916\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930067798365718\n",
      "K-fold 1 : 0.6958248019218445\n",
      "K-fold 2 : 0.6933103929395261\n",
      "K-fold 3 : 0.6931346240250961\n",
      "K-fold 4 : 0.693076491355896\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932042982843187\n",
      "K-fold 1 : 0.6934489693906573\n",
      "K-fold 2 : 0.6931078950564067\n",
      "K-fold 3 : 0.6932342542542351\n",
      "K-fold 4 : 0.6932253433598412\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929671842118968\n",
      "K-fold 1 : 0.6929401625757632\n",
      "K-fold 2 : 0.6931085197821908\n",
      "K-fold 3 : 0.6931287672208704\n",
      "K-fold 4 : 0.6930356958638066\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930360659309056\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 72.66493055555556\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 93.56770833333333\n",
      "K-fold 3 : 82.88194444444444\n",
      "K-fold 4 : 93.69791666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 72.70833333333333\n",
      "K-fold 1 : 48.958333333333336\n",
      "K-fold 2 : 94.6875\n",
      "K-fold 3 : 83.85416666666667\n",
      "K-fold 4 : 93.29861111111111\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 72.94270833333333\n",
      "K-fold 1 : 52.526041666666664\n",
      "K-fold 2 : 94.11458333333333\n",
      "K-fold 3 : 82.88194444444444\n",
      "K-fold 4 : 93.69791666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 73.36805555555556\n",
      "K-fold 1 : 53.78472222222222\n",
      "K-fold 2 : 94.6875\n",
      "K-fold 3 : 83.85416666666667\n",
      "K-fold 4 : 93.68055555555556\n",
      "---------------------------------\n",
      "Average best validation accuracy: 79.875\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.5002518306175868\n",
      "K-fold 1 : 0.6868031289842393\n",
      "K-fold 2 : 0.27909922897815703\n",
      "K-fold 3 : 0.394438064760632\n",
      "K-fold 4 : 0.26482647276586957\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.5047254925188811\n",
      "K-fold 1 : 0.6814428438311038\n",
      "K-fold 2 : 0.2841707714225935\n",
      "K-fold 3 : 0.3801429569721222\n",
      "K-fold 4 : 0.33689197250034497\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.49777910278903115\n",
      "K-fold 1 : 0.674303279320399\n",
      "K-fold 2 : 0.27672160449955197\n",
      "K-fold 3 : 0.39346902403566575\n",
      "K-fold 4 : 0.26482647276586957\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.5019337858842767\n",
      "K-fold 1 : 0.6719899436701899\n",
      "K-fold 2 : 0.2576704783284146\n",
      "K-fold 3 : 0.37204483021860535\n",
      "K-fold 4 : 0.28335976795009943\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4173997612103172\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.27777777777778\n",
      "K-fold 1 : 50.390625\n",
      "K-fold 2 : 49.49652777777778\n",
      "K-fold 3 : 49.817708333333336\n",
      "K-fold 4 : 49.973958333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.458333333333336\n",
      "K-fold 1 : 52.1875\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 49.826388888888886\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 51.25\n",
      "K-fold 3 : 51.08506944444444\n",
      "K-fold 4 : 51.28472222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.458333333333336\n",
      "K-fold 1 : 52.1875\n",
      "K-fold 2 : 51.49305555555556\n",
      "K-fold 3 : 51.21527777777778\n",
      "K-fold 4 : 51.00694444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.47222222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6940717160701751\n",
      "K-fold 1 : 0.6936791718006134\n",
      "K-fold 2 : 0.6971247269047631\n",
      "K-fold 3 : 0.6944540268845029\n",
      "K-fold 4 : 0.694220095872879\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927146289659583\n",
      "K-fold 1 : 0.6925450563430786\n",
      "K-fold 2 : 0.6931230425834656\n",
      "K-fold 3 : 0.6936365236406741\n",
      "K-fold 4 : 0.6936465087144271\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933869295650058\n",
      "K-fold 1 : 0.6934551669491662\n",
      "K-fold 2 : 0.6933219611644745\n",
      "K-fold 3 : 0.685538853539361\n",
      "K-fold 4 : 0.6931302395131853\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926374124444049\n",
      "K-fold 1 : 0.6921718872111776\n",
      "K-fold 2 : 0.6927415080692457\n",
      "K-fold 3 : 0.6856495271558347\n",
      "K-fold 4 : 0.6930164228314939\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6912433515424314\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 68.95833333333333\n",
      "K-fold 1 : 93.16840277777777\n",
      "K-fold 2 : 92.47395833333333\n",
      "K-fold 3 : 54.72222222222222\n",
      "K-fold 4 : 95.38194444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 67.1875\n",
      "K-fold 1 : 94.375\n",
      "K-fold 2 : 94.40972222222223\n",
      "K-fold 3 : 55.86805555555556\n",
      "K-fold 4 : 96.21527777777777\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 74.14930555555556\n",
      "K-fold 1 : 94.33159722222223\n",
      "K-fold 2 : 94.14930555555556\n",
      "K-fold 3 : 56.51909722222222\n",
      "K-fold 4 : 95.59895833333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 78.64583333333333\n",
      "K-fold 1 : 94.375\n",
      "K-fold 2 : 94.47916666666667\n",
      "K-fold 3 : 59.09722222222222\n",
      "K-fold 4 : 96.21527777777777\n",
      "---------------------------------\n",
      "Average best validation accuracy: 84.5625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.5063068512413237\n",
      "K-fold 1 : 0.27355813963545694\n",
      "K-fold 2 : 0.31342012882232667\n",
      "K-fold 3 : 0.6515583634376526\n",
      "K-fold 4 : 0.20029069748189715\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.5155947506427765\n",
      "K-fold 1 : 0.26211619409530057\n",
      "K-fold 2 : 0.2886637339125509\n",
      "K-fold 3 : 0.654370455638222\n",
      "K-fold 4 : 0.17045121348422507\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.5063068512413237\n",
      "K-fold 1 : 0.26125659694274267\n",
      "K-fold 2 : 0.27907478627231386\n",
      "K-fold 3 : 0.6488014035754733\n",
      "K-fold 4 : 0.19479189953870243\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.5155947506427765\n",
      "K-fold 1 : 0.25136005165784253\n",
      "K-fold 2 : 0.2717684222304303\n",
      "K-fold 3 : 0.6532064624454664\n",
      "K-fold 4 : 0.17045121348422507\n",
      "---------------------------------\n",
      "Average best validation loss: 0.37247618009214817\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 73.19444444444444\n",
      "K-fold 1 : 50.00868055555556\n",
      "K-fold 2 : 49.64409722222222\n",
      "K-fold 3 : 50.15625\n",
      "K-fold 4 : 49.40972222222222\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 73.54166666666667\n",
      "K-fold 1 : 52.326388888888886\n",
      "K-fold 2 : 49.30555555555556\n",
      "K-fold 3 : 50.138888888888886\n",
      "K-fold 4 : 49.72222222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 73.24652777777777\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 50.920138888888886\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 74.54861111111111\n",
      "K-fold 1 : 52.951388888888886\n",
      "K-fold 2 : 51.666666666666664\n",
      "K-fold 3 : 51.111111111111114\n",
      "K-fold 4 : 50.27777777777778\n",
      "---------------------------------\n",
      "Average best validation accuracy: 56.11111111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.5070364637507333\n",
      "K-fold 1 : 0.6945074929131402\n",
      "K-fold 2 : 0.6970944623152415\n",
      "K-fold 3 : 0.6936964922481113\n",
      "K-fold 4 : 0.6961122685008578\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.501175053741621\n",
      "K-fold 1 : 0.6928303138069485\n",
      "K-fold 2 : 0.7002115327378978\n",
      "K-fold 3 : 0.6931574033654254\n",
      "K-fold 4 : 0.7001333703165469\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.5028054830100801\n",
      "K-fold 1 : 0.6931541310416327\n",
      "K-fold 2 : 0.6931132687462701\n",
      "K-fold 3 : 0.6934702866607242\n",
      "K-fold 4 : 0.693328454097112\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.491032424180404\n",
      "K-fold 1 : 0.6922310279763263\n",
      "K-fold 2 : 0.692813824052396\n",
      "K-fold 3 : 0.6927189878795458\n",
      "K-fold 4 : 0.6894317113834879\n",
      "---------------------------------\n",
      "Average best validation loss: 0.651645595094432\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 94.09722222222223\n",
      "K-fold 1 : 92.421875\n",
      "K-fold 2 : 93.70659722222223\n",
      "K-fold 3 : 95.66840277777777\n",
      "K-fold 4 : 95.546875\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 94.96527777777777\n",
      "K-fold 1 : 92.5\n",
      "K-fold 2 : 93.19444444444444\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 94.13194444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 94.31423611111111\n",
      "K-fold 1 : 93.14236111111111\n",
      "K-fold 2 : 94.69618055555556\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.88541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.86805555555556\n",
      "K-fold 1 : 93.99305555555556\n",
      "K-fold 2 : 95.86805555555556\n",
      "K-fold 3 : 95.9375\n",
      "K-fold 4 : 95.52083333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.4375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.23333270632558398\n",
      "K-fold 1 : 0.28102178507381015\n",
      "K-fold 2 : 0.21786121676365536\n",
      "K-fold 3 : 0.18668949355681738\n",
      "K-fold 4 : 0.19141289119919142\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.21250182649363641\n",
      "K-fold 1 : 0.2860597618248152\n",
      "K-fold 2 : 0.22963190532248953\n",
      "K-fold 3 : 0.18370877659839133\n",
      "K-fold 4 : 0.22378593229729196\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.22459460231992934\n",
      "K-fold 1 : 0.27385988467269473\n",
      "K-fold 2 : 0.2027334878842036\n",
      "K-fold 3 : 0.18526849850184388\n",
      "K-fold 4 : 0.18273951220843526\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1970905042860819\n",
      "K-fold 1 : 0.2707927466734596\n",
      "K-fold 2 : 0.1882902756333351\n",
      "K-fold 3 : 0.17321557907954507\n",
      "K-fold 4 : 0.18893327337244284\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2036644758089729\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.817708333333336\n",
      "K-fold 1 : 49.947916666666664\n",
      "K-fold 2 : 58.064236111111114\n",
      "K-fold 3 : 93.35069444444444\n",
      "K-fold 4 : 94.46180555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.52777777777778\n",
      "K-fold 1 : 49.34027777777778\n",
      "K-fold 2 : 59.6875\n",
      "K-fold 3 : 93.64583333333333\n",
      "K-fold 4 : 94.20138888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.08506944444444\n",
      "K-fold 1 : 51.68402777777778\n",
      "K-fold 2 : 58.60243055555556\n",
      "K-fold 3 : 95.49479166666667\n",
      "K-fold 4 : 95.92013888888889\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.326388888888886\n",
      "K-fold 1 : 50.97222222222222\n",
      "K-fold 2 : 60.38194444444444\n",
      "K-fold 3 : 95.79861111111111\n",
      "K-fold 4 : 95.38194444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 70.97222222222221\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6956000434027778\n",
      "K-fold 1 : 0.7172606070836385\n",
      "K-fold 2 : 0.6463000608815087\n",
      "K-fold 3 : 0.24526398893859652\n",
      "K-fold 4 : 0.21055748181210623\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931414681932201\n",
      "K-fold 1 : 0.6956928190977677\n",
      "K-fold 2 : 0.6262915834136631\n",
      "K-fold 3 : 0.23488916845425314\n",
      "K-fold 4 : 0.21558825477309848\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693204300933414\n",
      "K-fold 1 : 0.6935994194613563\n",
      "K-fold 2 : 0.637370025449329\n",
      "K-fold 3 : 0.18796707168221474\n",
      "K-fold 4 : 0.17800092937217818\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6925795026447462\n",
      "K-fold 1 : 0.6930472228838049\n",
      "K-fold 2 : 0.6204440956530364\n",
      "K-fold 3 : 0.18319289256697116\n",
      "K-fold 4 : 0.1895263580524403\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4757580143601999\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.390625\n",
      "K-fold 1 : 91.484375\n",
      "K-fold 2 : 72.84722222222223\n",
      "K-fold 3 : 49.904513888888886\n",
      "K-fold 4 : 50.85069444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 52.048611111111114\n",
      "K-fold 1 : 89.65277777777777\n",
      "K-fold 2 : 68.88888888888889\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 49.0625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.52777777777778\n",
      "K-fold 1 : 92.69097222222223\n",
      "K-fold 2 : 72.84722222222223\n",
      "K-fold 3 : 50.920138888888886\n",
      "K-fold 4 : 51.99652777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.916666666666664\n",
      "K-fold 1 : 93.61111111111111\n",
      "K-fold 2 : 85.0\n",
      "K-fold 3 : 54.548611111111114\n",
      "K-fold 4 : 54.791666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 68.17361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6894433253341251\n",
      "K-fold 1 : 0.2911644928985172\n",
      "K-fold 2 : 0.5001211295525233\n",
      "K-fold 3 : 0.694440488020579\n",
      "K-fold 4 : 0.6907818078994751\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6845575208249299\n",
      "K-fold 1 : 0.3035257704879927\n",
      "K-fold 2 : 0.4879682737848033\n",
      "K-fold 3 : 0.6937319791835287\n",
      "K-fold 4 : 0.6878227591514587\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6876059558656481\n",
      "K-fold 1 : 0.28298787805769177\n",
      "K-fold 2 : 0.5001211295525233\n",
      "K-fold 3 : 0.6934230897161696\n",
      "K-fold 4 : 0.6897084143426683\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6840311496154122\n",
      "K-fold 1 : 0.29371726707271906\n",
      "K-fold 2 : 0.47204348833664606\n",
      "K-fold 3 : 0.6910461394683175\n",
      "K-fold 4 : 0.6877797712450442\n",
      "---------------------------------\n",
      "Average best validation loss: 0.5657235631476278\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.130208333333336\n",
      "K-fold 1 : 49.704861111111114\n",
      "K-fold 2 : 49.25347222222222\n",
      "K-fold 3 : 49.375\n",
      "K-fold 4 : 50.234375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.6875\n",
      "K-fold 1 : 50.34722222222222\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 48.333333333333336\n",
      "K-fold 4 : 49.548611111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 51.614583333333336\n",
      "K-fold 2 : 51.076388888888886\n",
      "K-fold 3 : 51.02430555555556\n",
      "K-fold 4 : 50.911458333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.3125\n",
      "K-fold 1 : 50.34722222222222\n",
      "K-fold 2 : 51.701388888888886\n",
      "K-fold 3 : 51.666666666666664\n",
      "K-fold 4 : 51.423611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.09027777777778\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6944983879725138\n",
      "K-fold 1 : 0.6944044013818105\n",
      "K-fold 2 : 0.6949875030252669\n",
      "K-fold 3 : 0.6943295419216156\n",
      "K-fold 4 : 0.694732501771715\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6941932102908259\n",
      "K-fold 1 : 0.6935684966004413\n",
      "K-fold 2 : 0.6929531771203746\n",
      "K-fold 3 : 0.6931518083033354\n",
      "K-fold 4 : 0.6986051642376444\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931589623292287\n",
      "K-fold 1 : 0.6933571716149648\n",
      "K-fold 2 : 0.6935112675031027\n",
      "K-fold 3 : 0.6934706310431162\n",
      "K-fold 4 : 0.6932866315046946\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693132467891859\n",
      "K-fold 1 : 0.6931388818699381\n",
      "K-fold 2 : 0.6929531771203746\n",
      "K-fold 3 : 0.6926337195479352\n",
      "K-fold 4 : 0.6930029806883439\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929722454236902\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.53125\n",
      "K-fold 1 : 92.59548611111111\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 93.36805555555556\n",
      "K-fold 4 : 91.77083333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.763888888888886\n",
      "K-fold 1 : 94.34027777777777\n",
      "K-fold 2 : 49.02777777777778\n",
      "K-fold 3 : 93.125\n",
      "K-fold 4 : 92.95138888888889\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.13715277777778\n",
      "K-fold 1 : 94.03645833333333\n",
      "K-fold 2 : 51.71875\n",
      "K-fold 3 : 94.18402777777777\n",
      "K-fold 4 : 92.56076388888889\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.43055555555556\n",
      "K-fold 1 : 94.34027777777777\n",
      "K-fold 2 : 51.80555555555556\n",
      "K-fold 3 : 94.23611111111111\n",
      "K-fold 4 : 94.72222222222223\n",
      "---------------------------------\n",
      "Average best validation accuracy: 77.50694444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6953704754511515\n",
      "K-fold 1 : 0.29498798416720495\n",
      "K-fold 2 : 0.6954120881027646\n",
      "K-fold 3 : 0.29390689763757916\n",
      "K-fold 4 : 0.29592150847117105\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6947286673214125\n",
      "K-fold 1 : 0.28784847518672113\n",
      "K-fold 2 : 0.6958711950675301\n",
      "K-fold 3 : 0.29320020714531775\n",
      "K-fold 4 : 0.2810852877471758\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6878230763806237\n",
      "K-fold 1 : 0.287526340285937\n",
      "K-fold 2 : 0.6923214428954654\n",
      "K-fold 3 : 0.2793743865357505\n",
      "K-fold 4 : 0.2854158671365844\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6881368523058684\n",
      "K-fold 1 : 0.2713826020126757\n",
      "K-fold 2 : 0.6927389010139133\n",
      "K-fold 3 : 0.27868804465169494\n",
      "K-fold 4 : 0.26529886087645654\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4392490521721218\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.80902777777778\n",
      "K-fold 1 : 49.748263888888886\n",
      "K-fold 2 : 49.635416666666664\n",
      "K-fold 3 : 49.56597222222222\n",
      "K-fold 4 : 49.817708333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.65277777777778\n",
      "K-fold 1 : 49.34027777777778\n",
      "K-fold 2 : 50.486111111111114\n",
      "K-fold 3 : 50.90277777777778\n",
      "K-fold 4 : 49.201388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.18055555555556\n",
      "K-fold 1 : 51.29340277777778\n",
      "K-fold 2 : 50.954861111111114\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 51.13715277777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.729166666666664\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 51.423611111111114\n",
      "K-fold 3 : 51.80555555555556\n",
      "K-fold 4 : 50.798611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.138888888888886\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6947390960322486\n",
      "K-fold 1 : 0.6939833442370097\n",
      "K-fold 2 : 0.695007077852885\n",
      "K-fold 3 : 0.6940358195039961\n",
      "K-fold 4 : 0.6946306500169966\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6951798692993496\n",
      "K-fold 1 : 0.6932159247605697\n",
      "K-fold 2 : 0.6930686805559241\n",
      "K-fold 3 : 0.6930571483529132\n",
      "K-fold 4 : 0.6942653474600419\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6934292919105953\n",
      "K-fold 1 : 0.6934050930870904\n",
      "K-fold 2 : 0.6933770895004272\n",
      "K-fold 3 : 0.6932846989896563\n",
      "K-fold 4 : 0.6934543410936992\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929025986920232\n",
      "K-fold 1 : 0.6929552788319795\n",
      "K-fold 2 : 0.6929836247278296\n",
      "K-fold 3 : 0.6928285282591115\n",
      "K-fold 4 : 0.6929819868958514\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692930403481359\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.41493055555556\n",
      "K-fold 1 : 92.1875\n",
      "K-fold 2 : 69.62673611111111\n",
      "K-fold 3 : 90.35590277777777\n",
      "K-fold 4 : 52.85590277777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.90972222222222\n",
      "K-fold 1 : 92.63888888888889\n",
      "K-fold 2 : 79.86111111111111\n",
      "K-fold 3 : 89.79166666666667\n",
      "K-fold 4 : 51.18055555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 52.88194444444444\n",
      "K-fold 1 : 93.38541666666667\n",
      "K-fold 2 : 72.80381944444444\n",
      "K-fold 3 : 91.25868055555556\n",
      "K-fold 4 : 55.38194444444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 54.6875\n",
      "K-fold 1 : 93.75\n",
      "K-fold 2 : 86.94444444444444\n",
      "K-fold 3 : 94.47916666666667\n",
      "K-fold 4 : 56.28472222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 77.22916666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6876715607113308\n",
      "K-fold 1 : 0.2925744632879893\n",
      "K-fold 2 : 0.48136826952298484\n",
      "K-fold 3 : 0.3097040547264947\n",
      "K-fold 4 : 0.6775423732068804\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6888860282690629\n",
      "K-fold 1 : 0.2944079598654871\n",
      "K-fold 2 : 0.4699528437593709\n",
      "K-fold 3 : 0.2809346318244934\n",
      "K-fold 4 : 0.6770302471907242\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6808695250087314\n",
      "K-fold 1 : 0.28172024769915477\n",
      "K-fold 2 : 0.47284974422719744\n",
      "K-fold 3 : 0.2963686779141426\n",
      "K-fold 4 : 0.6775423732068804\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6714410885520603\n",
      "K-fold 1 : 0.27656775129878003\n",
      "K-fold 2 : 0.46010652961938275\n",
      "K-fold 3 : 0.27880331161229505\n",
      "K-fold 4 : 0.6748350418132284\n",
      "---------------------------------\n",
      "Average best validation loss: 0.47235074457914933\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.494791666666664\n",
      "K-fold 1 : 49.713541666666664\n",
      "K-fold 2 : 49.782986111111114\n",
      "K-fold 3 : 50.763888888888886\n",
      "K-fold 4 : 93.38541666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.923611111111114\n",
      "K-fold 1 : 49.479166666666664\n",
      "K-fold 2 : 48.36805555555556\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 94.0625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.076388888888886\n",
      "K-fold 1 : 51.33680555555556\n",
      "K-fold 2 : 51.05034722222222\n",
      "K-fold 3 : 50.998263888888886\n",
      "K-fold 4 : 94.33159722222223\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.49305555555556\n",
      "K-fold 1 : 51.979166666666664\n",
      "K-fold 2 : 51.63194444444444\n",
      "K-fold 3 : 51.52777777777778\n",
      "K-fold 4 : 94.0625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 60.13888888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6955361273553636\n",
      "K-fold 1 : 0.6969845235347748\n",
      "K-fold 2 : 0.6939282086160448\n",
      "K-fold 3 : 0.6980979124704997\n",
      "K-fold 4 : 0.2708424738711781\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931737402211064\n",
      "K-fold 1 : 0.6933159154394398\n",
      "K-fold 2 : 0.6936810949574346\n",
      "K-fold 3 : 0.6941526480343031\n",
      "K-fold 4 : 0.27381520102853363\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933419618341657\n",
      "K-fold 1 : 0.6933138926823934\n",
      "K-fold 2 : 0.6935947954654693\n",
      "K-fold 3 : 0.6934569239616394\n",
      "K-fold 4 : 0.2599207176102532\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927127838134766\n",
      "K-fold 1 : 0.6930086016654968\n",
      "K-fold 2 : 0.6919287287670634\n",
      "K-fold 3 : 0.6911345201989879\n",
      "K-fold 4 : 0.26589297017325525\n",
      "---------------------------------\n",
      "Average best validation loss: 0.606935520923656\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.76041666666667\n",
      "K-fold 1 : 91.46701388888889\n",
      "K-fold 2 : 94.19270833333333\n",
      "K-fold 3 : 70.546875\n",
      "K-fold 4 : 93.85416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 94.54861111111111\n",
      "K-fold 1 : 90.20833333333333\n",
      "K-fold 2 : 94.51388888888889\n",
      "K-fold 3 : 72.67361111111111\n",
      "K-fold 4 : 94.89583333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.02083333333333\n",
      "K-fold 1 : 92.79513888888889\n",
      "K-fold 2 : 94.296875\n",
      "K-fold 3 : 72.74305555555556\n",
      "K-fold 4 : 93.85416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 94.65277777777777\n",
      "K-fold 1 : 93.47222222222223\n",
      "K-fold 2 : 95.72916666666667\n",
      "K-fold 3 : 87.11805555555556\n",
      "K-fold 4 : 94.89583333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 93.17361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.27952381521463393\n",
      "K-fold 1 : 0.31075978461239073\n",
      "K-fold 2 : 0.24868914236625037\n",
      "K-fold 3 : 0.47416557007365756\n",
      "K-fold 4 : 0.2830909157792727\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2700393089781637\n",
      "K-fold 1 : 0.3544079998265142\n",
      "K-fold 2 : 0.24722801343254422\n",
      "K-fold 3 : 0.4852284789085388\n",
      "K-fold 4 : 0.26012654861678247\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.27952381521463393\n",
      "K-fold 1 : 0.2920739084482193\n",
      "K-fold 2 : 0.24323751876751581\n",
      "K-fold 3 : 0.46807308693726857\n",
      "K-fold 4 : 0.2821933743026521\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2594827536655509\n",
      "K-fold 1 : 0.2989313135976377\n",
      "K-fold 2 : 0.2335519376008407\n",
      "K-fold 3 : 0.46065814469171606\n",
      "K-fold 4 : 0.25454938606075617\n",
      "---------------------------------\n",
      "Average best validation loss: 0.3014347071233003\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.41840277777778\n",
      "K-fold 1 : 49.817708333333336\n",
      "K-fold 2 : 49.921875\n",
      "K-fold 3 : 49.91319444444444\n",
      "K-fold 4 : 50.38194444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.895833333333336\n",
      "K-fold 1 : 51.59722222222222\n",
      "K-fold 2 : 51.5625\n",
      "K-fold 3 : 49.201388888888886\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.90277777777778\n",
      "K-fold 1 : 51.05034722222222\n",
      "K-fold 2 : 50.89409722222222\n",
      "K-fold 3 : 51.41493055555556\n",
      "K-fold 4 : 51.267361111111114\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.59722222222222\n",
      "K-fold 1 : 53.854166666666664\n",
      "K-fold 2 : 56.49305555555556\n",
      "K-fold 3 : 52.77777777777778\n",
      "K-fold 4 : 50.69444444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 53.083333333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939922789732615\n",
      "K-fold 1 : 0.7949992656707764\n",
      "K-fold 2 : 0.6972871469126807\n",
      "K-fold 3 : 0.6990664230452643\n",
      "K-fold 4 : 0.7151775234275394\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6940389145975527\n",
      "K-fold 1 : 0.6982501149177551\n",
      "K-fold 2 : 0.696685148322064\n",
      "K-fold 3 : 0.6938047979189002\n",
      "K-fold 4 : 0.6933449688165084\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6934338172276815\n",
      "K-fold 1 : 0.6935626698864831\n",
      "K-fold 2 : 0.6938919438256158\n",
      "K-fold 3 : 0.6931872977150811\n",
      "K-fold 4 : 0.6938108013735877\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926727735477946\n",
      "K-fold 1 : 0.6927562278249989\n",
      "K-fold 2 : 0.6876747945080632\n",
      "K-fold 3 : 0.6928127408027649\n",
      "K-fold 4 : 0.6929330929465916\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6917699259260427\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.22569444444444\n",
      "K-fold 1 : 50.34722222222222\n",
      "K-fold 2 : 49.02777777777778\n",
      "K-fold 3 : 49.895833333333336\n",
      "K-fold 4 : 49.192708333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.40972222222222\n",
      "K-fold 1 : 50.27777777777778\n",
      "K-fold 2 : 50.104166666666664\n",
      "K-fold 3 : 48.888888888888886\n",
      "K-fold 4 : 48.81944444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.16319444444444\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.12847222222222\n",
      "K-fold 3 : 51.111111111111114\n",
      "K-fold 4 : 50.90277777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 52.986111111111114\n",
      "K-fold 2 : 51.28472222222222\n",
      "K-fold 3 : 51.701388888888886\n",
      "K-fold 4 : 52.53472222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.909722222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6953936583466\n",
      "K-fold 1 : 0.6940691471099854\n",
      "K-fold 2 : 0.6945809741814931\n",
      "K-fold 3 : 0.6936762419011858\n",
      "K-fold 4 : 0.6950887209839292\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6951594223146853\n",
      "K-fold 1 : 0.6933481200881626\n",
      "K-fold 2 : 0.6952299397924672\n",
      "K-fold 3 : 0.6932767655538477\n",
      "K-fold 4 : 0.6935065129528875\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6935748219490051\n",
      "K-fold 1 : 0.6934857600265079\n",
      "K-fold 2 : 0.6934414373503791\n",
      "K-fold 3 : 0.6934126463201311\n",
      "K-fold 4 : 0.6937640719943576\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929697135220403\n",
      "K-fold 1 : 0.693054419496785\n",
      "K-fold 2 : 0.692845238291699\n",
      "K-fold 3 : 0.6925761285035507\n",
      "K-fold 4 : 0.6926740900329922\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928239179694134\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.329861111111114\n",
      "K-fold 1 : 49.6875\n",
      "K-fold 2 : 50.50347222222222\n",
      "K-fold 3 : 50.50347222222222\n",
      "K-fold 4 : 49.80902777777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.27777777777778\n",
      "K-fold 1 : 49.65277777777778\n",
      "K-fold 2 : 50.90277777777778\n",
      "K-fold 3 : 50.27777777777778\n",
      "K-fold 4 : 49.166666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.05902777777778\n",
      "K-fold 4 : 51.12847222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.59027777777778\n",
      "K-fold 1 : 51.94444444444444\n",
      "K-fold 2 : 50.90277777777778\n",
      "K-fold 3 : 50.69444444444444\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.99305555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937538100613488\n",
      "K-fold 1 : 0.6940265291266972\n",
      "K-fold 2 : 0.6939438998699188\n",
      "K-fold 3 : 0.6933838248252868\n",
      "K-fold 4 : 0.6937809262010787\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932309788206349\n",
      "K-fold 1 : 0.6934646212536356\n",
      "K-fold 2 : 0.693212319975314\n",
      "K-fold 3 : 0.6931243590686632\n",
      "K-fold 4 : 0.6942055691843447\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931816094451481\n",
      "K-fold 1 : 0.6932387067211999\n",
      "K-fold 2 : 0.6934268295764923\n",
      "K-fold 3 : 0.6932083745797475\n",
      "K-fold 4 : 0.6933635705047183\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693133955416472\n",
      "K-fold 1 : 0.6931324575258337\n",
      "K-fold 2 : 0.6930251484331877\n",
      "K-fold 3 : 0.6931209849274677\n",
      "K-fold 4 : 0.6930549766706384\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930935045947197\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.173611111111114\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 49.95659722222222\n",
      "K-fold 4 : 49.123263888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.451388888888886\n",
      "K-fold 1 : 50.486111111111114\n",
      "K-fold 2 : 48.68055555555556\n",
      "K-fold 3 : 50.451388888888886\n",
      "K-fold 4 : 50.03472222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.111111111111114\n",
      "K-fold 1 : 51.44965277777778\n",
      "K-fold 2 : 50.98090277777778\n",
      "K-fold 3 : 51.119791666666664\n",
      "K-fold 4 : 51.12847222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.423611111111114\n",
      "K-fold 1 : 51.49305555555556\n",
      "K-fold 2 : 53.15972222222222\n",
      "K-fold 3 : 52.326388888888886\n",
      "K-fold 4 : 54.0625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.49305555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.694699356953303\n",
      "K-fold 1 : 0.6942757593260871\n",
      "K-fold 2 : 0.695953189002143\n",
      "K-fold 3 : 0.6952947941091325\n",
      "K-fold 4 : 0.694543555047777\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693151505097099\n",
      "K-fold 1 : 0.6931208087050397\n",
      "K-fold 2 : 0.695061955762946\n",
      "K-fold 3 : 0.7033871775088103\n",
      "K-fold 4 : 0.6959990859031677\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933796717060937\n",
      "K-fold 1 : 0.6936248315705194\n",
      "K-fold 2 : 0.6936198592185974\n",
      "K-fold 3 : 0.6936577585008409\n",
      "K-fold 4 : 0.693242033984926\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930542329083318\n",
      "K-fold 1 : 0.6923212098038715\n",
      "K-fold 2 : 0.6926142625186754\n",
      "K-fold 3 : 0.6927494795426078\n",
      "K-fold 4 : 0.6928230057591978\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927124381065368\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.52256944444444\n",
      "K-fold 1 : 48.967013888888886\n",
      "K-fold 2 : 49.375\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 50.46875\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.173611111111114\n",
      "K-fold 1 : 49.34027777777778\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 48.611111111111114\n",
      "K-fold 4 : 51.388888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.94618055555556\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.18055555555556\n",
      "K-fold 3 : 50.989583333333336\n",
      "K-fold 4 : 51.12847222222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.69444444444444\n",
      "K-fold 1 : 50.65972222222222\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.59722222222222\n",
      "K-fold 4 : 51.90972222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.18055555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6941286815537346\n",
      "K-fold 1 : 0.693968947728475\n",
      "K-fold 2 : 0.6939605739381578\n",
      "K-fold 3 : 0.6940095874998304\n",
      "K-fold 4 : 0.6941811164220174\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933759528657665\n",
      "K-fold 1 : 0.6932263452073802\n",
      "K-fold 2 : 0.6930521959843843\n",
      "K-fold 3 : 0.695923211781875\n",
      "K-fold 4 : 0.6928865961406542\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931535462538402\n",
      "K-fold 1 : 0.6932570212417178\n",
      "K-fold 2 : 0.6931731363137563\n",
      "K-fold 3 : 0.6932798259788089\n",
      "K-fold 4 : 0.6930801067087385\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931435828623564\n",
      "K-fold 1 : 0.6930455098981443\n",
      "K-fold 2 : 0.693003130995709\n",
      "K-fold 3 : 0.6926066098005875\n",
      "K-fold 4 : 0.6927593635476154\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929116394208825\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.130208333333336\n",
      "K-fold 1 : 50.060763888888886\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 50.27777777777778\n",
      "K-fold 4 : 49.123263888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.583333333333336\n",
      "K-fold 1 : 49.44444444444444\n",
      "K-fold 2 : 49.513888888888886\n",
      "K-fold 3 : 48.854166666666664\n",
      "K-fold 4 : 49.75694444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.954861111111114\n",
      "K-fold 1 : 51.05902777777778\n",
      "K-fold 2 : 51.39756944444444\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 51.18055555555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.43055555555556\n",
      "K-fold 1 : 51.423611111111114\n",
      "K-fold 2 : 52.291666666666664\n",
      "K-fold 3 : 52.916666666666664\n",
      "K-fold 4 : 52.56944444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.32638888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6971635434362623\n",
      "K-fold 1 : 0.6965313494205475\n",
      "K-fold 2 : 0.7070997019608816\n",
      "K-fold 3 : 0.6953717562887404\n",
      "K-fold 4 : 0.6995440191692777\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6936529201009999\n",
      "K-fold 1 : 0.6950806249742922\n",
      "K-fold 2 : 0.7273104864618053\n",
      "K-fold 3 : 0.6962428118871606\n",
      "K-fold 4 : 0.6929398360459701\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6938430064254337\n",
      "K-fold 1 : 0.6937298092577192\n",
      "K-fold 2 : 0.6938951121436225\n",
      "K-fold 3 : 0.6937276879946391\n",
      "K-fold 4 : 0.6941332618395487\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692437381848045\n",
      "K-fold 1 : 0.6926163124001544\n",
      "K-fold 2 : 0.6928867801376011\n",
      "K-fold 3 : 0.692262175290481\n",
      "K-fold 4 : 0.6910237955010455\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6922452890354654\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.470486111111114\n",
      "K-fold 1 : 50.182291666666664\n",
      "K-fold 2 : 49.817708333333336\n",
      "K-fold 3 : 49.704861111111114\n",
      "K-fold 4 : 50.14756944444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.479166666666664\n",
      "K-fold 1 : 50.03472222222222\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 49.375\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.41493055555556\n",
      "K-fold 1 : 50.92881944444444\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 51.09375\n",
      "K-fold 4 : 51.119791666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 51.979166666666664\n",
      "K-fold 2 : 52.013888888888886\n",
      "K-fold 3 : 50.625\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.17361111111111\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693974855211046\n",
      "K-fold 1 : 0.6937467561827766\n",
      "K-fold 2 : 0.6937788082493677\n",
      "K-fold 3 : 0.6937791652149624\n",
      "K-fold 4 : 0.6933289653725094\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6936036996219469\n",
      "K-fold 1 : 0.6932458722073099\n",
      "K-fold 2 : 0.6934504845867986\n",
      "K-fold 3 : 0.6940813660621643\n",
      "K-fold 4 : 0.6931458582048831\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932273977332645\n",
      "K-fold 1 : 0.6933363225724962\n",
      "K-fold 2 : 0.6933873448106977\n",
      "K-fold 3 : 0.6929630365636613\n",
      "K-fold 4 : 0.6933289653725094\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693106674629709\n",
      "K-fold 1 : 0.6930810342664304\n",
      "K-fold 2 : 0.6931324782578842\n",
      "K-fold 3 : 0.6930861784064252\n",
      "K-fold 4 : 0.6930355481479479\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930883827416794\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.026041666666664\n",
      "K-fold 1 : 49.244791666666664\n",
      "K-fold 2 : 50.017361111111114\n",
      "K-fold 3 : 50.607638888888886\n",
      "K-fold 4 : 50.15625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.65277777777778\n",
      "K-fold 1 : 49.30555555555556\n",
      "K-fold 2 : 49.548611111111114\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 50.86805555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 51.223958333333336\n",
      "K-fold 2 : 51.08506944444444\n",
      "K-fold 3 : 51.29340277777778\n",
      "K-fold 4 : 51.39756944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 53.020833333333336\n",
      "K-fold 1 : 52.1875\n",
      "K-fold 2 : 52.395833333333336\n",
      "K-fold 3 : 51.076388888888886\n",
      "K-fold 4 : 52.77777777777778\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.29166666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6944280505180359\n",
      "K-fold 1 : 0.6960442324479421\n",
      "K-fold 2 : 0.6999374886353811\n",
      "K-fold 3 : 0.6950671977467007\n",
      "K-fold 4 : 0.6967772927549151\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6949908292811849\n",
      "K-fold 1 : 0.6945801429126574\n",
      "K-fold 2 : 0.7117646958516992\n",
      "K-fold 3 : 0.6972754882729572\n",
      "K-fold 4 : 0.6951760882916658\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6942686047818926\n",
      "K-fold 1 : 0.69390290511979\n",
      "K-fold 2 : 0.6944530579778884\n",
      "K-fold 3 : 0.694370816151301\n",
      "K-fold 4 : 0.6941553294658661\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926145786824434\n",
      "K-fold 1 : 0.6926842927932739\n",
      "K-fold 2 : 0.6924693662187328\n",
      "K-fold 3 : 0.6932021534961202\n",
      "K-fold 4 : 0.692189740098041\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926320262577222\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.59027777777778\n",
      "K-fold 1 : 49.479166666666664\n",
      "K-fold 2 : 50.08680555555556\n",
      "K-fold 3 : 51.05902777777778\n",
      "K-fold 4 : 49.791666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.583333333333336\n",
      "K-fold 1 : 48.888888888888886\n",
      "K-fold 2 : 49.583333333333336\n",
      "K-fold 3 : 49.583333333333336\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.197916666666664\n",
      "K-fold 1 : 51.197916666666664\n",
      "K-fold 2 : 51.467013888888886\n",
      "K-fold 3 : 51.05902777777778\n",
      "K-fold 4 : 50.89409722222222\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.00694444444444\n",
      "K-fold 1 : 52.15277777777778\n",
      "K-fold 2 : 51.388888888888886\n",
      "K-fold 3 : 50.416666666666664\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.15972222222222\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934016333685981\n",
      "K-fold 1 : 0.6940307709905836\n",
      "K-fold 2 : 0.6937092343966166\n",
      "K-fold 3 : 0.6942194521427154\n",
      "K-fold 4 : 0.6937071747250028\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.694144966809646\n",
      "K-fold 1 : 0.6935030092363772\n",
      "K-fold 2 : 0.6932478236115497\n",
      "K-fold 3 : 0.6947084976279218\n",
      "K-fold 4 : 0.6932491400967473\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931324515077802\n",
      "K-fold 1 : 0.6930645108222961\n",
      "K-fold 2 : 0.6932332283920712\n",
      "K-fold 3 : 0.6931963370905982\n",
      "K-fold 4 : 0.6933238718244764\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930356699487438\n",
      "K-fold 1 : 0.6928804672282675\n",
      "K-fold 2 : 0.693121523960777\n",
      "K-fold 3 : 0.6931242994640184\n",
      "K-fold 4 : 0.6929789781570435\n",
      "---------------------------------\n",
      "Average best validation loss: 0.69302818775177\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_18_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.859375\n",
      "K-fold 1 : 51.189236111111114\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 49.84375\n",
      "K-fold 4 : 50.71180555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.40972222222222\n",
      "K-fold 1 : 49.93055555555556\n",
      "K-fold 2 : 51.111111111111114\n",
      "K-fold 3 : 48.78472222222222\n",
      "K-fold 4 : 48.68055555555556\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 51.189236111111114\n",
      "K-fold 2 : 50.71180555555556\n",
      "K-fold 3 : 51.52777777777778\n",
      "K-fold 4 : 51.24131944444444\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.86805555555556\n",
      "K-fold 1 : 50.27777777777778\n",
      "K-fold 2 : 51.28472222222222\n",
      "K-fold 3 : 51.21527777777778\n",
      "K-fold 4 : 51.31944444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.99305555555556\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693859561946657\n",
      "K-fold 1 : 0.693726913134257\n",
      "K-fold 2 : 0.6938788480228848\n",
      "K-fold 3 : 0.6937851760122511\n",
      "K-fold 4 : 0.693853978978263\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6949041796767194\n",
      "K-fold 1 : 0.6959033297455829\n",
      "K-fold 2 : 0.6931652919105862\n",
      "K-fold 3 : 0.6934740724770919\n",
      "K-fold 4 : 0.6952804637991864\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931569192144605\n",
      "K-fold 1 : 0.6931077639261881\n",
      "K-fold 2 : 0.693306612306171\n",
      "K-fold 3 : 0.6932051446702745\n",
      "K-fold 4 : 0.693057445022795\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931406907413317\n",
      "K-fold 1 : 0.6931443888208141\n",
      "K-fold 2 : 0.6929250800091288\n",
      "K-fold 3 : 0.6928298447443091\n",
      "K-fold 4 : 0.6927901972895083\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929660403210185\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_18_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.557291666666664\n",
      "K-fold 1 : 50.364583333333336\n",
      "K-fold 2 : 49.80902777777778\n",
      "K-fold 3 : 50.66840277777778\n",
      "K-fold 4 : 49.357638888888886\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 48.958333333333336\n",
      "K-fold 2 : 49.166666666666664\n",
      "K-fold 3 : 48.99305555555556\n",
      "K-fold 4 : 49.72222222222222\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.876736111111114\n",
      "K-fold 1 : 51.02430555555556\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 51.13715277777778\n",
      "K-fold 4 : 50.989583333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 50.833333333333336\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 50.27777777777778\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.81944444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937705801592933\n",
      "K-fold 1 : 0.6931932422849867\n",
      "K-fold 2 : 0.6937991347577837\n",
      "K-fold 3 : 0.693574955728319\n",
      "K-fold 4 : 0.693977681795756\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6951852492664171\n",
      "K-fold 1 : 0.6945752423742543\n",
      "K-fold 2 : 0.6942024023636527\n",
      "K-fold 3 : 0.6944392815880154\n",
      "K-fold 4 : 0.6939126693684122\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930379973517524\n",
      "K-fold 1 : 0.6929404748810662\n",
      "K-fold 2 : 0.6930482341183557\n",
      "K-fold 3 : 0.6930808597140842\n",
      "K-fold 4 : 0.6928814477390713\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693002972913825\n",
      "K-fold 1 : 0.6929110547770625\n",
      "K-fold 2 : 0.6929792476736981\n",
      "K-fold 3 : 0.69291090965271\n",
      "K-fold 4 : 0.6931284925212031\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929865355076997\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_36_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.078125\n",
      "K-fold 1 : 49.861111111111114\n",
      "K-fold 2 : 49.56597222222222\n",
      "K-fold 3 : 50.03472222222222\n",
      "K-fold 4 : 49.401041666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 50.104166666666664\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 51.076388888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.44097222222222\n",
      "K-fold 1 : 51.84027777777778\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.032986111111114\n",
      "K-fold 4 : 51.21527777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.90277777777778\n",
      "K-fold 1 : 50.104166666666664\n",
      "K-fold 2 : 50.97222222222222\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 51.5625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.909722222222214\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937183088726467\n",
      "K-fold 1 : 0.6939650926325056\n",
      "K-fold 2 : 0.6935385611322191\n",
      "K-fold 3 : 0.6936483482519785\n",
      "K-fold 4 : 0.6942615634865231\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934012563332267\n",
      "K-fold 1 : 0.6932094693183899\n",
      "K-fold 2 : 0.6930393447046694\n",
      "K-fold 3 : 0.6929825570272363\n",
      "K-fold 4 : 0.6930460152418717\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6927286280526055\n",
      "K-fold 1 : 0.6928776211208767\n",
      "K-fold 2 : 0.693198647763994\n",
      "K-fold 3 : 0.6930921541319953\n",
      "K-fold 4 : 0.693068939447403\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930172624795333\n",
      "K-fold 1 : 0.6931355595588684\n",
      "K-fold 2 : 0.6929712269617163\n",
      "K-fold 3 : 0.6929568026376807\n",
      "K-fold 4 : 0.6927816453187362\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929724993913069\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_36_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.529513888888886\n",
      "K-fold 1 : 50.373263888888886\n",
      "K-fold 2 : 49.470486111111114\n",
      "K-fold 3 : 50.61631944444444\n",
      "K-fold 4 : 48.87152777777778\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.826388888888886\n",
      "K-fold 1 : 50.24305555555556\n",
      "K-fold 2 : 49.75694444444444\n",
      "K-fold 3 : 49.895833333333336\n",
      "K-fold 4 : 51.458333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 51.032986111111114\n",
      "K-fold 2 : 51.432291666666664\n",
      "K-fold 3 : 51.501736111111114\n",
      "K-fold 4 : 51.09375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.173611111111114\n",
      "K-fold 1 : 50.24305555555556\n",
      "K-fold 2 : 50.24305555555556\n",
      "K-fold 3 : 50.104166666666664\n",
      "K-fold 4 : 51.458333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.44444444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6938221838739184\n",
      "K-fold 1 : 0.6937779201401605\n",
      "K-fold 2 : 0.6940387063556247\n",
      "K-fold 3 : 0.693398904800415\n",
      "K-fold 4 : 0.6948640975687239\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938896904820981\n",
      "K-fold 1 : 0.6931098932805269\n",
      "K-fold 2 : 0.6938391716583915\n",
      "K-fold 3 : 0.6934467735497848\n",
      "K-fold 4 : 0.6950426127599634\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931478142738342\n",
      "K-fold 1 : 0.6932479023933411\n",
      "K-fold 2 : 0.6929508003923628\n",
      "K-fold 3 : 0.6931219273143344\n",
      "K-fold 4 : 0.6929964979489645\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693147265392801\n",
      "K-fold 1 : 0.6931082217589669\n",
      "K-fold 2 : 0.693132397921189\n",
      "K-fold 3 : 0.6931463169014972\n",
      "K-fold 4 : 0.6926823465720467\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6930433097093001\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_72_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.876736111111114\n",
      "K-fold 1 : 50.14756944444444\n",
      "K-fold 2 : 49.583333333333336\n",
      "K-fold 3 : 50.546875\n",
      "K-fold 4 : 50.39930555555556\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.02777777777778\n",
      "K-fold 1 : 51.52777777777778\n",
      "K-fold 2 : 49.270833333333336\n",
      "K-fold 3 : 48.99305555555556\n",
      "K-fold 4 : 50.763888888888886\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.63194444444444\n",
      "K-fold 1 : 51.232638888888886\n",
      "K-fold 2 : 51.05902777777778\n",
      "K-fold 3 : 51.10243055555556\n",
      "K-fold 4 : 51.5625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 51.52777777777778\n",
      "K-fold 2 : 51.59722222222222\n",
      "K-fold 3 : 51.00694444444444\n",
      "K-fold 4 : 50.97222222222222\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.25\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937777492735121\n",
      "K-fold 1 : 0.6936342808935377\n",
      "K-fold 2 : 0.6940364638964335\n",
      "K-fold 3 : 0.6938212116559347\n",
      "K-fold 4 : 0.6937232428126865\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.695082135822462\n",
      "K-fold 1 : 0.6934538250384124\n",
      "K-fold 2 : 0.6934605629547782\n",
      "K-fold 3 : 0.6934597699538522\n",
      "K-fold 4 : 0.6930848411891771\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932539297474756\n",
      "K-fold 1 : 0.6932264029979706\n",
      "K-fold 2 : 0.6931674944029914\n",
      "K-fold 3 : 0.6929974456628164\n",
      "K-fold 4 : 0.6930850333637661\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929626309353373\n",
      "K-fold 1 : 0.6925609863322714\n",
      "K-fold 2 : 0.6928590898928435\n",
      "K-fold 3 : 0.6929438243741575\n",
      "K-fold 4 : 0.6928641433301179\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928381349729456\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_72_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.43402777777778\n",
      "K-fold 1 : 50.546875\n",
      "K-fold 2 : 50.03472222222222\n",
      "K-fold 3 : 49.869791666666664\n",
      "K-fold 4 : 50.052083333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.27777777777778\n",
      "K-fold 1 : 51.90972222222222\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 47.74305555555556\n",
      "K-fold 4 : 50.69444444444444\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 51.154513888888886\n",
      "K-fold 2 : 51.09375\n",
      "K-fold 3 : 51.015625\n",
      "K-fold 4 : 50.920138888888886\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.27777777777778\n",
      "K-fold 1 : 51.90972222222222\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 52.25694444444444\n",
      "K-fold 4 : 50.69444444444444\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.31944444444444\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6940290338463253\n",
      "K-fold 1 : 0.6938195314672259\n",
      "K-fold 2 : 0.6935337285200754\n",
      "K-fold 3 : 0.6939950883388519\n",
      "K-fold 4 : 0.6933968424797058\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931998937026315\n",
      "K-fold 1 : 0.6926828674648119\n",
      "K-fold 2 : 0.6928950781407563\n",
      "K-fold 3 : 0.696325755637625\n",
      "K-fold 4 : 0.6931562449621118\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930697282155355\n",
      "K-fold 1 : 0.6931798219680786\n",
      "K-fold 2 : 0.6931600239541795\n",
      "K-fold 3 : 0.6930939859814114\n",
      "K-fold 4 : 0.6931842790709601\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931387963502303\n",
      "K-fold 1 : 0.6925468833550162\n",
      "K-fold 2 : 0.6927592883939329\n",
      "K-fold 3 : 0.6921416546987451\n",
      "K-fold 4 : 0.693072453789089\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927318153174028\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_1_hidden_size_144_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.46006944444444\n",
      "K-fold 1 : 50.234375\n",
      "K-fold 2 : 50.546875\n",
      "K-fold 3 : 50.486111111111114\n",
      "K-fold 4 : 49.75694444444444\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.201388888888886\n",
      "K-fold 1 : 50.38194444444444\n",
      "K-fold 2 : 48.09027777777778\n",
      "K-fold 3 : 51.076388888888886\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.25868055555556\n",
      "K-fold 1 : 51.05034722222222\n",
      "K-fold 2 : 51.21527777777778\n",
      "K-fold 3 : 51.02430555555556\n",
      "K-fold 4 : 51.25868055555556\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.15277777777778\n",
      "K-fold 1 : 51.28472222222222\n",
      "K-fold 2 : 52.88194444444444\n",
      "K-fold 3 : 51.076388888888886\n",
      "K-fold 4 : 52.048611111111114\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.88888888888889\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6941172467337714\n",
      "K-fold 1 : 0.6942717929681143\n",
      "K-fold 2 : 0.6934584736824035\n",
      "K-fold 3 : 0.6937296708424886\n",
      "K-fold 4 : 0.6940332498815325\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6936623324518618\n",
      "K-fold 1 : 0.6931092687275099\n",
      "K-fold 2 : 0.6937204728955808\n",
      "K-fold 3 : 0.6930713446243949\n",
      "K-fold 4 : 0.6926223428353019\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930379827817281\n",
      "K-fold 1 : 0.6930902335378859\n",
      "K-fold 2 : 0.693206708961063\n",
      "K-fold 3 : 0.6931558575895097\n",
      "K-fold 4 : 0.6930814564228058\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692948377650717\n",
      "K-fold 1 : 0.6930518435395282\n",
      "K-fold 2 : 0.6920145128084265\n",
      "K-fold 3 : 0.69303072794624\n",
      "K-fold 4 : 0.6926223428353019\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927335609560428\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_9_num_hidden_2_hidden_size_144_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.61805555555556\n",
      "K-fold 1 : 49.592013888888886\n",
      "K-fold 2 : 49.982638888888886\n",
      "K-fold 3 : 49.505208333333336\n",
      "K-fold 4 : 50.15625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.44444444444444\n",
      "K-fold 1 : 48.36805555555556\n",
      "K-fold 2 : 49.30555555555556\n",
      "K-fold 3 : 49.479166666666664\n",
      "K-fold 4 : 49.236111111111114\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.97222222222222\n",
      "K-fold 1 : 50.842013888888886\n",
      "K-fold 2 : 51.232638888888886\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 50.90277777777778\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.55555555555556\n",
      "K-fold 1 : 51.63194444444444\n",
      "K-fold 2 : 50.69444444444444\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.84722222222223\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6948707269297706\n",
      "K-fold 1 : 0.6940222177240584\n",
      "K-fold 2 : 0.6942273239294688\n",
      "K-fold 3 : 0.6944630444049835\n",
      "K-fold 4 : 0.6934598022037082\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6937195192212644\n",
      "K-fold 1 : 0.6937499564626942\n",
      "K-fold 2 : 0.6938193777333135\n",
      "K-fold 3 : 0.6936836683231852\n",
      "K-fold 4 : 0.693591903085294\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931228829754723\n",
      "K-fold 1 : 0.6932350999779171\n",
      "K-fold 2 : 0.6929263797071245\n",
      "K-fold 3 : 0.6931347297297583\n",
      "K-fold 4 : 0.6927836345301734\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930952512699625\n",
      "K-fold 1 : 0.6925702691078186\n",
      "K-fold 2 : 0.6930953652962394\n",
      "K-fold 3 : 0.6930893167205479\n",
      "K-fold 4 : 0.6929799214653347\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929660247719805\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the hyperparameter combination already exists in CSV\n",
    "def is_hyperparameter_row_present(hyperparameters, existing_rows):\n",
    "    hyperparameter_tuple = tuple(sorted({\n",
    "        key: str(val) for key, val in  hyperparameters.items()\n",
    "    }.items()))\n",
    "    return hyperparameter_tuple in existing_rows\n",
    "\n",
    "# Initialize an empty set to store processed hyperparameter combinations\n",
    "existing_rows = set()\n",
    "\n",
    "# Check if the CSV file already exists and load existing rows\n",
    "if os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # Read the headers and rows from the existing file\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            # Convert each row back into a dictionary of hyperparameters\n",
    "            row_dict = dict(zip(headers, row))\n",
    "            row_dict.pop(\"val_acc\")\n",
    "            row_dict.pop(\"val_loss\")\n",
    "            # Create a hashable tuple for checking if the row already exists\n",
    "            existing_rows.add(tuple(sorted(row_dict.items())))\n",
    "\n",
    "# Iterate through hyperparameter combinations\n",
    "for lr in lr_values:\n",
    "    for alpha in alpha_values:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            for num_hidden in num_hidden_layers:\n",
    "                hyperparameters = {\n",
    "                    \"num_hidden\": num_hidden,\n",
    "                    \"hidden_size\": hidden_layer_size,\n",
    "                    \"lr\": lr, \n",
    "                    \"alpha\": alpha, \n",
    "                    \"batch_size\": 128, \n",
    "                    \"num_epochs\": 100\n",
    "                }\n",
    "\n",
    "                # Check if this combination has already been processed\n",
    "                if is_hyperparameter_row_present(hyperparameters, existing_rows):\n",
    "                    print(f\"Skipping already processed hyperparameter combination: {hyperparameters}\")\n",
    "                    continue  # Skip to the next combination\n",
    "\n",
    "                # Compute the result (training the model)\n",
    "                val_acc, val_loss = model_training(hyperparameters)\n",
    "\n",
    "                # Prepare the result row\n",
    "                result_row = {**hyperparameters, \"val_acc\": val_acc, \"val_loss\": val_loss}\n",
    "\n",
    "                # Append the result to the CSV file\n",
    "                with open(csv_file_path, mode='a', newline='') as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=result_row.keys())\n",
    "                    \n",
    "                    # Write header only if the file is empty (first write)\n",
    "                    if f.tell() == 0:\n",
    "                        writer.writeheader()\n",
    "                    \n",
    "                    writer.writerow(result_row)\n",
    "\n",
    "                # Add this combination to the existing_rows set to avoid recalculation in future runs\n",
    "                existing_rows.add(tuple(sorted(hyperparameters.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_thresholds = {\n",
    "    9: 0.95,\n",
    "    12: 0.925,\n",
    "    15: 0.9,\n",
    "}\n",
    "\n",
    "def plot_val_accuracy_vs(n, hyperparameter, desc):\n",
    "    \"\"\"\n",
    "    Plot validation accuracy vs a given hyperparameter, with points equidistant on the x-axis.\n",
    "    Add validation accuracy values on top of each point using annotations and manage layout.\n",
    "    \n",
    "    Parameters:\n",
    "        n (int): Used for naming and computations.\n",
    "        hyperparameter (str): The hyperparameter to plot against.\n",
    "        desc (str): Description or label for the hyperparameter axis.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_file_path = f\"hyperparameter_tuning_results-{n}.csv\"\n",
    "    selected_hyperparameters = {\n",
    "        \"num_hidden\": 1,\n",
    "        \"hidden_size\": 4 * n,\n",
    "        \"lr\": 0.01, \n",
    "        \"alpha\": 0.0001, \n",
    "        \"batch_size\": 128, \n",
    "        \"num_epochs\": 100\n",
    "    }\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    data[\"val_acc\"] /= 100  # Optional normalization for val_acc (remove if not needed)\n",
    "    \n",
    "    # Dynamically build the filter condition\n",
    "    filter_condition = pd.Series([True] * len(data))\n",
    "    for key, value in selected_hyperparameters.items():\n",
    "        if key != hyperparameter:\n",
    "            filter_condition &= (data[key] == value)\n",
    "    filtered_data = data[filter_condition]\n",
    "    \n",
    "    # Plot using equidistant points\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    x_positions = range(len(filtered_data))  # Equidistant points\n",
    "    plt.plot(x_positions, filtered_data['val_acc'], marker='o', linestyle='-', label=\"Validation accuracy\")\n",
    "    \n",
    "    # Replace x-axis ticks with hyperparameter values\n",
    "    if hyperparameter == \"hidden_size\":\n",
    "        ticks = [f\"{int(tick/n)}n\" for tick in filtered_data[hyperparameter]]\n",
    "    else:\n",
    "        ticks = filtered_data[hyperparameter]\n",
    "    plt.xticks(x_positions, ticks, rotation=45)\n",
    "    \n",
    "    # Add validation accuracy values as annotations\n",
    "    for x, val in zip(x_positions, filtered_data['val_acc']):\n",
    "        plt.annotate(\n",
    "            f\"{val:.2f}\",  # Text to annotate\n",
    "            (x, val),  # Point to annotate\n",
    "            textcoords=\"offset points\",  # Offset the text position\n",
    "            xytext=(0, 10),  # Position 10 points above the data point\n",
    "            ha='center', fontsize=9  # Center-align the text\n",
    "        )\n",
    "        \n",
    "    # Add red dashed line for accuracy threshold\n",
    "    if n in accuracy_thresholds:\n",
    "        threshold = accuracy_thresholds[n]\n",
    "        plt.axhline(y=threshold, color='red', linestyle='--', label=f'Acuuracy threshold {threshold:.2f}')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(desc)\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title(f'Validation Accuracy vs {desc} (n = {n})')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(top=1, bottom=0.5)\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()  # Apply tight layout after adjusting\n",
    "    \n",
    "    # Save the plot with bbox_inches='tight' to include all elements\n",
    "    plt.savefig(f\"Plots/hyperparameter-tuning-{hyperparameter}-n-{n}.svg\", format=\"svg\", bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [9, 12, 15]:\n",
    "    plot_val_accuracy_vs(n, \"hidden_size\", \"Hidden layer size\")\n",
    "    plot_val_accuracy_vs(n, \"lr\", \"Learning rate\")\n",
    "    plot_val_accuracy_vs(n, \"alpha\", \"Weight decay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
