{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Type\n",
    "n=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data and convert to tensor\n",
    "binary = True\n",
    "\n",
    "X = np.load(\"Datasets/kryptonite-%s-X.npy\"%(n))\n",
    "y = np.load(\"Datasets/kryptonite-%s-y.npy\"%(n))\n",
    "if binary:\n",
    "    X = np.where(X>0.5, 1, 0)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 20% test\n",
    "\n",
    "X_temp = torch.tensor(X_temp.astype(np.float32)).to(device)\n",
    "y_temp = torch.tensor(y_temp.astype(np.float32)).unsqueeze(1).to(device)\n",
    "\n",
    "X_test = torch.tensor(X_test.astype(np.float32)).to(device)\n",
    "y_test = torch.tensor(y_test.astype(np.float32)).unsqueeze(1).to(device)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layer_size, num_hidden_layers):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_layer_size),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        for _ in range(num_hidden_layers-1):\n",
    "            layers.append(nn.Linear(hidden_layer_size, hidden_layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        layers.append(nn.Linear(hidden_layer_size, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenise(lists):\n",
    "    max_length = max(len(sublist) for sublist in lists)  # Find the length of the longest list\n",
    "    for sublist in lists:\n",
    "        sublist.extend([sublist[-1]] * (max_length - len(sublist)))  # Extend with last element\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path(\"Plots/HyperparameterTuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_acc_list, val_acc_list, id=None):\n",
    "    # Mean and std across each each kth fold of validation\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    for i in range(5):\n",
    "        train_acc.append(train_acc_list[i])\n",
    "        val_acc.append(val_acc_list[i])\n",
    "\n",
    "    train_acc = np.array(homogenise(train_acc))\n",
    "    val_acc = np.array(homogenise(val_acc))\n",
    "\n",
    "    train_mean = np.mean(train_acc, axis=0)\n",
    "    val_mean = np.mean(val_acc, axis=0)\n",
    "\n",
    "    train_std = np.std(train_acc, axis=0)\n",
    "    val_std = np.std(val_acc, axis=0)\n",
    "\n",
    "    plt.plot(train_mean)\n",
    "    plt.fill_between(range(len(train_mean)),train_mean-train_std,train_mean+train_std,alpha=.6)\n",
    "    plt.title(\"Training Accuracy per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/train_acc_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/train_acc.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(val_mean)\n",
    "    plt.fill_between(range(len(val_mean)),val_mean-val_std,val_mean+val_std,alpha=.6)\n",
    "    plt.title(\"Validation Accuracy per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/val_acc_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/val_acc.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Training accuracy (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_acc[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Validation accuracy (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_acc[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    print(\"Training accuracy (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_acc[i].max())\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    average_best_validation_accuracy = 0\n",
    "    print(\"Validation accuracy (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_acc[i].max())\n",
    "        average_best_validation_accuracy += val_acc[i].max()\n",
    "    print(\"---------------------------------\")\n",
    "    average_best_validation_accuracy /= 5\n",
    "    \n",
    "    print(f\"Average best validation accuracy: {average_best_validation_accuracy}\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    return average_best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss_list, val_loss_list, id=None):\n",
    "    # Mean and std across each each kth fold of validation\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for i in range(5):\n",
    "        train_loss.append(train_loss_list[i])\n",
    "        val_loss.append(val_loss_list[i])\n",
    "\n",
    "    train_loss = np.array(homogenise(train_loss))\n",
    "    val_loss = np.array(homogenise(val_loss))\n",
    "\n",
    "    train_mean = np.mean(train_loss, axis=0)\n",
    "    val_mean = np.mean(val_loss, axis=0)\n",
    "\n",
    "    train_std = np.std(train_loss, axis=0)\n",
    "    val_std = np.std(val_loss, axis=0)\n",
    "\n",
    "    plt.plot(train_mean)\n",
    "    plt.fill_between(range(len(train_mean)),train_mean-train_std,train_mean+train_std,alpha=.6)\n",
    "    plt.title(\"Training Loss per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/train_loss_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/train_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(val_mean)\n",
    "    plt.fill_between(range(len(val_mean)),val_mean-val_std,val_mean+val_std,alpha=.6)\n",
    "    plt.title(\"Validation Loss per epoch\")\n",
    "    if id:\n",
    "        plt.savefig(f\"{dir}/val_loss_{id}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"{dir}/val_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Training loss (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_loss[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Validation loss (last epoch)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_loss[i][-1])\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    print(\"Training loss best\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", train_loss[i].min())\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    avg_best_validation_loss = 0\n",
    "    print(\"Validation loss (best)\")\n",
    "    for i in range(5):\n",
    "        print(\"K-fold\", i, \":\", val_loss[i].min())\n",
    "        avg_best_validation_loss += val_loss[i].min()\n",
    "    print(\"---------------------------------\")\n",
    "    avg_best_validation_loss /= 5\n",
    "    \n",
    "    print(f\"Average best validation loss: {avg_best_validation_loss}\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    return avg_best_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(hyperparameters):\n",
    "    # Store loss and accuracy for each K-fold \n",
    "    train_acc_list={0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    val_acc_list = {0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "\n",
    "    train_loss_list={0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    val_loss_list = {0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "    \n",
    "    # Enable or disable early stopping\n",
    "    early_stopping_enabled = False\n",
    "\n",
    "    # K-fold training loop\n",
    "    count=0\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train_index, val_index in kf.split(X_temp):\n",
    "        X_train_tensor, X_val_tensor = X_temp[train_index], X_temp[val_index]\n",
    "        y_train_tensor, y_val_tensor = y_temp[train_index], y_temp[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=hyperparameters[\"batch_size\"])\n",
    "\n",
    "        model = NeuralNet(n, hyperparameters[\"hidden_size\"], hyperparameters[\"num_hidden\"]).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparameters[\"lr\"], weight_decay=hyperparameters[\"alpha\"])\n",
    "\n",
    "        num_epochs = hyperparameters[\"num_epochs\"]\n",
    "        \n",
    "        # Variables required for early stopping\n",
    "        early_stopping_counter = 0\n",
    "        patience = 5\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for _ in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0 # accuracy cal\n",
    "            for input, label in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                correct += (outputs.round()==label).float().sum().item()\n",
    "                running_loss+=loss.item()\n",
    "\n",
    "            avg_loss = running_loss/len(train_loader)\n",
    "            accuracy = 100*correct/len(X_train_tensor)\n",
    "            train_loss_list[count].append(avg_loss)\n",
    "            train_acc_list[count].append(accuracy)\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss = 0.0\n",
    "            correct = 0\n",
    "            for input, label in val_loader:\n",
    "                target = model(input)\n",
    "                loss = criterion(target, label)\n",
    "                valid_loss += loss.item()\n",
    "                correct += (target.round()==label).float().sum().item()\n",
    "            avg_loss = valid_loss/len(val_loader)\n",
    "            accuracy = 100*correct/len(X_val_tensor)\n",
    "            val_loss_list[count].append(avg_loss)\n",
    "            val_acc_list[count].append(accuracy)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if early_stopping_enabled:\n",
    "                if avg_loss < best_val_loss:\n",
    "                    best_val_loss = avg_loss\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                if early_stopping_counter > patience:\n",
    "                    break\n",
    "                \n",
    "        count+=1\n",
    "\n",
    "    file_id_for_plot = f\"n_{n}\"\n",
    "    for key, val in hyperparameters.items():\n",
    "        file_id_for_plot += f\"_{key}_{val}\"\n",
    "    file_id_for_plot = file_id_for_plot.replace(\".\", \"-\")\n",
    "    \n",
    "    print(\"---------------------------------\")\n",
    "    print(file_id_for_plot)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    average_best_validation_accuracy = plot_accuracy(train_acc_list, val_acc_list, id=file_id_for_plot)\n",
    "    avg_best_validation_loss = plot_losses(train_loss_list, val_loss_list, id=file_id_for_plot)\n",
    "    \n",
    "    return average_best_validation_accuracy, avg_best_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter combinations\n",
    "lr_values = [0.001, 0.01, 0.05, 0.1]\n",
    "alpha_values = [0.0001, 0.001, 0.01, 0.1]\n",
    "hidden_layer_sizes = [2*n, 4*n, 8*n, 16*n]\n",
    "num_hidden_layers = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.48697916666667\n",
      "K-fold 1 : 90.64453125\n",
      "K-fold 2 : 91.33463541666667\n",
      "K-fold 3 : 86.06119791666667\n",
      "K-fold 4 : 93.88020833333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 92.76041666666667\n",
      "K-fold 1 : 90.3125\n",
      "K-fold 2 : 91.40625\n",
      "K-fold 3 : 85.26041666666667\n",
      "K-fold 4 : 94.16666666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 92.48697916666667\n",
      "K-fold 1 : 90.64453125\n",
      "K-fold 2 : 91.33463541666667\n",
      "K-fold 3 : 86.06119791666667\n",
      "K-fold 4 : 93.99088541666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 92.890625\n",
      "K-fold 1 : 90.703125\n",
      "K-fold 2 : 91.40625\n",
      "K-fold 3 : 85.52083333333333\n",
      "K-fold 4 : 94.27083333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 90.95833333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2915234316140413\n",
      "K-fold 1 : 0.30387099186579386\n",
      "K-fold 2 : 0.29161298597852386\n",
      "K-fold 3 : 0.3556473236531019\n",
      "K-fold 4 : 0.2654620632529259\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2930496513843536\n",
      "K-fold 1 : 0.31271530091762545\n",
      "K-fold 2 : 0.2931800976395607\n",
      "K-fold 3 : 0.36003828247388203\n",
      "K-fold 4 : 0.2661247506737709\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2915234316140413\n",
      "K-fold 1 : 0.30387099186579386\n",
      "K-fold 2 : 0.29161298597852386\n",
      "K-fold 3 : 0.3556473236531019\n",
      "K-fold 4 : 0.2654620632529259\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2930496513843536\n",
      "K-fold 1 : 0.31215198189020155\n",
      "K-fold 2 : 0.2931800976395607\n",
      "K-fold 3 : 0.36003828247388203\n",
      "K-fold 4 : 0.2661247506737709\n",
      "---------------------------------\n",
      "Average best validation loss: 0.30490895281235375\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.8203125\n",
      "K-fold 1 : 95.0\n",
      "K-fold 2 : 96.45182291666667\n",
      "K-fold 3 : 96.06770833333333\n",
      "K-fold 4 : 95.52734375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.234375\n",
      "K-fold 2 : 96.11979166666667\n",
      "K-fold 3 : 95.80729166666667\n",
      "K-fold 4 : 95.41666666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.8203125\n",
      "K-fold 1 : 95.1171875\n",
      "K-fold 2 : 96.45182291666667\n",
      "K-fold 3 : 96.06770833333333\n",
      "K-fold 4 : 95.59895833333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 95.80729166666667\n",
      "K-fold 2 : 96.11979166666667\n",
      "K-fold 3 : 95.96354166666667\n",
      "K-fold 4 : 95.78125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.90104166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17202132493257521\n",
      "K-fold 1 : 0.18943164870142937\n",
      "K-fold 2 : 0.15317557075371344\n",
      "K-fold 3 : 0.1609319691856702\n",
      "K-fold 4 : 0.17527971211820842\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17658013353745142\n",
      "K-fold 1 : 0.1911349765956402\n",
      "K-fold 2 : 0.17144748245676358\n",
      "K-fold 3 : 0.1809931884209315\n",
      "K-fold 4 : 0.18685390030344326\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17083265458544095\n",
      "K-fold 1 : 0.18943164870142937\n",
      "K-fold 2 : 0.152163392615815\n",
      "K-fold 3 : 0.1609319691856702\n",
      "K-fold 4 : 0.17425029780715703\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.17425573393702506\n",
      "K-fold 1 : 0.1911349765956402\n",
      "K-fold 2 : 0.17144748245676358\n",
      "K-fold 3 : 0.1744123046596845\n",
      "K-fold 4 : 0.1822524331510067\n",
      "---------------------------------\n",
      "Average best validation loss: 0.178700586160024\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.97005208333333\n",
      "K-fold 1 : 92.90364583333333\n",
      "K-fold 2 : 91.5234375\n",
      "K-fold 3 : 95.76822916666667\n",
      "K-fold 4 : 95.05208333333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.59895833333333\n",
      "K-fold 1 : 91.69270833333333\n",
      "K-fold 2 : 91.38020833333333\n",
      "K-fold 3 : 94.765625\n",
      "K-fold 4 : 95.44270833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.99609375\n",
      "K-fold 1 : 92.90364583333333\n",
      "K-fold 2 : 91.5234375\n",
      "K-fold 3 : 95.76822916666667\n",
      "K-fold 4 : 95.05208333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.59895833333333\n",
      "K-fold 1 : 91.77083333333333\n",
      "K-fold 2 : 91.43229166666667\n",
      "K-fold 3 : 94.765625\n",
      "K-fold 4 : 95.98958333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 93.91145833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.20114983065674702\n",
      "K-fold 1 : 0.2650208520392577\n",
      "K-fold 2 : 0.2969281622519096\n",
      "K-fold 3 : 0.20397421872864166\n",
      "K-fold 4 : 0.2378171568115552\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.215546881655852\n",
      "K-fold 1 : 0.27829447388648987\n",
      "K-fold 2 : 0.3059924304485321\n",
      "K-fold 3 : 0.22758621722459793\n",
      "K-fold 4 : 0.2251687650879224\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.20114983065674702\n",
      "K-fold 1 : 0.2650208520392577\n",
      "K-fold 2 : 0.2969281622519096\n",
      "K-fold 3 : 0.20397421872864166\n",
      "K-fold 4 : 0.2378171568115552\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.215546881655852\n",
      "K-fold 1 : 0.27829447388648987\n",
      "K-fold 2 : 0.3059924304485321\n",
      "K-fold 3 : 0.22758621722459793\n",
      "K-fold 4 : 0.2251687650879224\n",
      "---------------------------------\n",
      "Average best validation loss: 0.25051775366067885\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.53645833333333\n",
      "K-fold 1 : 96.41927083333333\n",
      "K-fold 2 : 96.31510416666667\n",
      "K-fold 3 : 96.2890625\n",
      "K-fold 4 : 96.31510416666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.67708333333333\n",
      "K-fold 1 : 96.27604166666667\n",
      "K-fold 2 : 96.66666666666667\n",
      "K-fold 3 : 96.640625\n",
      "K-fold 4 : 96.53645833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.53645833333333\n",
      "K-fold 1 : 96.41927083333333\n",
      "K-fold 2 : 96.32161458333333\n",
      "K-fold 3 : 96.29557291666667\n",
      "K-fold 4 : 96.33463541666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.67708333333333\n",
      "K-fold 1 : 96.27604166666667\n",
      "K-fold 2 : 96.66666666666667\n",
      "K-fold 3 : 96.77083333333333\n",
      "K-fold 4 : 96.53645833333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.13896199654166896\n",
      "K-fold 1 : 0.1435533368960023\n",
      "K-fold 2 : 0.14736984570821127\n",
      "K-fold 3 : 0.15285882658014696\n",
      "K-fold 4 : 0.14897615977873405\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19505107228954632\n",
      "K-fold 1 : 0.17520428001880645\n",
      "K-fold 2 : 0.16103103682398795\n",
      "K-fold 3 : 0.16222784419854483\n",
      "K-fold 4 : 0.16667307193080586\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.13896199654166896\n",
      "K-fold 1 : 0.14157403235634167\n",
      "K-fold 2 : 0.14736984570821127\n",
      "K-fold 3 : 0.14879608741030098\n",
      "K-fold 4 : 0.14897615977873405\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1920783278842767\n",
      "K-fold 1 : 0.16836442003647487\n",
      "K-fold 2 : 0.1556704729795456\n",
      "K-fold 3 : 0.15030125975608827\n",
      "K-fold 4 : 0.16420055230458577\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16612300659219423\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.3671875\n",
      "K-fold 1 : 96.26302083333333\n",
      "K-fold 2 : 96.47135416666667\n",
      "K-fold 3 : 96.39973958333333\n",
      "K-fold 4 : 96.20442708333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.25\n",
      "K-fold 1 : 96.53645833333333\n",
      "K-fold 2 : 96.04166666666667\n",
      "K-fold 3 : 95.98958333333333\n",
      "K-fold 4 : 96.90104166666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.38020833333333\n",
      "K-fold 1 : 96.28255208333333\n",
      "K-fold 2 : 96.47786458333333\n",
      "K-fold 3 : 96.41927083333333\n",
      "K-fold 4 : 96.21744791666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.30208333333333\n",
      "K-fold 1 : 96.53645833333333\n",
      "K-fold 2 : 96.04166666666667\n",
      "K-fold 3 : 96.015625\n",
      "K-fold 4 : 96.953125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.36979166666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17827816121280193\n",
      "K-fold 1 : 0.16990882077564795\n",
      "K-fold 2 : 0.1650412820279598\n",
      "K-fold 3 : 0.16989865843206645\n",
      "K-fold 4 : 0.1803603406374653\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.196437523017327\n",
      "K-fold 1 : 0.17654850979646047\n",
      "K-fold 2 : 0.18661448483665785\n",
      "K-fold 3 : 0.19353326559066772\n",
      "K-fold 4 : 0.16828274205327035\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17827816121280193\n",
      "K-fold 1 : 0.16990882077564795\n",
      "K-fold 2 : 0.16503751886387666\n",
      "K-fold 3 : 0.16954479000220696\n",
      "K-fold 4 : 0.1803603406374653\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.1948477144042651\n",
      "K-fold 1 : 0.17554858972628912\n",
      "K-fold 2 : 0.18418152655164402\n",
      "K-fold 3 : 0.19353326559066772\n",
      "K-fold 4 : 0.16828274205327035\n",
      "---------------------------------\n",
      "Average best validation loss: 0.18327876766522727\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.34114583333333\n",
      "K-fold 1 : 96.40625\n",
      "K-fold 2 : 96.22395833333333\n",
      "K-fold 3 : 96.3671875\n",
      "K-fold 4 : 96.35416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.40625\n",
      "K-fold 1 : 95.9375\n",
      "K-fold 2 : 96.61458333333333\n",
      "K-fold 3 : 96.11979166666667\n",
      "K-fold 4 : 96.51041666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.38020833333333\n",
      "K-fold 1 : 96.49088541666667\n",
      "K-fold 2 : 96.30208333333333\n",
      "K-fold 3 : 96.45833333333333\n",
      "K-fold 4 : 96.35416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.45833333333333\n",
      "K-fold 1 : 96.04166666666667\n",
      "K-fold 2 : 96.71875\n",
      "K-fold 3 : 96.11979166666667\n",
      "K-fold 4 : 96.58854166666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.13708993205800651\n",
      "K-fold 1 : 0.1355561787262559\n",
      "K-fold 2 : 0.1430206616098682\n",
      "K-fold 3 : 0.13600708314528068\n",
      "K-fold 4 : 0.13884898473819096\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16919435436526933\n",
      "K-fold 1 : 0.18737499850491682\n",
      "K-fold 2 : 0.1592537720998128\n",
      "K-fold 3 : 0.18507603108882903\n",
      "K-fold 4 : 0.1642236811419328\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.13708993205800651\n",
      "K-fold 1 : 0.13304143641144037\n",
      "K-fold 2 : 0.14088411101450524\n",
      "K-fold 3 : 0.13356272326782345\n",
      "K-fold 4 : 0.13716619809468586\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15970026440918444\n",
      "K-fold 1 : 0.1798216407497724\n",
      "K-fold 2 : 0.15326561604936917\n",
      "K-fold 3 : 0.1808572029074033\n",
      "K-fold 4 : 0.15553627014160157\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16583619885146617\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.3671875\n",
      "K-fold 1 : 96.43229166666667\n",
      "K-fold 2 : 96.47135416666667\n",
      "K-fold 3 : 96.2890625\n",
      "K-fold 4 : 96.36067708333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.45833333333333\n",
      "K-fold 1 : 96.06770833333333\n",
      "K-fold 2 : 96.015625\n",
      "K-fold 3 : 96.77083333333333\n",
      "K-fold 4 : 96.484375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.3671875\n",
      "K-fold 1 : 96.43880208333333\n",
      "K-fold 2 : 96.47786458333333\n",
      "K-fold 3 : 96.2890625\n",
      "K-fold 4 : 96.3671875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.45833333333333\n",
      "K-fold 1 : 96.19791666666667\n",
      "K-fold 2 : 96.015625\n",
      "K-fold 3 : 96.77083333333333\n",
      "K-fold 4 : 96.484375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1543673176318407\n",
      "K-fold 1 : 0.15330320441474518\n",
      "K-fold 2 : 0.15212658957267802\n",
      "K-fold 3 : 0.15429782414187987\n",
      "K-fold 4 : 0.15360398031771183\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16471386303504307\n",
      "K-fold 1 : 0.18649906441569328\n",
      "K-fold 2 : 0.1801354224483172\n",
      "K-fold 3 : 0.15414961899320284\n",
      "K-fold 4 : 0.16839230209589004\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15433643323679766\n",
      "K-fold 1 : 0.15330320441474518\n",
      "K-fold 2 : 0.15212658957267802\n",
      "K-fold 3 : 0.15429782414187987\n",
      "K-fold 4 : 0.15259635398785273\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16471386303504307\n",
      "K-fold 1 : 0.1809789642691612\n",
      "K-fold 2 : 0.17829005767901737\n",
      "K-fold 3 : 0.1532466933131218\n",
      "K-fold 4 : 0.16839230209589004\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16912437607844671\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-001_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.31510416666667\n",
      "K-fold 1 : 96.26953125\n",
      "K-fold 2 : 96.39322916666667\n",
      "K-fold 3 : 96.20442708333333\n",
      "K-fold 4 : 96.31510416666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 96.58854166666667\n",
      "K-fold 2 : 95.83333333333333\n",
      "K-fold 3 : 96.30208333333333\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.40625\n",
      "K-fold 1 : 96.32161458333333\n",
      "K-fold 2 : 96.46484375\n",
      "K-fold 3 : 96.36067708333333\n",
      "K-fold 4 : 96.40625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.27604166666667\n",
      "K-fold 1 : 96.69270833333333\n",
      "K-fold 2 : 96.09375\n",
      "K-fold 3 : 96.53645833333333\n",
      "K-fold 4 : 96.35416666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.390625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.12458618143573404\n",
      "K-fold 1 : 0.12947870722661417\n",
      "K-fold 2 : 0.12369191739708185\n",
      "K-fold 3 : 0.12210352960973977\n",
      "K-fold 4 : 0.11952122272923589\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2042467859884103\n",
      "K-fold 1 : 0.1707886797686418\n",
      "K-fold 2 : 0.19257492845257124\n",
      "K-fold 3 : 0.1782206964989503\n",
      "K-fold 4 : 0.19326032400131227\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1195705340243876\n",
      "K-fold 1 : 0.12772184836988648\n",
      "K-fold 2 : 0.11997399255633354\n",
      "K-fold 3 : 0.11995846253509322\n",
      "K-fold 4 : 0.11869062806169192\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16943938980499904\n",
      "K-fold 1 : 0.15729883561531702\n",
      "K-fold 2 : 0.17676940883199374\n",
      "K-fold 3 : 0.1592226897676786\n",
      "K-fold 4 : 0.1706451120475928\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16667508721351626\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.25911458333333\n",
      "K-fold 1 : 86.04817708333333\n",
      "K-fold 2 : 91.46484375\n",
      "K-fold 3 : 78.11197916666667\n",
      "K-fold 4 : 79.79166666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 90.80729166666667\n",
      "K-fold 1 : 86.14583333333333\n",
      "K-fold 2 : 91.84895833333333\n",
      "K-fold 3 : 77.8125\n",
      "K-fold 4 : 79.53125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 92.25911458333333\n",
      "K-fold 1 : 86.04817708333333\n",
      "K-fold 2 : 91.47786458333333\n",
      "K-fold 3 : 78.13151041666667\n",
      "K-fold 4 : 79.87630208333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 90.859375\n",
      "K-fold 1 : 86.14583333333333\n",
      "K-fold 2 : 91.84895833333333\n",
      "K-fold 3 : 77.8125\n",
      "K-fold 4 : 80.0\n",
      "---------------------------------\n",
      "Average best validation accuracy: 85.33333333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2888618192325036\n",
      "K-fold 1 : 0.4044679860273997\n",
      "K-fold 2 : 0.3312269395838181\n",
      "K-fold 3 : 0.5133976933856805\n",
      "K-fold 4 : 0.47847118228673935\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.307574991385142\n",
      "K-fold 1 : 0.3992442508538564\n",
      "K-fold 2 : 0.32124954064687095\n",
      "K-fold 3 : 0.5161071727673213\n",
      "K-fold 4 : 0.4836663454771042\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2888618192325036\n",
      "K-fold 1 : 0.4044679860273997\n",
      "K-fold 2 : 0.3312269395838181\n",
      "K-fold 3 : 0.5133976933856805\n",
      "K-fold 4 : 0.47847118228673935\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.307574991385142\n",
      "K-fold 1 : 0.3992442508538564\n",
      "K-fold 2 : 0.32124954064687095\n",
      "K-fold 3 : 0.5161071727673213\n",
      "K-fold 4 : 0.4836663454771042\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4055684602260589\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 94.66145833333333\n",
      "K-fold 1 : 95.56640625\n",
      "K-fold 2 : 95.26692708333333\n",
      "K-fold 3 : 95.18880208333333\n",
      "K-fold 4 : 94.9609375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 94.34895833333333\n",
      "K-fold 1 : 94.81770833333333\n",
      "K-fold 2 : 95.57291666666667\n",
      "K-fold 3 : 95.13020833333333\n",
      "K-fold 4 : 95.703125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 94.66145833333333\n",
      "K-fold 1 : 95.67057291666667\n",
      "K-fold 2 : 95.26692708333333\n",
      "K-fold 3 : 95.22786458333333\n",
      "K-fold 4 : 94.96744791666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 94.34895833333333\n",
      "K-fold 1 : 95.3125\n",
      "K-fold 2 : 95.57291666666667\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.703125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.33333333333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.20056437545766434\n",
      "K-fold 1 : 0.199606905815502\n",
      "K-fold 2 : 0.19056239016354085\n",
      "K-fold 3 : 0.2018532923112313\n",
      "K-fold 4 : 0.19140988700091838\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.21961153745651246\n",
      "K-fold 1 : 0.2127569357554118\n",
      "K-fold 2 : 0.19735951671997706\n",
      "K-fold 3 : 0.2005691652496656\n",
      "K-fold 4 : 0.1843523008128007\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.20056437545766434\n",
      "K-fold 1 : 0.1984786763166388\n",
      "K-fold 2 : 0.1905511881535252\n",
      "K-fold 3 : 0.2017573098341624\n",
      "K-fold 4 : 0.19109953089306753\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.219123142460982\n",
      "K-fold 1 : 0.21185387372970582\n",
      "K-fold 2 : 0.19249416540066402\n",
      "K-fold 3 : 0.20021896560986838\n",
      "K-fold 4 : 0.17925865650177003\n",
      "---------------------------------\n",
      "Average best validation loss: 0.20058976074059806\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 89.30989583333333\n",
      "K-fold 1 : 95.0390625\n",
      "K-fold 2 : 94.67447916666667\n",
      "K-fold 3 : 94.6875\n",
      "K-fold 4 : 94.56380208333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 89.08854166666667\n",
      "K-fold 1 : 95.36458333333333\n",
      "K-fold 2 : 94.21875\n",
      "K-fold 3 : 94.81770833333333\n",
      "K-fold 4 : 94.66145833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 89.4140625\n",
      "K-fold 1 : 95.04557291666667\n",
      "K-fold 2 : 94.74609375\n",
      "K-fold 3 : 94.75911458333333\n",
      "K-fold 4 : 94.67447916666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 89.34895833333333\n",
      "K-fold 1 : 95.36458333333333\n",
      "K-fold 2 : 94.42708333333333\n",
      "K-fold 3 : 94.97395833333333\n",
      "K-fold 4 : 95.13020833333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 93.84895833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.33651721104979515\n",
      "K-fold 1 : 0.25139953680336474\n",
      "K-fold 2 : 0.26101226011912027\n",
      "K-fold 3 : 0.24062503824631373\n",
      "K-fold 4 : 0.24511773673196632\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.33761950929959617\n",
      "K-fold 1 : 0.24880394985278448\n",
      "K-fold 2 : 0.26715468962987265\n",
      "K-fold 3 : 0.2504342595736186\n",
      "K-fold 4 : 0.2480371356010437\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.33651721104979515\n",
      "K-fold 1 : 0.25139953680336474\n",
      "K-fold 2 : 0.26043664750953516\n",
      "K-fold 3 : 0.24062503824631373\n",
      "K-fold 4 : 0.24511773673196632\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.3371681878964106\n",
      "K-fold 1 : 0.24880394985278448\n",
      "K-fold 2 : 0.26715468962987265\n",
      "K-fold 3 : 0.24875436474879584\n",
      "K-fold 4 : 0.2480371356010437\n",
      "---------------------------------\n",
      "Average best validation loss: 0.26998366554578146\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.79427083333333\n",
      "K-fold 1 : 95.24739583333333\n",
      "K-fold 2 : 96.39973958333333\n",
      "K-fold 3 : 95.72265625\n",
      "K-fold 4 : 96.39973958333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.20833333333333\n",
      "K-fold 1 : 95.98958333333333\n",
      "K-fold 2 : 96.30208333333333\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 95.83333333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.84635416666667\n",
      "K-fold 1 : 95.26041666666667\n",
      "K-fold 2 : 96.40625\n",
      "K-fold 3 : 95.72265625\n",
      "K-fold 4 : 96.4453125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.9375\n",
      "K-fold 1 : 96.19791666666667\n",
      "K-fold 2 : 96.30208333333333\n",
      "K-fold 3 : 95.72916666666667\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.0625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17681940260032813\n",
      "K-fold 1 : 0.1855968588963151\n",
      "K-fold 2 : 0.16275686416774987\n",
      "K-fold 3 : 0.17393987402319908\n",
      "K-fold 4 : 0.16825914413978657\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19269756376743316\n",
      "K-fold 1 : 0.1655938059091568\n",
      "K-fold 2 : 0.18045630753040315\n",
      "K-fold 3 : 0.1799871566394965\n",
      "K-fold 4 : 0.20001618713140487\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17656382850060862\n",
      "K-fold 1 : 0.18461373522877694\n",
      "K-fold 2 : 0.16138800916572413\n",
      "K-fold 3 : 0.17393987402319908\n",
      "K-fold 4 : 0.1657788336277008\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.18584502736727396\n",
      "K-fold 1 : 0.1655938059091568\n",
      "K-fold 2 : 0.16722671538591385\n",
      "K-fold 3 : 0.17977105577786764\n",
      "K-fold 4 : 0.1786400280892849\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17541532650589944\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.47786458333333\n",
      "K-fold 1 : 96.328125\n",
      "K-fold 2 : 96.28255208333333\n",
      "K-fold 3 : 95.90494791666667\n",
      "K-fold 4 : 95.95052083333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.88541666666667\n",
      "K-fold 1 : 95.98958333333333\n",
      "K-fold 2 : 96.09375\n",
      "K-fold 3 : 95.0\n",
      "K-fold 4 : 96.71875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.49088541666667\n",
      "K-fold 1 : 96.328125\n",
      "K-fold 2 : 96.31510416666667\n",
      "K-fold 3 : 95.90494791666667\n",
      "K-fold 4 : 95.95052083333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.88541666666667\n",
      "K-fold 1 : 96.22395833333333\n",
      "K-fold 2 : 96.328125\n",
      "K-fold 3 : 95.67708333333333\n",
      "K-fold 4 : 96.97916666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.21875\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.19291465505957603\n",
      "K-fold 1 : 0.20718366652727127\n",
      "K-fold 2 : 0.20567508687575659\n",
      "K-fold 3 : 0.22405026021103064\n",
      "K-fold 4 : 0.21673433880011242\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.21140181124210358\n",
      "K-fold 1 : 0.21608199576536816\n",
      "K-fold 2 : 0.2177983582019806\n",
      "K-fold 3 : 0.23000306636095047\n",
      "K-fold 4 : 0.20025642663240434\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1927562612419327\n",
      "K-fold 1 : 0.20718366652727127\n",
      "K-fold 2 : 0.20567508687575659\n",
      "K-fold 3 : 0.22405026021103064\n",
      "K-fold 4 : 0.21673433880011242\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.21140181124210358\n",
      "K-fold 1 : 0.21520300060510636\n",
      "K-fold 2 : 0.2107442557811737\n",
      "K-fold 3 : 0.22858050713936487\n",
      "K-fold 4 : 0.20025642663240434\n",
      "---------------------------------\n",
      "Average best validation loss: 0.21323720028003054\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.32161458333333\n",
      "K-fold 1 : 96.484375\n",
      "K-fold 2 : 96.36067708333333\n",
      "K-fold 3 : 96.27604166666667\n",
      "K-fold 4 : 96.43880208333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.640625\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 96.43229166666667\n",
      "K-fold 3 : 96.77083333333333\n",
      "K-fold 4 : 96.171875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.32161458333333\n",
      "K-fold 1 : 96.51041666666667\n",
      "K-fold 2 : 96.38020833333333\n",
      "K-fold 3 : 96.29557291666667\n",
      "K-fold 4 : 96.4453125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.640625\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 96.43229166666667\n",
      "K-fold 3 : 96.77083333333333\n",
      "K-fold 4 : 96.171875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16401256124178568\n",
      "K-fold 1 : 0.15639513644079367\n",
      "K-fold 2 : 0.1585977359985312\n",
      "K-fold 3 : 0.16494176735480626\n",
      "K-fold 4 : 0.15501572377979755\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.15773209308584532\n",
      "K-fold 1 : 0.18852142468094826\n",
      "K-fold 2 : 0.17015564541021982\n",
      "K-fold 3 : 0.1508324772119522\n",
      "K-fold 4 : 0.16643030866980552\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16332824596514303\n",
      "K-fold 1 : 0.1542582806199789\n",
      "K-fold 2 : 0.15692192539572716\n",
      "K-fold 3 : 0.1641015208636721\n",
      "K-fold 4 : 0.15501572377979755\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15501502479116122\n",
      "K-fold 1 : 0.18687794655561446\n",
      "K-fold 2 : 0.1601528689265251\n",
      "K-fold 3 : 0.15054704596598942\n",
      "K-fold 4 : 0.16643030866980552\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16380463898181916\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.47135416666667\n",
      "K-fold 1 : 96.39973958333333\n",
      "K-fold 2 : 96.38671875\n",
      "K-fold 3 : 96.20442708333333\n",
      "K-fold 4 : 96.46484375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 96.328125\n",
      "K-fold 2 : 96.38020833333333\n",
      "K-fold 3 : 97.109375\n",
      "K-fold 4 : 96.06770833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.47135416666667\n",
      "K-fold 1 : 96.40625\n",
      "K-fold 2 : 96.38671875\n",
      "K-fold 3 : 96.20442708333333\n",
      "K-fold 4 : 96.47786458333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 96.328125\n",
      "K-fold 2 : 96.38020833333333\n",
      "K-fold 3 : 97.109375\n",
      "K-fold 4 : 96.06770833333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18469612170010805\n",
      "K-fold 1 : 0.1879857295503219\n",
      "K-fold 2 : 0.18989608579625686\n",
      "K-fold 3 : 0.19709739362200102\n",
      "K-fold 4 : 0.18789943555990854\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19650378475586575\n",
      "K-fold 1 : 0.19325414846340816\n",
      "K-fold 2 : 0.19730090821782748\n",
      "K-fold 3 : 0.178312365959088\n",
      "K-fold 4 : 0.19663747772574425\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18469612170010805\n",
      "K-fold 1 : 0.18759803976863623\n",
      "K-fold 2 : 0.18982735661168892\n",
      "K-fold 3 : 0.19661264245708784\n",
      "K-fold 4 : 0.18789943555990854\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.19556673814853032\n",
      "K-fold 1 : 0.19325414846340816\n",
      "K-fold 2 : 0.19556874136130015\n",
      "K-fold 3 : 0.1777597799897194\n",
      "K-fold 4 : 0.19645198211073875\n",
      "---------------------------------\n",
      "Average best validation loss: 0.19172027801473934\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-001_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.25\n",
      "K-fold 1 : 96.4453125\n",
      "K-fold 2 : 96.34765625\n",
      "K-fold 3 : 96.43880208333333\n",
      "K-fold 4 : 96.40625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.92708333333333\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 96.53645833333333\n",
      "K-fold 3 : 96.14583333333333\n",
      "K-fold 4 : 96.19791666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.25651041666667\n",
      "K-fold 1 : 96.45182291666667\n",
      "K-fold 2 : 96.36067708333333\n",
      "K-fold 3 : 96.4453125\n",
      "K-fold 4 : 96.43880208333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.92708333333333\n",
      "K-fold 1 : 96.11979166666667\n",
      "K-fold 2 : 96.53645833333333\n",
      "K-fold 3 : 96.14583333333333\n",
      "K-fold 4 : 96.22395833333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.39062499999999\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.15775783515224853\n",
      "K-fold 1 : 0.15992427449673413\n",
      "K-fold 2 : 0.1526173476750652\n",
      "K-fold 3 : 0.15372280652324358\n",
      "K-fold 4 : 0.15778764318674804\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.15148322097957134\n",
      "K-fold 1 : 0.19281303385893503\n",
      "K-fold 2 : 0.17017512122790018\n",
      "K-fold 3 : 0.17845133816202483\n",
      "K-fold 4 : 0.17603373726209004\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15734416594107944\n",
      "K-fold 1 : 0.15971209313720464\n",
      "K-fold 2 : 0.1525238394116362\n",
      "K-fold 3 : 0.15269529428333045\n",
      "K-fold 4 : 0.15445499178022146\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.14438231562574705\n",
      "K-fold 1 : 0.17606066862742106\n",
      "K-fold 2 : 0.15671003237366676\n",
      "K-fold 3 : 0.16904568920532861\n",
      "K-fold 4 : 0.16671108280618985\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16258195772767065\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.217447916666664\n",
      "K-fold 1 : 53.489583333333336\n",
      "K-fold 2 : 51.145833333333336\n",
      "K-fold 3 : 61.868489583333336\n",
      "K-fold 4 : 50.963541666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.0\n",
      "K-fold 1 : 53.854166666666664\n",
      "K-fold 2 : 50.286458333333336\n",
      "K-fold 3 : 62.161458333333336\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.575520833333336\n",
      "K-fold 1 : 54.31640625\n",
      "K-fold 2 : 51.145833333333336\n",
      "K-fold 3 : 61.89453125\n",
      "K-fold 4 : 51.15234375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.729166666666664\n",
      "K-fold 1 : 55.338541666666664\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 62.161458333333336\n",
      "K-fold 4 : 51.458333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 54.041666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6928652892510097\n",
      "K-fold 1 : 0.6910604760050774\n",
      "K-fold 2 : 0.6906021470824878\n",
      "K-fold 3 : 0.6899160757660866\n",
      "K-fold 4 : 0.691722430785497\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693404879172643\n",
      "K-fold 1 : 0.6901213228702545\n",
      "K-fold 2 : 0.6920811255772908\n",
      "K-fold 3 : 0.690617314974467\n",
      "K-fold 4 : 0.6922270397345225\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.692542240023613\n",
      "K-fold 1 : 0.6910604760050774\n",
      "K-fold 2 : 0.6905777230858803\n",
      "K-fold 3 : 0.6899160757660866\n",
      "K-fold 4 : 0.691722430785497\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6932108561197917\n",
      "K-fold 1 : 0.6901213228702545\n",
      "K-fold 2 : 0.6920045534769694\n",
      "K-fold 3 : 0.6906134426593781\n",
      "K-fold 4 : 0.6922270397345225\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6916354429721832\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.904947916666664\n",
      "K-fold 1 : 50.76171875\n",
      "K-fold 2 : 50.9765625\n",
      "K-fold 3 : 50.9765625\n",
      "K-fold 4 : 51.25\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 51.822916666666664\n",
      "K-fold 2 : 50.963541666666664\n",
      "K-fold 3 : 50.963541666666664\n",
      "K-fold 4 : 49.869791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.904947916666664\n",
      "K-fold 1 : 50.76171875\n",
      "K-fold 2 : 50.9765625\n",
      "K-fold 3 : 50.983072916666664\n",
      "K-fold 4 : 51.25\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 51.822916666666664\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 50.963541666666664\n",
      "K-fold 4 : 49.869791666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.98958333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930010134975115\n",
      "K-fold 1 : 0.6930488114555676\n",
      "K-fold 2 : 0.6929762641588847\n",
      "K-fold 3 : 0.6929719910025597\n",
      "K-fold 4 : 0.6928664460778237\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928617199261983\n",
      "K-fold 1 : 0.6927552143732707\n",
      "K-fold 2 : 0.6929616093635559\n",
      "K-fold 3 : 0.6929615298906963\n",
      "K-fold 4 : 0.6935245990753174\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929903641343117\n",
      "K-fold 1 : 0.693037478129069\n",
      "K-fold 2 : 0.6929644246896108\n",
      "K-fold 3 : 0.6929648319880167\n",
      "K-fold 4 : 0.6928420886397362\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928463300069173\n",
      "K-fold 1 : 0.6926816701889038\n",
      "K-fold 2 : 0.692912079890569\n",
      "K-fold 3 : 0.6929614702860515\n",
      "K-fold 4 : 0.6934488177299499\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929700736204782\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 43.020833333333336\n",
      "K-fold 1 : 58.88671875\n",
      "K-fold 2 : 62.766927083333336\n",
      "K-fold 3 : 49.4140625\n",
      "K-fold 4 : 58.4375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 44.0625\n",
      "K-fold 1 : 58.255208333333336\n",
      "K-fold 2 : 63.697916666666664\n",
      "K-fold 3 : 53.072916666666664\n",
      "K-fold 4 : 58.229166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 53.3203125\n",
      "K-fold 1 : 59.231770833333336\n",
      "K-fold 2 : 63.854166666666664\n",
      "K-fold 3 : 56.03515625\n",
      "K-fold 4 : 58.9453125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 54.296875\n",
      "K-fold 1 : 58.802083333333336\n",
      "K-fold 2 : 63.697916666666664\n",
      "K-fold 3 : 55.9375\n",
      "K-fold 4 : 58.229166666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 58.192708333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6917746856808662\n",
      "K-fold 1 : 0.6788969948887825\n",
      "K-fold 2 : 0.6895522976915042\n",
      "K-fold 3 : 0.6885497738917669\n",
      "K-fold 4 : 0.6920820221304893\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6913956046104431\n",
      "K-fold 1 : 0.6816824595133464\n",
      "K-fold 2 : 0.6898485084374746\n",
      "K-fold 3 : 0.6884670992692311\n",
      "K-fold 4 : 0.6924632767836253\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6917150189479192\n",
      "K-fold 1 : 0.6788969948887825\n",
      "K-fold 2 : 0.6895394881566366\n",
      "K-fold 3 : 0.688540335992972\n",
      "K-fold 4 : 0.6920435999830564\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6913677712281545\n",
      "K-fold 1 : 0.6816824595133464\n",
      "K-fold 2 : 0.6898422598838806\n",
      "K-fold 3 : 0.6883774002393087\n",
      "K-fold 4 : 0.6924354652563731\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6887410712242127\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.080729166666664\n",
      "K-fold 2 : 51.022135416666664\n",
      "K-fold 3 : 50.826822916666664\n",
      "K-fold 4 : 50.9765625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 50.546875\n",
      "K-fold 2 : 50.78125\n",
      "K-fold 3 : 51.5625\n",
      "K-fold 4 : 50.963541666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.080729166666664\n",
      "K-fold 2 : 51.022135416666664\n",
      "K-fold 3 : 50.826822916666664\n",
      "K-fold 4 : 50.9765625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 50.546875\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 51.5625\n",
      "K-fold 4 : 50.963541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.0\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929784958561261\n",
      "K-fold 1 : 0.6929345071315766\n",
      "K-fold 2 : 0.6929672136902809\n",
      "K-fold 3 : 0.6930230821172396\n",
      "K-fold 4 : 0.6929741596182187\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929410477479299\n",
      "K-fold 1 : 0.6931383113066355\n",
      "K-fold 2 : 0.6930357893308003\n",
      "K-fold 3 : 0.6927753229935963\n",
      "K-fold 4 : 0.6929617285728454\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929631993174553\n",
      "K-fold 1 : 0.6929215773940086\n",
      "K-fold 2 : 0.6929386749863624\n",
      "K-fold 3 : 0.6930158709486326\n",
      "K-fold 4 : 0.6929631183544794\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692940870920817\n",
      "K-fold 1 : 0.6930332938830058\n",
      "K-fold 2 : 0.693025263150533\n",
      "K-fold 3 : 0.6927486638228099\n",
      "K-fold 4 : 0.6929545144240061\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929405212402344\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.69921875\n",
      "K-fold 1 : 50.768229166666664\n",
      "K-fold 2 : 60.403645833333336\n",
      "K-fold 3 : 66.88802083333333\n",
      "K-fold 4 : 63.470052083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.796875\n",
      "K-fold 2 : 59.010416666666664\n",
      "K-fold 3 : 67.08333333333333\n",
      "K-fold 4 : 63.90625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 53.385416666666664\n",
      "K-fold 1 : 51.85546875\n",
      "K-fold 2 : 62.109375\n",
      "K-fold 3 : 66.88802083333333\n",
      "K-fold 4 : 63.743489583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.864583333333336\n",
      "K-fold 1 : 51.848958333333336\n",
      "K-fold 2 : 62.760416666666664\n",
      "K-fold 3 : 67.08333333333333\n",
      "K-fold 4 : 63.90625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.692708333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6863749424616495\n",
      "K-fold 1 : 0.6927779684464137\n",
      "K-fold 2 : 0.6879028518994649\n",
      "K-fold 3 : 0.688213445742925\n",
      "K-fold 4 : 0.6896440431475639\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6872810204823812\n",
      "K-fold 1 : 0.6925399005413055\n",
      "K-fold 2 : 0.6892560303211213\n",
      "K-fold 3 : 0.6878831962744395\n",
      "K-fold 4 : 0.6899082521597545\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6863335559765498\n",
      "K-fold 1 : 0.692731182773908\n",
      "K-fold 2 : 0.6879028518994649\n",
      "K-fold 3 : 0.6881929606199264\n",
      "K-fold 4 : 0.6895976687471072\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6872083067893981\n",
      "K-fold 1 : 0.6924202124277751\n",
      "K-fold 2 : 0.6892074346542358\n",
      "K-fold 3 : 0.6877792954444886\n",
      "K-fold 4 : 0.6898767153422037\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6892983929316203\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.748697916666664\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.204427083333336\n",
      "K-fold 3 : 50.99609375\n",
      "K-fold 4 : 50.95703125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.875\n",
      "K-fold 1 : 51.015625\n",
      "K-fold 2 : 50.052083333333336\n",
      "K-fold 3 : 50.885416666666664\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.768229166666664\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.204427083333336\n",
      "K-fold 3 : 50.99609375\n",
      "K-fold 4 : 50.95703125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.875\n",
      "K-fold 1 : 51.40625\n",
      "K-fold 2 : 50.052083333333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.11979166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693058905005455\n",
      "K-fold 1 : 0.6929860999186833\n",
      "K-fold 2 : 0.6928666477402051\n",
      "K-fold 3 : 0.6929607217510542\n",
      "K-fold 4 : 0.6929851626356442\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6926876564820608\n",
      "K-fold 1 : 0.6929416060447693\n",
      "K-fold 2 : 0.6933779100577037\n",
      "K-fold 3 : 0.6929920574029287\n",
      "K-fold 4 : 0.6929330090681712\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930426577727\n",
      "K-fold 1 : 0.6929700091481209\n",
      "K-fold 2 : 0.692865307132403\n",
      "K-fold 3 : 0.692953123152256\n",
      "K-fold 4 : 0.6929707696040471\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926743745803833\n",
      "K-fold 1 : 0.6928561210632325\n",
      "K-fold 2 : 0.6932478388150533\n",
      "K-fold 3 : 0.6929903546969096\n",
      "K-fold 4 : 0.6929301619529724\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929397702217102\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 54.21875\n",
      "K-fold 1 : 53.841145833333336\n",
      "K-fold 2 : 50.221354166666664\n",
      "K-fold 3 : 61.341145833333336\n",
      "K-fold 4 : 60.729166666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 61.354166666666664\n",
      "K-fold 1 : 56.432291666666664\n",
      "K-fold 2 : 43.098958333333336\n",
      "K-fold 3 : 56.119791666666664\n",
      "K-fold 4 : 59.0625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 64.30338541666667\n",
      "K-fold 1 : 61.315104166666664\n",
      "K-fold 2 : 54.51171875\n",
      "K-fold 3 : 63.61328125\n",
      "K-fold 4 : 60.729166666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 64.58333333333333\n",
      "K-fold 1 : 61.588541666666664\n",
      "K-fold 2 : 53.541666666666664\n",
      "K-fold 3 : 62.916666666666664\n",
      "K-fold 4 : 59.0625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 60.338541666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6896690423289935\n",
      "K-fold 1 : 0.6853362560272217\n",
      "K-fold 2 : 0.6908530265092849\n",
      "K-fold 3 : 0.6825976232687633\n",
      "K-fold 4 : 0.6871840059757233\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6909622410933177\n",
      "K-fold 1 : 0.6840239346027375\n",
      "K-fold 2 : 0.6908771415551503\n",
      "K-fold 3 : 0.684770937760671\n",
      "K-fold 4 : 0.688584687312444\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6896510114272435\n",
      "K-fold 1 : 0.6852872724334399\n",
      "K-fold 2 : 0.6908420835932095\n",
      "K-fold 3 : 0.6825737888614337\n",
      "K-fold 4 : 0.687057354549567\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6909014364083608\n",
      "K-fold 1 : 0.6839660843213399\n",
      "K-fold 2 : 0.6908771415551503\n",
      "K-fold 3 : 0.684770937760671\n",
      "K-fold 4 : 0.6885093967119853\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6878049993515014\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-001_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.826822916666664\n",
      "K-fold 1 : 51.30859375\n",
      "K-fold 2 : 50.885416666666664\n",
      "K-fold 3 : 50.8203125\n",
      "K-fold 4 : 51.028645833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.5625\n",
      "K-fold 1 : 49.635416666666664\n",
      "K-fold 2 : 51.328125\n",
      "K-fold 3 : 51.588541666666664\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.826822916666664\n",
      "K-fold 1 : 51.30859375\n",
      "K-fold 2 : 50.885416666666664\n",
      "K-fold 3 : 50.8203125\n",
      "K-fold 4 : 51.028645833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.5625\n",
      "K-fold 1 : 49.635416666666664\n",
      "K-fold 2 : 51.432291666666664\n",
      "K-fold 3 : 51.588541666666664\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.994791666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930184101065\n",
      "K-fold 1 : 0.6928161491950353\n",
      "K-fold 2 : 0.6930004720886548\n",
      "K-fold 3 : 0.6930293018619219\n",
      "K-fold 4 : 0.6929482410351435\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927655716737111\n",
      "K-fold 1 : 0.6936545034249624\n",
      "K-fold 2 : 0.6928321599960328\n",
      "K-fold 3 : 0.6927529056866963\n",
      "K-fold 4 : 0.693044368426005\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930169388651848\n",
      "K-fold 1 : 0.6928123046954473\n",
      "K-fold 2 : 0.6929975142081578\n",
      "K-fold 3 : 0.6930215602119764\n",
      "K-fold 4 : 0.6929424131910006\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927366097768147\n",
      "K-fold 1 : 0.6932856261730194\n",
      "K-fold 2 : 0.6928227543830872\n",
      "K-fold 3 : 0.6927376230557759\n",
      "K-fold 4 : 0.6930335899194081\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692923240661621\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 50.774739583333336\n",
      "K-fold 2 : 50.716145833333336\n",
      "K-fold 3 : 51.256510416666664\n",
      "K-fold 4 : 50.9765625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.286458333333336\n",
      "K-fold 1 : 51.770833333333336\n",
      "K-fold 2 : 52.005208333333336\n",
      "K-fold 3 : 49.84375\n",
      "K-fold 4 : 50.963541666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.158854166666664\n",
      "K-fold 1 : 50.774739583333336\n",
      "K-fold 2 : 50.716145833333336\n",
      "K-fold 3 : 51.256510416666664\n",
      "K-fold 4 : 51.438802083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.286458333333336\n",
      "K-fold 1 : 51.770833333333336\n",
      "K-fold 2 : 52.005208333333336\n",
      "K-fold 3 : 50.15625\n",
      "K-fold 4 : 50.963541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.03645833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.692924398680528\n",
      "K-fold 1 : 0.6930632884303729\n",
      "K-fold 2 : 0.693070982893308\n",
      "K-fold 3 : 0.692864054441452\n",
      "K-fold 4 : 0.6929945513606072\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931897203127543\n",
      "K-fold 1 : 0.6927953322728475\n",
      "K-fold 2 : 0.6927172124385834\n",
      "K-fold 3 : 0.6933454811573029\n",
      "K-fold 4 : 0.69298095703125\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.692900795241197\n",
      "K-fold 1 : 0.6930373986562093\n",
      "K-fold 2 : 0.6930520683526993\n",
      "K-fold 3 : 0.6928473298748334\n",
      "K-fold 4 : 0.6929684698581695\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931623498598735\n",
      "K-fold 1 : 0.692769302924474\n",
      "K-fold 2 : 0.6927172124385834\n",
      "K-fold 3 : 0.693125985066096\n",
      "K-fold 4 : 0.6929613689581553\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929472438494365\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.171875\n",
      "K-fold 1 : 50.885416666666664\n",
      "K-fold 2 : 50.72265625\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.865885416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.182291666666664\n",
      "K-fold 1 : 51.328125\n",
      "K-fold 2 : 51.979166666666664\n",
      "K-fold 3 : 49.973958333333336\n",
      "K-fold 4 : 51.40625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.171875\n",
      "K-fold 1 : 50.885416666666664\n",
      "K-fold 2 : 50.72265625\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.865885416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.182291666666664\n",
      "K-fold 1 : 51.328125\n",
      "K-fold 2 : 51.979166666666664\n",
      "K-fold 3 : 50.026041666666664\n",
      "K-fold 4 : 51.40625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.98437499999999\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929014563560486\n",
      "K-fold 1 : 0.6930285354455312\n",
      "K-fold 2 : 0.6930673604210218\n",
      "K-fold 3 : 0.6928878078858057\n",
      "K-fold 4 : 0.6930261219541232\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932160397370656\n",
      "K-fold 1 : 0.692903071641922\n",
      "K-fold 2 : 0.6928421497344971\n",
      "K-fold 3 : 0.6933173318703969\n",
      "K-fold 4 : 0.6928637822469076\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928874254226685\n",
      "K-fold 1 : 0.6929919019341468\n",
      "K-fold 2 : 0.693045049905777\n",
      "K-fold 3 : 0.6928668225804965\n",
      "K-fold 4 : 0.6930091217160225\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931305964787801\n",
      "K-fold 1 : 0.6928161482016245\n",
      "K-fold 2 : 0.6926441272099813\n",
      "K-fold 3 : 0.6931510448455811\n",
      "K-fold 4 : 0.692751012245814\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928985857963561\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 50.826822916666664\n",
      "K-fold 2 : 50.963541666666664\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 50.99609375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 51.5625\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 50.703125\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 50.826822916666664\n",
      "K-fold 2 : 50.963541666666664\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 51.5625\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 50.703125\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929752285281817\n",
      "K-fold 1 : 0.6930314168334007\n",
      "K-fold 2 : 0.6929908911387126\n",
      "K-fold 3 : 0.6929624179999033\n",
      "K-fold 4 : 0.6929979597528776\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693048506975174\n",
      "K-fold 1 : 0.6928288996219635\n",
      "K-fold 2 : 0.6929530998071035\n",
      "K-fold 3 : 0.6930483798185985\n",
      "K-fold 4 : 0.6929994066556294\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929438367486\n",
      "K-fold 1 : 0.6930192286769549\n",
      "K-fold 2 : 0.6929729094107946\n",
      "K-fold 3 : 0.6928850322961807\n",
      "K-fold 4 : 0.6929387470086416\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930482486883799\n",
      "K-fold 1 : 0.6928026099999746\n",
      "K-fold 2 : 0.6929498672485351\n",
      "K-fold 3 : 0.6930482745170593\n",
      "K-fold 4 : 0.6929912726084392\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929680546124776\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.83984375\n",
      "K-fold 1 : 50.572916666666664\n",
      "K-fold 2 : 51.516927083333336\n",
      "K-fold 3 : 50.670572916666664\n",
      "K-fold 4 : 51.26953125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.510416666666664\n",
      "K-fold 1 : 52.578125\n",
      "K-fold 2 : 48.802083333333336\n",
      "K-fold 3 : 52.1875\n",
      "K-fold 4 : 49.791666666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.83984375\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 51.516927083333336\n",
      "K-fold 3 : 50.670572916666664\n",
      "K-fold 4 : 51.26953125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.510416666666664\n",
      "K-fold 1 : 52.578125\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 52.1875\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.53645833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930315653483073\n",
      "K-fold 1 : 0.693105366329352\n",
      "K-fold 2 : 0.6927722697456677\n",
      "K-fold 3 : 0.6930856853723526\n",
      "K-fold 4 : 0.6928668657938639\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928530792395274\n",
      "K-fold 1 : 0.6927585005760193\n",
      "K-fold 2 : 0.6939560015996297\n",
      "K-fold 3 : 0.6927514294783275\n",
      "K-fold 4 : 0.6933995286623637\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930073797702789\n",
      "K-fold 1 : 0.6930884674191475\n",
      "K-fold 2 : 0.6927105655272802\n",
      "K-fold 3 : 0.6930650234222412\n",
      "K-fold 4 : 0.6928424497445425\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928136746088663\n",
      "K-fold 1 : 0.6924686551094055\n",
      "K-fold 2 : 0.6929016729195913\n",
      "K-fold 3 : 0.6926687359809875\n",
      "K-fold 4 : 0.6931361734867096\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927977824211121\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.891927083333336\n",
      "K-fold 1 : 51.256510416666664\n",
      "K-fold 2 : 50.813802083333336\n",
      "K-fold 3 : 51.19140625\n",
      "K-fold 4 : 50.716145833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.302083333333336\n",
      "K-fold 1 : 49.84375\n",
      "K-fold 2 : 51.614583333333336\n",
      "K-fold 3 : 50.104166666666664\n",
      "K-fold 4 : 52.005208333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.891927083333336\n",
      "K-fold 1 : 51.30859375\n",
      "K-fold 2 : 51.100260416666664\n",
      "K-fold 3 : 51.217447916666664\n",
      "K-fold 4 : 50.716145833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.302083333333336\n",
      "K-fold 1 : 49.84375\n",
      "K-fold 2 : 51.71875\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 52.005208333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.11979166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930077662070592\n",
      "K-fold 1 : 0.6928788388768832\n",
      "K-fold 2 : 0.6930341844757398\n",
      "K-fold 3 : 0.6928996413946151\n",
      "K-fold 4 : 0.6930644939343135\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.692892191807429\n",
      "K-fold 1 : 0.6933613598346711\n",
      "K-fold 2 : 0.6928364197413127\n",
      "K-fold 3 : 0.6932693223158518\n",
      "K-fold 4 : 0.6927877028783163\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929989258448283\n",
      "K-fold 1 : 0.6928541466593743\n",
      "K-fold 2 : 0.6930244147777558\n",
      "K-fold 3 : 0.6928786878784498\n",
      "K-fold 4 : 0.6930527999997139\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928718268871308\n",
      "K-fold 1 : 0.6932138741016388\n",
      "K-fold 2 : 0.6925027251243592\n",
      "K-fold 3 : 0.6931327203909556\n",
      "K-fold 4 : 0.6927320619424184\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928906416893005\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.930989583333336\n",
      "K-fold 1 : 51.171875\n",
      "K-fold 2 : 51.11328125\n",
      "K-fold 3 : 50.91796875\n",
      "K-fold 4 : 50.735677083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 50.182291666666664\n",
      "K-fold 2 : 50.416666666666664\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 51.927083333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.930989583333336\n",
      "K-fold 1 : 51.171875\n",
      "K-fold 2 : 51.11328125\n",
      "K-fold 3 : 50.91796875\n",
      "K-fold 4 : 50.735677083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 50.182291666666664\n",
      "K-fold 2 : 50.416666666666664\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 51.927083333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930065815647443\n",
      "K-fold 1 : 0.692909537255764\n",
      "K-fold 2 : 0.692935204009215\n",
      "K-fold 3 : 0.6930081292986869\n",
      "K-fold 4 : 0.6930701022346815\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929333627223968\n",
      "K-fold 1 : 0.6932125528653462\n",
      "K-fold 2 : 0.6931289196014404\n",
      "K-fold 3 : 0.6929140011469523\n",
      "K-fold 4 : 0.6927875737349193\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929869825641314\n",
      "K-fold 1 : 0.6928901270031929\n",
      "K-fold 2 : 0.692916069428126\n",
      "K-fold 3 : 0.692987997829914\n",
      "K-fold 4 : 0.693048894405365\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929105738798778\n",
      "K-fold 1 : 0.6931880911191305\n",
      "K-fold 2 : 0.6931143522262573\n",
      "K-fold 3 : 0.6928898175557454\n",
      "K-fold 4 : 0.692554360628128\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929314390818279\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 50.930989583333336\n",
      "K-fold 2 : 51.282552083333336\n",
      "K-fold 3 : 50.748697916666664\n",
      "K-fold 4 : 51.022135416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 49.739583333333336\n",
      "K-fold 3 : 51.875\n",
      "K-fold 4 : 50.78125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.009114583333336\n",
      "K-fold 2 : 51.295572916666664\n",
      "K-fold 3 : 50.78125\n",
      "K-fold 4 : 51.022135416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.354166666666664\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 49.739583333333336\n",
      "K-fold 3 : 51.875\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.052083333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930568565924963\n",
      "K-fold 1 : 0.6929982235034307\n",
      "K-fold 2 : 0.6928842877348264\n",
      "K-fold 3 : 0.6930707136789958\n",
      "K-fold 4 : 0.6929717878500621\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928866585095723\n",
      "K-fold 1 : 0.6929397046566009\n",
      "K-fold 2 : 0.6934044738610585\n",
      "K-fold 3 : 0.692810332775116\n",
      "K-fold 4 : 0.6930251896381379\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930042599638303\n",
      "K-fold 1 : 0.6929834172129631\n",
      "K-fold 2 : 0.6928386718034745\n",
      "K-fold 3 : 0.6930438190698623\n",
      "K-fold 4 : 0.692949049671491\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692767455180486\n",
      "K-fold 1 : 0.6929078956445058\n",
      "K-fold 2 : 0.6932241360346476\n",
      "K-fold 3 : 0.692744247118632\n",
      "K-fold 4 : 0.6930167178312937\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929320903619131\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-001_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.022135416666664\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 51.217447916666664\n",
      "K-fold 3 : 51.165364583333336\n",
      "K-fold 4 : 50.657552083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.78125\n",
      "K-fold 1 : 51.640625\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 52.239583333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.022135416666664\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 51.263020833333336\n",
      "K-fold 3 : 51.165364583333336\n",
      "K-fold 4 : 50.657552083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.78125\n",
      "K-fold 1 : 51.640625\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 52.239583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.973958333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929712230960529\n",
      "K-fold 1 : 0.6930413608749707\n",
      "K-fold 2 : 0.6928844278057417\n",
      "K-fold 3 : 0.692944785952568\n",
      "K-fold 4 : 0.6930813024441401\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693025137980779\n",
      "K-fold 1 : 0.6928322712580363\n",
      "K-fold 2 : 0.693320510784785\n",
      "K-fold 3 : 0.6932421425978342\n",
      "K-fold 4 : 0.6927288850148519\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929462159673373\n",
      "K-fold 1 : 0.6930054734150569\n",
      "K-fold 2 : 0.6928655962149303\n",
      "K-fold 3 : 0.6928938870628675\n",
      "K-fold 4 : 0.6930678541461627\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930250704288483\n",
      "K-fold 1 : 0.6926704565684001\n",
      "K-fold 2 : 0.6932566821575165\n",
      "K-fold 3 : 0.6931385179360707\n",
      "K-fold 4 : 0.6926871319611867\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929555718104045\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.45833333333333\n",
      "K-fold 1 : 92.35026041666667\n",
      "K-fold 2 : 95.42317708333333\n",
      "K-fold 3 : 94.6875\n",
      "K-fold 4 : 95.17578125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 92.94270833333333\n",
      "K-fold 2 : 95.234375\n",
      "K-fold 3 : 95.33854166666667\n",
      "K-fold 4 : 95.625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.5234375\n",
      "K-fold 1 : 92.58463541666667\n",
      "K-fold 2 : 95.46223958333333\n",
      "K-fold 3 : 94.77864583333333\n",
      "K-fold 4 : 95.38411458333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.78125\n",
      "K-fold 1 : 92.94270833333333\n",
      "K-fold 2 : 95.72916666666667\n",
      "K-fold 3 : 95.78125\n",
      "K-fold 4 : 95.98958333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.24479166666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17076213794449965\n",
      "K-fold 1 : 0.24810588508844375\n",
      "K-fold 2 : 0.18310635692129532\n",
      "K-fold 3 : 0.20601030749579272\n",
      "K-fold 4 : 0.19813246553142866\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19856115604440372\n",
      "K-fold 1 : 0.24494778315226237\n",
      "K-fold 2 : 0.18941682130098342\n",
      "K-fold 3 : 0.18880044668912888\n",
      "K-fold 4 : 0.19167954847216606\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1698411606873075\n",
      "K-fold 1 : 0.244634893288215\n",
      "K-fold 2 : 0.1793241910636425\n",
      "K-fold 3 : 0.20494860056787728\n",
      "K-fold 4 : 0.19453300467381876\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.19349173630277317\n",
      "K-fold 1 : 0.24494778315226237\n",
      "K-fold 2 : 0.1811796672642231\n",
      "K-fold 3 : 0.18786496445536613\n",
      "K-fold 4 : 0.18968643595774967\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1994341174264749\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.17838541666667\n",
      "K-fold 1 : 79.54427083333333\n",
      "K-fold 2 : 96.35416666666667\n",
      "K-fold 3 : 96.19791666666667\n",
      "K-fold 4 : 92.70182291666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.58854166666667\n",
      "K-fold 1 : 79.296875\n",
      "K-fold 2 : 96.40625\n",
      "K-fold 3 : 95.98958333333333\n",
      "K-fold 4 : 92.265625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.29557291666667\n",
      "K-fold 1 : 79.55078125\n",
      "K-fold 2 : 96.38020833333333\n",
      "K-fold 3 : 96.23697916666667\n",
      "K-fold 4 : 92.72135416666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.69270833333333\n",
      "K-fold 1 : 79.42708333333333\n",
      "K-fold 2 : 96.40625\n",
      "K-fold 3 : 95.98958333333333\n",
      "K-fold 4 : 92.36979166666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 92.17708333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16307333043466013\n",
      "K-fold 1 : 0.41211019704739255\n",
      "K-fold 2 : 0.15312245457122722\n",
      "K-fold 3 : 0.16147349147746962\n",
      "K-fold 4 : 0.21449566551794608\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.15652385130524635\n",
      "K-fold 1 : 0.42265132466952005\n",
      "K-fold 2 : 0.15133274905383587\n",
      "K-fold 3 : 0.1682426944375038\n",
      "K-fold 4 : 0.23064029415448506\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15959558952599764\n",
      "K-fold 1 : 0.4111335804065069\n",
      "K-fold 2 : 0.15143226195747653\n",
      "K-fold 3 : 0.1601338326310118\n",
      "K-fold 4 : 0.21449566551794608\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.14767003866533437\n",
      "K-fold 1 : 0.4191120723883311\n",
      "K-fold 2 : 0.14940919565657776\n",
      "K-fold 3 : 0.16732973332206408\n",
      "K-fold 4 : 0.21841494167844455\n",
      "---------------------------------\n",
      "Average best validation loss: 0.22038719634215037\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.88541666666667\n",
      "K-fold 1 : 96.26302083333333\n",
      "K-fold 2 : 96.30208333333333\n",
      "K-fold 3 : 95.33203125\n",
      "K-fold 4 : 96.09375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.625\n",
      "K-fold 1 : 96.40625\n",
      "K-fold 2 : 96.19791666666667\n",
      "K-fold 3 : 94.921875\n",
      "K-fold 4 : 96.796875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.00260416666667\n",
      "K-fold 1 : 96.31510416666667\n",
      "K-fold 2 : 96.34765625\n",
      "K-fold 3 : 95.33203125\n",
      "K-fold 4 : 96.14583333333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.67708333333333\n",
      "K-fold 1 : 96.40625\n",
      "K-fold 2 : 96.328125\n",
      "K-fold 3 : 95.3125\n",
      "K-fold 4 : 96.796875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.10416666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18212125872572263\n",
      "K-fold 1 : 0.16659629515682658\n",
      "K-fold 2 : 0.1656612719098727\n",
      "K-fold 3 : 0.18750555211057265\n",
      "K-fold 4 : 0.17465769207725923\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.19353383034467697\n",
      "K-fold 1 : 0.1765968901415666\n",
      "K-fold 2 : 0.18114402741193772\n",
      "K-fold 3 : 0.20403982152541478\n",
      "K-fold 4 : 0.16508405456940334\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17859050693611303\n",
      "K-fold 1 : 0.16543530775234103\n",
      "K-fold 2 : 0.1656612719098727\n",
      "K-fold 3 : 0.18750555211057265\n",
      "K-fold 4 : 0.171173357963562\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.19284041797121365\n",
      "K-fold 1 : 0.16786260033647218\n",
      "K-fold 2 : 0.17478190039594968\n",
      "K-fold 3 : 0.20155614614486694\n",
      "K-fold 4 : 0.16414614791671436\n",
      "---------------------------------\n",
      "Average best validation loss: 0.18023744255304336\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.32161458333333\n",
      "K-fold 1 : 96.47135416666667\n",
      "K-fold 2 : 96.25651041666667\n",
      "K-fold 3 : 96.50390625\n",
      "K-fold 4 : 96.24348958333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.58854166666667\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 96.640625\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 96.69270833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.328125\n",
      "K-fold 1 : 96.47135416666667\n",
      "K-fold 2 : 96.29557291666667\n",
      "K-fold 3 : 96.51692708333333\n",
      "K-fold 4 : 96.25651041666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.58854166666667\n",
      "K-fold 1 : 95.91145833333333\n",
      "K-fold 2 : 96.66666666666667\n",
      "K-fold 3 : 95.88541666666667\n",
      "K-fold 4 : 96.92708333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.39583333333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.1560860900208354\n",
      "K-fold 1 : 0.15544818372776112\n",
      "K-fold 2 : 0.1600632606384655\n",
      "K-fold 3 : 0.14854091207186382\n",
      "K-fold 4 : 0.16065323042372862\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.14816532880067826\n",
      "K-fold 1 : 0.1746997132897377\n",
      "K-fold 2 : 0.15149742017189663\n",
      "K-fold 3 : 0.17156985650459924\n",
      "K-fold 4 : 0.14488427775601545\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15461671895657977\n",
      "K-fold 1 : 0.15544818372776112\n",
      "K-fold 2 : 0.1600632606384655\n",
      "K-fold 3 : 0.14758805076902112\n",
      "K-fold 4 : 0.15773850511759518\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.14746839354435604\n",
      "K-fold 1 : 0.1746997132897377\n",
      "K-fold 2 : 0.1498013863960902\n",
      "K-fold 3 : 0.168019071718057\n",
      "K-fold 4 : 0.14244758176306885\n",
      "---------------------------------\n",
      "Average best validation loss: 0.15648722934226195\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.9375\n",
      "K-fold 1 : 96.38671875\n",
      "K-fold 2 : 96.18489583333333\n",
      "K-fold 3 : 96.33463541666667\n",
      "K-fold 4 : 96.46484375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.22395833333333\n",
      "K-fold 1 : 95.75520833333333\n",
      "K-fold 2 : 96.77083333333333\n",
      "K-fold 3 : 96.25\n",
      "K-fold 4 : 95.78125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.02864583333333\n",
      "K-fold 1 : 96.43880208333333\n",
      "K-fold 2 : 96.24348958333333\n",
      "K-fold 3 : 96.37369791666667\n",
      "K-fold 4 : 96.47135416666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.58854166666667\n",
      "K-fold 1 : 96.171875\n",
      "K-fold 2 : 96.84895833333333\n",
      "K-fold 3 : 96.328125\n",
      "K-fold 4 : 95.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.17177438487609228\n",
      "K-fold 1 : 0.1607193075120449\n",
      "K-fold 2 : 0.16606378306945166\n",
      "K-fold 3 : 0.16160203746209542\n",
      "K-fold 4 : 0.15995579284305375\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17822390670577684\n",
      "K-fold 1 : 0.20130251025160154\n",
      "K-fold 2 : 0.15897536873817444\n",
      "K-fold 3 : 0.17418439437945685\n",
      "K-fold 4 : 0.20255372325579327\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.17030522481848795\n",
      "K-fold 1 : 0.15950527315338453\n",
      "K-fold 2 : 0.163960824906826\n",
      "K-fold 3 : 0.15765289658059675\n",
      "K-fold 4 : 0.15802501483509937\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16565093820293744\n",
      "K-fold 1 : 0.17688497354586918\n",
      "K-fold 2 : 0.1565452255308628\n",
      "K-fold 3 : 0.17100136677424113\n",
      "K-fold 4 : 0.18081763088703157\n",
      "---------------------------------\n",
      "Average best validation loss: 0.17018002698818843\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.98958333333333\n",
      "K-fold 1 : 96.43229166666667\n",
      "K-fold 2 : 96.4453125\n",
      "K-fold 3 : 96.34114583333333\n",
      "K-fold 4 : 96.30859375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 97.265625\n",
      "K-fold 1 : 95.859375\n",
      "K-fold 2 : 96.015625\n",
      "K-fold 3 : 96.04166666666667\n",
      "K-fold 4 : 96.22395833333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.10677083333333\n",
      "K-fold 1 : 96.45833333333333\n",
      "K-fold 2 : 96.47786458333333\n",
      "K-fold 3 : 96.4453125\n",
      "K-fold 4 : 96.34765625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 97.36979166666667\n",
      "K-fold 1 : 95.96354166666667\n",
      "K-fold 2 : 96.015625\n",
      "K-fold 3 : 96.09375\n",
      "K-fold 4 : 96.484375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.15516584642852346\n",
      "K-fold 1 : 0.15032535810023545\n",
      "K-fold 2 : 0.14835244165733458\n",
      "K-fold 3 : 0.15586566729471088\n",
      "K-fold 4 : 0.14397133405630788\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.13200713445742926\n",
      "K-fold 1 : 0.17727899178862572\n",
      "K-fold 2 : 0.17177957283953826\n",
      "K-fold 3 : 0.17343048204978306\n",
      "K-fold 4 : 0.17381649613380432\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.15407319230337937\n",
      "K-fold 1 : 0.15032535810023545\n",
      "K-fold 2 : 0.14799626239885885\n",
      "K-fold 3 : 0.1546926967178782\n",
      "K-fold 4 : 0.14358544619753957\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.12465421395997206\n",
      "K-fold 1 : 0.1688333511352539\n",
      "K-fold 2 : 0.1662500058611234\n",
      "K-fold 3 : 0.16951543018221854\n",
      "K-fold 4 : 0.16062500762442747\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1579756017525991\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.18489583333333\n",
      "K-fold 1 : 96.29557291666667\n",
      "K-fold 2 : 96.42578125\n",
      "K-fold 3 : 96.38671875\n",
      "K-fold 4 : 96.35416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.53645833333333\n",
      "K-fold 1 : 96.61458333333333\n",
      "K-fold 2 : 96.09375\n",
      "K-fold 3 : 96.30208333333333\n",
      "K-fold 4 : 95.88541666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.29557291666667\n",
      "K-fold 1 : 96.30208333333333\n",
      "K-fold 2 : 96.45182291666667\n",
      "K-fold 3 : 96.40625\n",
      "K-fold 4 : 96.41276041666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.69270833333333\n",
      "K-fold 1 : 96.66666666666667\n",
      "K-fold 2 : 96.11979166666667\n",
      "K-fold 3 : 96.30208333333333\n",
      "K-fold 4 : 96.171875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.390625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16216612240920464\n",
      "K-fold 1 : 0.16230865928033988\n",
      "K-fold 2 : 0.1573739420933028\n",
      "K-fold 3 : 0.15996244276563326\n",
      "K-fold 4 : 0.15611552701642115\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.15987554813424745\n",
      "K-fold 1 : 0.1628878320256869\n",
      "K-fold 2 : 0.18739949290951094\n",
      "K-fold 3 : 0.1677550954123338\n",
      "K-fold 4 : 0.19978391180435817\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.1602597067753474\n",
      "K-fold 1 : 0.1609006787960728\n",
      "K-fold 2 : 0.1573739420933028\n",
      "K-fold 3 : 0.15877442446847756\n",
      "K-fold 4 : 0.15402633932729562\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.15708670591314633\n",
      "K-fold 1 : 0.15806653946638108\n",
      "K-fold 2 : 0.17672044932842254\n",
      "K-fold 3 : 0.1677550954123338\n",
      "K-fold 4 : 0.17937817896405855\n",
      "---------------------------------\n",
      "Average best validation loss: 0.16780139381686845\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-01_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.328125\n",
      "K-fold 1 : 96.34114583333333\n",
      "K-fold 2 : 96.2890625\n",
      "K-fold 3 : 96.36067708333333\n",
      "K-fold 4 : 96.328125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 96.328125\n",
      "K-fold 1 : 96.27604166666667\n",
      "K-fold 2 : 96.58854166666667\n",
      "K-fold 3 : 96.09375\n",
      "K-fold 4 : 96.40625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.40625\n",
      "K-fold 1 : 96.40625\n",
      "K-fold 2 : 96.328125\n",
      "K-fold 3 : 96.39322916666667\n",
      "K-fold 4 : 96.35416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.35416666666667\n",
      "K-fold 1 : 96.27604166666667\n",
      "K-fold 2 : 96.61458333333333\n",
      "K-fold 3 : 96.19791666666667\n",
      "K-fold 4 : 96.484375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 96.38541666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.14863579183196027\n",
      "K-fold 1 : 0.14810939095914363\n",
      "K-fold 2 : 0.14750727949043116\n",
      "K-fold 3 : 0.1524636924266815\n",
      "K-fold 4 : 0.1493216587230563\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.1679515264928341\n",
      "K-fold 1 : 0.17106628989179928\n",
      "K-fold 2 : 0.15807824730873107\n",
      "K-fold 3 : 0.17574230407675107\n",
      "K-fold 4 : 0.16017250828444957\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.14552346703906854\n",
      "K-fold 1 : 0.14502320007110636\n",
      "K-fold 2 : 0.1455091116639475\n",
      "K-fold 3 : 0.15152725211034218\n",
      "K-fold 4 : 0.14854550277814269\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16178314462304116\n",
      "K-fold 1 : 0.1615537149210771\n",
      "K-fold 2 : 0.14740561073025069\n",
      "K-fold 3 : 0.16376815214753151\n",
      "K-fold 4 : 0.151982431858778\n",
      "---------------------------------\n",
      "Average best validation loss: 0.1572986108561357\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 93.07942708333333\n",
      "K-fold 1 : 95.47526041666667\n",
      "K-fold 2 : 91.37369791666667\n",
      "K-fold 3 : 86.06770833333333\n",
      "K-fold 4 : 88.86067708333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 92.21354166666667\n",
      "K-fold 1 : 95.78125\n",
      "K-fold 2 : 91.484375\n",
      "K-fold 3 : 86.66666666666667\n",
      "K-fold 4 : 91.71875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.17708333333333\n",
      "K-fold 1 : 95.703125\n",
      "K-fold 2 : 91.37369791666667\n",
      "K-fold 3 : 86.06770833333333\n",
      "K-fold 4 : 89.62239583333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 92.78645833333333\n",
      "K-fold 1 : 95.78125\n",
      "K-fold 2 : 92.29166666666667\n",
      "K-fold 3 : 86.66666666666667\n",
      "K-fold 4 : 93.28125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 92.16145833333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.26230450918277104\n",
      "K-fold 1 : 0.22990015409886838\n",
      "K-fold 2 : 0.2813878847906987\n",
      "K-fold 3 : 0.3696421374877294\n",
      "K-fold 4 : 0.3341845200707515\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2773289302984873\n",
      "K-fold 1 : 0.22446165531873702\n",
      "K-fold 2 : 0.2813483272989591\n",
      "K-fold 3 : 0.35705003241697947\n",
      "K-fold 4 : 0.32637957533200584\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2595045165469249\n",
      "K-fold 1 : 0.22675453213353952\n",
      "K-fold 2 : 0.2813878847906987\n",
      "K-fold 3 : 0.3696421374877294\n",
      "K-fold 4 : 0.3281085689862569\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2638490080833435\n",
      "K-fold 1 : 0.22310952693223954\n",
      "K-fold 2 : 0.27422836621602376\n",
      "K-fold 3 : 0.35705003241697947\n",
      "K-fold 4 : 0.3230130622784297\n",
      "---------------------------------\n",
      "Average best validation loss: 0.28824999918540317\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 87.87760416666667\n",
      "K-fold 1 : 95.79427083333333\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 50.657552083333336\n",
      "K-fold 4 : 96.02213541666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 93.09895833333333\n",
      "K-fold 1 : 96.04166666666667\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 95.96354166666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 88.35286458333333\n",
      "K-fold 1 : 95.80729166666667\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.26953125\n",
      "K-fold 4 : 96.02213541666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.203125\n",
      "K-fold 1 : 96.04166666666667\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 95.96354166666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 77.26562500000001\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.29557769211630025\n",
      "K-fold 1 : 0.19370633848011493\n",
      "K-fold 2 : 0.6931096797188123\n",
      "K-fold 3 : 0.6933084944883983\n",
      "K-fold 4 : 0.18119124080985785\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.29424996276696525\n",
      "K-fold 1 : 0.20153413812319437\n",
      "K-fold 2 : 0.6929834425449372\n",
      "K-fold 3 : 0.6931654930114746\n",
      "K-fold 4 : 0.1820161739985148\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2941186099002759\n",
      "K-fold 1 : 0.1897666398435831\n",
      "K-fold 2 : 0.6928955321510633\n",
      "K-fold 3 : 0.6927737290660541\n",
      "K-fold 4 : 0.18054030227164428\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2894326056043307\n",
      "K-fold 1 : 0.18406951030095417\n",
      "K-fold 2 : 0.6929810523986817\n",
      "K-fold 3 : 0.6931390146414439\n",
      "K-fold 4 : 0.1820161739985148\n",
      "---------------------------------\n",
      "Average best validation loss: 0.40832767138878506\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.21484375\n",
      "K-fold 1 : 94.98697916666667\n",
      "K-fold 2 : 91.92057291666667\n",
      "K-fold 3 : 93.56119791666667\n",
      "K-fold 4 : 86.28255208333333\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.49479166666667\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 90.65104166666667\n",
      "K-fold 3 : 95.10416666666667\n",
      "K-fold 4 : 86.58854166666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.51432291666667\n",
      "K-fold 1 : 95.41015625\n",
      "K-fold 2 : 92.23307291666667\n",
      "K-fold 3 : 94.17317708333333\n",
      "K-fold 4 : 86.41276041666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.49479166666667\n",
      "K-fold 1 : 95.72916666666667\n",
      "K-fold 2 : 92.91666666666667\n",
      "K-fold 3 : 95.20833333333333\n",
      "K-fold 4 : 91.25\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.11979166666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2327071224649747\n",
      "K-fold 1 : 0.2328424363086621\n",
      "K-fold 2 : 0.29191441362102827\n",
      "K-fold 3 : 0.25982201484342415\n",
      "K-fold 4 : 0.3382389465967814\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2363842303554217\n",
      "K-fold 1 : 0.23130930612484615\n",
      "K-fold 2 : 0.2932156284650167\n",
      "K-fold 3 : 0.24720691988865534\n",
      "K-fold 4 : 0.34941063622633617\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.22967899007101852\n",
      "K-fold 1 : 0.22839943940440813\n",
      "K-fold 2 : 0.2852253175030152\n",
      "K-fold 3 : 0.2562950218717257\n",
      "K-fold 4 : 0.3346728692452113\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.23316984474658967\n",
      "K-fold 1 : 0.22480604151884714\n",
      "K-fold 2 : 0.27894768863916397\n",
      "K-fold 3 : 0.24608740011850994\n",
      "K-fold 4 : 0.33951119184494016\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2645044333736102\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 95.93098958333333\n",
      "K-fold 1 : 95.98958333333333\n",
      "K-fold 2 : 50.64453125\n",
      "K-fold 3 : 50.442708333333336\n",
      "K-fold 4 : 50.924479166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.98958333333333\n",
      "K-fold 1 : 96.06770833333333\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.015625\n",
      "K-fold 4 : 51.171875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 95.99609375\n",
      "K-fold 1 : 96.015625\n",
      "K-fold 2 : 51.217447916666664\n",
      "K-fold 3 : 50.963541666666664\n",
      "K-fold 4 : 51.236979166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 96.640625\n",
      "K-fold 1 : 96.09375\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 51.015625\n",
      "K-fold 4 : 51.171875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 69.13020833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.18194911150882642\n",
      "K-fold 1 : 0.1843586842219035\n",
      "K-fold 2 : 0.6930837045113246\n",
      "K-fold 3 : 0.6932506809631983\n",
      "K-fold 4 : 0.693072787920634\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.17848573525746664\n",
      "K-fold 1 : 0.18503397131959598\n",
      "K-fold 2 : 0.6930713057518005\n",
      "K-fold 3 : 0.6929455618063609\n",
      "K-fold 4 : 0.6929883201917012\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.18002582465608916\n",
      "K-fold 1 : 0.18378886183102924\n",
      "K-fold 2 : 0.6928566773732503\n",
      "K-fold 3 : 0.6929613108436267\n",
      "K-fold 4 : 0.6930212080478668\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16827514618635178\n",
      "K-fold 1 : 0.17907326246301333\n",
      "K-fold 2 : 0.6930690348148346\n",
      "K-fold 3 : 0.6929409225781759\n",
      "K-fold 4 : 0.6928725719451905\n",
      "---------------------------------\n",
      "Average best validation loss: 0.48524618759751326\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 91.82291666666667\n",
      "K-fold 1 : 91.04817708333333\n",
      "K-fold 2 : 93.44401041666667\n",
      "K-fold 3 : 93.69140625\n",
      "K-fold 4 : 94.38151041666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 90.91145833333333\n",
      "K-fold 1 : 88.75\n",
      "K-fold 2 : 94.03645833333333\n",
      "K-fold 3 : 93.30729166666667\n",
      "K-fold 4 : 93.02083333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 91.89453125\n",
      "K-fold 1 : 91.57552083333333\n",
      "K-fold 2 : 93.79557291666667\n",
      "K-fold 3 : 94.19921875\n",
      "K-fold 4 : 94.69401041666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.046875\n",
      "K-fold 1 : 92.23958333333333\n",
      "K-fold 2 : 94.34895833333333\n",
      "K-fold 3 : 95.078125\n",
      "K-fold 4 : 95.49479166666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 94.04166666666666\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2768747789164384\n",
      "K-fold 1 : 0.2827669626722733\n",
      "K-fold 2 : 0.25177215673029424\n",
      "K-fold 3 : 0.25078542766471706\n",
      "K-fold 4 : 0.2417745762815078\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2803423121571541\n",
      "K-fold 1 : 0.2927370627721151\n",
      "K-fold 2 : 0.2411988730231921\n",
      "K-fold 3 : 0.25693281292915343\n",
      "K-fold 4 : 0.2474290187160174\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.27389358716706436\n",
      "K-fold 1 : 0.27763498164713385\n",
      "K-fold 2 : 0.2493715938180685\n",
      "K-fold 3 : 0.24703191295266153\n",
      "K-fold 4 : 0.23732694685459138\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.27944438010454176\n",
      "K-fold 1 : 0.27644454886515935\n",
      "K-fold 2 : 0.23768412619829177\n",
      "K-fold 3 : 0.2495092988014221\n",
      "K-fold 4 : 0.2369585618376732\n",
      "---------------------------------\n",
      "Average best validation loss: 0.25600818316141766\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.126302083333336\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 50.540364583333336\n",
      "K-fold 3 : 50.455729166666664\n",
      "K-fold 4 : 50.735677083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.364583333333336\n",
      "K-fold 1 : 50.911458333333336\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 51.536458333333336\n",
      "K-fold 4 : 51.744791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.217447916666664\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.243489583333336\n",
      "K-fold 3 : 50.8984375\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.364583333333336\n",
      "K-fold 1 : 50.911458333333336\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 51.5625\n",
      "K-fold 4 : 51.744791666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97916666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929945190747578\n",
      "K-fold 1 : 0.693144424756368\n",
      "K-fold 2 : 0.693171293536822\n",
      "K-fold 3 : 0.6931213195125262\n",
      "K-fold 4 : 0.6932974403103193\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933275779088338\n",
      "K-fold 1 : 0.6931071817874909\n",
      "K-fold 2 : 0.693136062224706\n",
      "K-fold 3 : 0.6928887009620667\n",
      "K-fold 4 : 0.6929040233294169\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929208263754845\n",
      "K-fold 1 : 0.6929051607847214\n",
      "K-fold 2 : 0.692910511791706\n",
      "K-fold 3 : 0.6930322522918383\n",
      "K-fold 4 : 0.6930037657419841\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931208908557892\n",
      "K-fold 1 : 0.6929742832978566\n",
      "K-fold 2 : 0.6931184728940328\n",
      "K-fold 3 : 0.6926315426826477\n",
      "K-fold 4 : 0.692538191874822\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928766763210297\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 92.92317708333333\n",
      "K-fold 1 : 93.63932291666667\n",
      "K-fold 2 : 96.02864583333333\n",
      "K-fold 3 : 94.21223958333333\n",
      "K-fold 4 : 94.81119791666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 90.96354166666667\n",
      "K-fold 1 : 95.18229166666667\n",
      "K-fold 2 : 96.27604166666667\n",
      "K-fold 3 : 94.79166666666667\n",
      "K-fold 4 : 95.41666666666667\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 93.2421875\n",
      "K-fold 1 : 94.22526041666667\n",
      "K-fold 2 : 96.02864583333333\n",
      "K-fold 3 : 94.51171875\n",
      "K-fold 4 : 94.95442708333333\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.72395833333333\n",
      "K-fold 1 : 95.44270833333333\n",
      "K-fold 2 : 96.484375\n",
      "K-fold 3 : 94.81770833333333\n",
      "K-fold 4 : 95.49479166666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 95.19270833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.2632510129362345\n",
      "K-fold 1 : 0.25080819688737394\n",
      "K-fold 2 : 0.22542833536863327\n",
      "K-fold 3 : 0.24352743824323017\n",
      "K-fold 4 : 0.2346672839174668\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.27771051128705343\n",
      "K-fold 1 : 0.23749939153591793\n",
      "K-fold 2 : 0.23274105588595073\n",
      "K-fold 3 : 0.2561534826954206\n",
      "K-fold 4 : 0.23379026502370834\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2599676267554363\n",
      "K-fold 1 : 0.2454224766542514\n",
      "K-fold 2 : 0.22504478481908638\n",
      "K-fold 3 : 0.24352743824323017\n",
      "K-fold 4 : 0.23278526129821936\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.26301730424165726\n",
      "K-fold 1 : 0.2372216502825419\n",
      "K-fold 2 : 0.22055614093939463\n",
      "K-fold 3 : 0.2529912665486336\n",
      "K-fold 4 : 0.23244038075208664\n",
      "---------------------------------\n",
      "Average best validation loss: 0.2412453485528628\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-01_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 96.04166666666667\n",
      "K-fold 1 : 50.169270833333336\n",
      "K-fold 2 : 50.540364583333336\n",
      "K-fold 3 : 50.787760416666664\n",
      "K-fold 4 : 50.384114583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 51.979166666666664\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 50.9375\n",
      "K-fold 4 : 50.677083333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 96.12630208333333\n",
      "K-fold 1 : 51.256510416666664\n",
      "K-fold 2 : 51.4453125\n",
      "K-fold 3 : 51.087239583333336\n",
      "K-fold 4 : 51.236979166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 95.83333333333333\n",
      "K-fold 1 : 51.979166666666664\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 50.9375\n",
      "K-fold 4 : 50.677083333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.989583333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.16506627527996898\n",
      "K-fold 1 : 0.6931691686312358\n",
      "K-fold 2 : 0.6938954025506974\n",
      "K-fold 3 : 0.6932360256711642\n",
      "K-fold 4 : 0.6939554075400035\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.16859995325406393\n",
      "K-fold 1 : 0.6928764839967092\n",
      "K-fold 2 : 0.6930759668350219\n",
      "K-fold 3 : 0.6929782330989838\n",
      "K-fold 4 : 0.6931779325008393\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.16503403515865406\n",
      "K-fold 1 : 0.6930264999469121\n",
      "K-fold 2 : 0.6928421467542648\n",
      "K-fold 3 : 0.6929851457476616\n",
      "K-fold 4 : 0.6928832526008288\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.16521921182672183\n",
      "K-fold 1 : 0.6924063265323639\n",
      "K-fold 2 : 0.6930552939573924\n",
      "K-fold 3 : 0.6929714163144429\n",
      "K-fold 4 : 0.6930528302987417\n",
      "---------------------------------\n",
      "Average best validation loss: 0.5873410157859326\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.559895833333336\n",
      "K-fold 1 : 50.833333333333336\n",
      "K-fold 2 : 50.95703125\n",
      "K-fold 3 : 50.364583333333336\n",
      "K-fold 4 : 51.243489583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.390625\n",
      "K-fold 1 : 48.307291666666664\n",
      "K-fold 2 : 48.90625\n",
      "K-fold 3 : 51.692708333333336\n",
      "K-fold 4 : 50.0\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.236979166666664\n",
      "K-fold 1 : 51.0546875\n",
      "K-fold 2 : 51.061197916666664\n",
      "K-fold 3 : 51.03515625\n",
      "K-fold 4 : 51.341145833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.598958333333336\n",
      "K-fold 1 : 51.692708333333336\n",
      "K-fold 2 : 51.276041666666664\n",
      "K-fold 3 : 51.692708333333336\n",
      "K-fold 4 : 51.640625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.380208333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930956189831098\n",
      "K-fold 1 : 0.6930459380149842\n",
      "K-fold 2 : 0.6930893485744795\n",
      "K-fold 3 : 0.6932204152146976\n",
      "K-fold 4 : 0.6929780428608259\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934037248293559\n",
      "K-fold 1 : 0.693433407942454\n",
      "K-fold 2 : 0.6932016472021739\n",
      "K-fold 3 : 0.6928180257479349\n",
      "K-fold 4 : 0.6936842183272044\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928643504778544\n",
      "K-fold 1 : 0.6930167352159818\n",
      "K-fold 2 : 0.6928283552328746\n",
      "K-fold 3 : 0.69297001461188\n",
      "K-fold 4 : 0.69274915655454\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929490307966868\n",
      "K-fold 1 : 0.6925739924112956\n",
      "K-fold 2 : 0.6928313632806142\n",
      "K-fold 3 : 0.6925698260466258\n",
      "K-fold 4 : 0.6930678069591523\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927984038988748\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.7421875\n",
      "K-fold 1 : 51.07421875\n",
      "K-fold 2 : 50.970052083333336\n",
      "K-fold 3 : 50.638020833333336\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 50.572916666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 50.755208333333336\n",
      "K-fold 4 : 51.848958333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.15234375\n",
      "K-fold 1 : 51.321614583333336\n",
      "K-fold 2 : 51.126302083333336\n",
      "K-fold 3 : 51.028645833333336\n",
      "K-fold 4 : 51.067708333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 50.572916666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 50.755208333333336\n",
      "K-fold 4 : 51.848958333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.973958333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930516098936399\n",
      "K-fold 1 : 0.6930309678117434\n",
      "K-fold 2 : 0.6931788424650828\n",
      "K-fold 3 : 0.6929994915922483\n",
      "K-fold 4 : 0.6931689987579982\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930923223495483\n",
      "K-fold 1 : 0.6932708601156871\n",
      "K-fold 2 : 0.6929530560970306\n",
      "K-fold 3 : 0.6933030426502228\n",
      "K-fold 4 : 0.6928114215532939\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928635194897652\n",
      "K-fold 1 : 0.6929098039865493\n",
      "K-fold 2 : 0.6929451867938041\n",
      "K-fold 3 : 0.6929675504565239\n",
      "K-fold 4 : 0.6929490541418394\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930483082930247\n",
      "K-fold 1 : 0.6930815239747365\n",
      "K-fold 2 : 0.6929513136545817\n",
      "K-fold 3 : 0.6930331130822499\n",
      "K-fold 4 : 0.6924665649731954\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929161647955577\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.09375\n",
      "K-fold 1 : 50.17578125\n",
      "K-fold 2 : 49.694010416666664\n",
      "K-fold 3 : 50.481770833333336\n",
      "K-fold 4 : 51.412760416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.947916666666664\n",
      "K-fold 1 : 51.015625\n",
      "K-fold 2 : 52.786458333333336\n",
      "K-fold 3 : 51.901041666666664\n",
      "K-fold 4 : 49.21875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.438802083333336\n",
      "K-fold 1 : 51.178385416666664\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 50.963541666666664\n",
      "K-fold 4 : 51.614583333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.807291666666664\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 52.786458333333336\n",
      "K-fold 3 : 52.526041666666664\n",
      "K-fold 4 : 49.21875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.291666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931500176588694\n",
      "K-fold 1 : 0.6932178407907486\n",
      "K-fold 2 : 0.6932020962238312\n",
      "K-fold 3 : 0.6932449236512184\n",
      "K-fold 4 : 0.6929293543100357\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931898812452952\n",
      "K-fold 1 : 0.6930872599283854\n",
      "K-fold 2 : 0.6919993182023366\n",
      "K-fold 3 : 0.6924717764059702\n",
      "K-fold 4 : 0.6938989380995433\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928279692927997\n",
      "K-fold 1 : 0.6929632395505905\n",
      "K-fold 2 : 0.6931386321783066\n",
      "K-fold 3 : 0.693028761446476\n",
      "K-fold 4 : 0.6926956752936045\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930829266707103\n",
      "K-fold 1 : 0.6928912321726481\n",
      "K-fold 2 : 0.6917025168736776\n",
      "K-fold 3 : 0.6923751095930736\n",
      "K-fold 4 : 0.6932292520999909\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926562074820201\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.299479166666664\n",
      "K-fold 1 : 51.0546875\n",
      "K-fold 2 : 51.061197916666664\n",
      "K-fold 3 : 50.579427083333336\n",
      "K-fold 4 : 51.080729166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.484375\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.5625\n",
      "K-fold 4 : 50.546875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.2890625\n",
      "K-fold 2 : 51.07421875\n",
      "K-fold 3 : 50.865885416666664\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.484375\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.5625\n",
      "K-fold 4 : 50.546875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931881179412206\n",
      "K-fold 1 : 0.6931003451347351\n",
      "K-fold 2 : 0.6930081725120545\n",
      "K-fold 3 : 0.6931159938375155\n",
      "K-fold 4 : 0.6929900924364726\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927075723807017\n",
      "K-fold 1 : 0.6932039439678193\n",
      "K-fold 2 : 0.6931043148040772\n",
      "K-fold 3 : 0.6926875352859497\n",
      "K-fold 4 : 0.693153178691864\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929992020130158\n",
      "K-fold 1 : 0.6928824250896771\n",
      "K-fold 2 : 0.6928714200854301\n",
      "K-fold 3 : 0.6930163751045862\n",
      "K-fold 4 : 0.6928330565492312\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927067716916402\n",
      "K-fold 1 : 0.6930624703566234\n",
      "K-fold 2 : 0.6930693686008453\n",
      "K-fold 3 : 0.6926585376262665\n",
      "K-fold 4 : 0.6930873950322469\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929169086615244\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.768229166666664\n",
      "K-fold 1 : 50.8203125\n",
      "K-fold 2 : 50.651041666666664\n",
      "K-fold 3 : 50.846354166666664\n",
      "K-fold 4 : 50.481770833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.510416666666664\n",
      "K-fold 1 : 50.442708333333336\n",
      "K-fold 2 : 49.765625\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 52.161458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.061197916666664\n",
      "K-fold 1 : 51.54296875\n",
      "K-fold 2 : 51.54296875\n",
      "K-fold 3 : 51.536458333333336\n",
      "K-fold 4 : 51.009114583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.083333333333336\n",
      "K-fold 1 : 50.494791666666664\n",
      "K-fold 2 : 51.09375\n",
      "K-fold 3 : 50.546875\n",
      "K-fold 4 : 52.161458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.276041666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931813552975654\n",
      "K-fold 1 : 0.693103107313315\n",
      "K-fold 2 : 0.6930705214540164\n",
      "K-fold 3 : 0.6931203325589498\n",
      "K-fold 4 : 0.6932312448819479\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.692841899394989\n",
      "K-fold 1 : 0.6931033571561177\n",
      "K-fold 2 : 0.6931520958741506\n",
      "K-fold 3 : 0.6933556199073792\n",
      "K-fold 4 : 0.693028199672699\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693054823577404\n",
      "K-fold 1 : 0.6927663331230481\n",
      "K-fold 2 : 0.6928840016325315\n",
      "K-fold 3 : 0.6928208842873573\n",
      "K-fold 4 : 0.6930820311109225\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926755289236705\n",
      "K-fold 1 : 0.6929743111133575\n",
      "K-fold 2 : 0.6931039810180664\n",
      "K-fold 3 : 0.6930563350518545\n",
      "K-fold 4 : 0.6922088027000427\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928037917613983\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 50.455729166666664\n",
      "K-fold 2 : 50.83984375\n",
      "K-fold 3 : 50.924479166666664\n",
      "K-fold 4 : 50.638020833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.510416666666664\n",
      "K-fold 2 : 49.427083333333336\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.989583333333336\n",
      "K-fold 1 : 51.028645833333336\n",
      "K-fold 2 : 51.165364583333336\n",
      "K-fold 3 : 50.924479166666664\n",
      "K-fold 4 : 51.2109375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.510416666666664\n",
      "K-fold 2 : 50.572916666666664\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930103550354639\n",
      "K-fold 1 : 0.693366077542305\n",
      "K-fold 2 : 0.6930853456258774\n",
      "K-fold 3 : 0.6930002689361572\n",
      "K-fold 4 : 0.6930870751539866\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931162039438884\n",
      "K-fold 1 : 0.6929188986619313\n",
      "K-fold 2 : 0.6933645109335581\n",
      "K-fold 3 : 0.6930740654468537\n",
      "K-fold 4 : 0.693164837360382\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929145753383636\n",
      "K-fold 1 : 0.6929664433002471\n",
      "K-fold 2 : 0.6928949137528737\n",
      "K-fold 3 : 0.6929590811332067\n",
      "K-fold 4 : 0.6929010336597761\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929615259170532\n",
      "K-fold 1 : 0.6926909188429514\n",
      "K-fold 2 : 0.6930815637111664\n",
      "K-fold 3 : 0.6928725520769755\n",
      "K-fold 4 : 0.6930624147256216\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929337950547537\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.677083333333336\n",
      "K-fold 1 : 50.696614583333336\n",
      "K-fold 2 : 50.481770833333336\n",
      "K-fold 3 : 50.670572916666664\n",
      "K-fold 4 : 50.748697916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.536458333333336\n",
      "K-fold 1 : 50.390625\n",
      "K-fold 2 : 51.484375\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.19140625\n",
      "K-fold 1 : 51.5234375\n",
      "K-fold 2 : 51.256510416666664\n",
      "K-fold 3 : 51.328125\n",
      "K-fold 4 : 51.393229166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.640625\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 51.536458333333336\n",
      "K-fold 3 : 50.755208333333336\n",
      "K-fold 4 : 51.536458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.348958333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933708389600118\n",
      "K-fold 1 : 0.6931539694468181\n",
      "K-fold 2 : 0.6932870755592982\n",
      "K-fold 3 : 0.6931071529785792\n",
      "K-fold 4 : 0.6932385931412379\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928982118765513\n",
      "K-fold 1 : 0.6937112212181091\n",
      "K-fold 2 : 0.6927305360635122\n",
      "K-fold 3 : 0.6935796717802684\n",
      "K-fold 4 : 0.6929995238780975\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930616860588391\n",
      "K-fold 1 : 0.6929130951563517\n",
      "K-fold 2 : 0.6930529609322548\n",
      "K-fold 3 : 0.6929580306013425\n",
      "K-fold 4 : 0.6929325784246126\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926666299502054\n",
      "K-fold 1 : 0.6930018345514933\n",
      "K-fold 2 : 0.6926545063654582\n",
      "K-fold 3 : 0.6930439690748851\n",
      "K-fold 4 : 0.6929039895534516\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928541858990986\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-01_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.204427083333336\n",
      "K-fold 1 : 50.677083333333336\n",
      "K-fold 2 : 50.891927083333336\n",
      "K-fold 3 : 50.813802083333336\n",
      "K-fold 4 : 50.436197916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.052083333333336\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.614583333333336\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.555989583333336\n",
      "K-fold 1 : 51.002604166666664\n",
      "K-fold 2 : 51.399739583333336\n",
      "K-fold 3 : 50.944010416666664\n",
      "K-fold 4 : 51.23046875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.052083333333336\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.614583333333336\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.973958333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929171532392502\n",
      "K-fold 1 : 0.6930918822685878\n",
      "K-fold 2 : 0.6930008108417193\n",
      "K-fold 3 : 0.693173166612784\n",
      "K-fold 4 : 0.6931761249899864\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932588219642639\n",
      "K-fold 1 : 0.6929562866687775\n",
      "K-fold 2 : 0.6930684685707093\n",
      "K-fold 3 : 0.6927289485931396\n",
      "K-fold 4 : 0.6929762283960978\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6927551875511805\n",
      "K-fold 1 : 0.6929887021581332\n",
      "K-fold 2 : 0.6929699768622716\n",
      "K-fold 3 : 0.6928550615906716\n",
      "K-fold 4 : 0.6929635648926099\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931467036406199\n",
      "K-fold 1 : 0.6928214887777965\n",
      "K-fold 2 : 0.6929513017336527\n",
      "K-fold 3 : 0.692625739177068\n",
      "K-fold 4 : 0.6929714222749074\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929033311208089\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.169270833333336\n",
      "K-fold 1 : 50.5078125\n",
      "K-fold 2 : 50.794270833333336\n",
      "K-fold 3 : 50.872395833333336\n",
      "K-fold 4 : 51.022135416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.380208333333336\n",
      "K-fold 1 : 50.130208333333336\n",
      "K-fold 2 : 50.833333333333336\n",
      "K-fold 3 : 51.744791666666664\n",
      "K-fold 4 : 50.78125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 51.184895833333336\n",
      "K-fold 2 : 51.100260416666664\n",
      "K-fold 3 : 50.872395833333336\n",
      "K-fold 4 : 51.165364583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.380208333333336\n",
      "K-fold 1 : 50.130208333333336\n",
      "K-fold 2 : 50.833333333333336\n",
      "K-fold 3 : 51.744791666666664\n",
      "K-fold 4 : 50.78125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932295317451159\n",
      "K-fold 1 : 0.6929744248588879\n",
      "K-fold 2 : 0.6931945259372393\n",
      "K-fold 3 : 0.6930601239204407\n",
      "K-fold 4 : 0.693104413151741\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929174482822418\n",
      "K-fold 1 : 0.6939297457536061\n",
      "K-fold 2 : 0.6930586318174998\n",
      "K-fold 3 : 0.692886491616567\n",
      "K-fold 4 : 0.6930249929428101\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929403463999431\n",
      "K-fold 1 : 0.6927228500445684\n",
      "K-fold 2 : 0.6928898135821024\n",
      "K-fold 3 : 0.6930266479651134\n",
      "K-fold 4 : 0.6927420849601428\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927661498387655\n",
      "K-fold 1 : 0.6931438227494557\n",
      "K-fold 2 : 0.6930081268151601\n",
      "K-fold 3 : 0.6925384958585104\n",
      "K-fold 4 : 0.693024601538976\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928962393601736\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.397135416666664\n",
      "K-fold 1 : 51.1328125\n",
      "K-fold 2 : 49.733072916666664\n",
      "K-fold 3 : 51.015625\n",
      "K-fold 4 : 50.794270833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.302083333333336\n",
      "K-fold 1 : 50.338541666666664\n",
      "K-fold 2 : 53.020833333333336\n",
      "K-fold 3 : 49.973958333333336\n",
      "K-fold 4 : 50.182291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.19140625\n",
      "K-fold 1 : 51.263020833333336\n",
      "K-fold 2 : 50.826822916666664\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 51.315104166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.302083333333336\n",
      "K-fold 1 : 50.338541666666664\n",
      "K-fold 2 : 53.020833333333336\n",
      "K-fold 3 : 50.026041666666664\n",
      "K-fold 4 : 50.182291666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932177161176999\n",
      "K-fold 1 : 0.6930566191673279\n",
      "K-fold 2 : 0.6932137454549472\n",
      "K-fold 3 : 0.6929460311929385\n",
      "K-fold 4 : 0.6930789098143577\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928091744581858\n",
      "K-fold 1 : 0.6932360967000325\n",
      "K-fold 2 : 0.692647659778595\n",
      "K-fold 3 : 0.6931472957134247\n",
      "K-fold 4 : 0.6932417611281078\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929604142904282\n",
      "K-fold 1 : 0.692851227025191\n",
      "K-fold 2 : 0.6929011315107345\n",
      "K-fold 3 : 0.6928427244226137\n",
      "K-fold 4 : 0.6927660172184308\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928080598513285\n",
      "K-fold 1 : 0.6931242763996124\n",
      "K-fold 2 : 0.6915949583053589\n",
      "K-fold 3 : 0.6931470513343811\n",
      "K-fold 4 : 0.6931405285994212\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927629748980204\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.494791666666664\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 51.087239583333336\n",
      "K-fold 3 : 50.774739583333336\n",
      "K-fold 4 : 51.09375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.432291666666664\n",
      "K-fold 1 : 51.067708333333336\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 50.494791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.002604166666664\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.282552083333336\n",
      "K-fold 3 : 51.11328125\n",
      "K-fold 4 : 51.106770833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.432291666666664\n",
      "K-fold 1 : 51.067708333333336\n",
      "K-fold 2 : 50.520833333333336\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 50.494791666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930994187792142\n",
      "K-fold 1 : 0.6930816863973935\n",
      "K-fold 2 : 0.693015898267428\n",
      "K-fold 3 : 0.6931121860941251\n",
      "K-fold 4 : 0.6930816700061162\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927816152572632\n",
      "K-fold 1 : 0.6929690460364024\n",
      "K-fold 2 : 0.6930994530518849\n",
      "K-fold 3 : 0.6928283492724101\n",
      "K-fold 4 : 0.693117908636729\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929770862062772\n",
      "K-fold 1 : 0.692946636180083\n",
      "K-fold 2 : 0.6928170114755631\n",
      "K-fold 3 : 0.6929335017999013\n",
      "K-fold 4 : 0.6928545465071996\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927371323108673\n",
      "K-fold 1 : 0.6929187953472138\n",
      "K-fold 2 : 0.6930929501851399\n",
      "K-fold 3 : 0.6927803834279378\n",
      "K-fold 4 : 0.6930981079737345\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929254738489787\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 50.572916666666664\n",
      "K-fold 2 : 50.872395833333336\n",
      "K-fold 3 : 50.384114583333336\n",
      "K-fold 4 : 50.592447916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 51.015625\n",
      "K-fold 2 : 50.807291666666664\n",
      "K-fold 3 : 50.625\n",
      "K-fold 4 : 51.71875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.315104166666664\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.061197916666664\n",
      "K-fold 4 : 50.99609375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 51.015625\n",
      "K-fold 2 : 50.807291666666664\n",
      "K-fold 3 : 50.625\n",
      "K-fold 4 : 51.71875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929892028371493\n",
      "K-fold 1 : 0.6931316360831261\n",
      "K-fold 2 : 0.6930977473656337\n",
      "K-fold 3 : 0.6931722640991211\n",
      "K-fold 4 : 0.6931322192152342\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930484533309936\n",
      "K-fold 1 : 0.6931357224782307\n",
      "K-fold 2 : 0.6930356562137604\n",
      "K-fold 3 : 0.6930796464284261\n",
      "K-fold 4 : 0.6927249809106191\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928390388687452\n",
      "K-fold 1 : 0.692870191236337\n",
      "K-fold 2 : 0.6928879315654437\n",
      "K-fold 3 : 0.6929200544953347\n",
      "K-fold 4 : 0.6929565995931626\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930483102798461\n",
      "K-fold 1 : 0.6929408470789592\n",
      "K-fold 2 : 0.6930168032646179\n",
      "K-fold 3 : 0.6930690864721935\n",
      "K-fold 4 : 0.6925565858681997\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929263265927632\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.197916666666664\n",
      "K-fold 1 : 50.319010416666664\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.833333333333336\n",
      "K-fold 4 : 50.013020833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.078125\n",
      "K-fold 1 : 51.171875\n",
      "K-fold 2 : 51.223958333333336\n",
      "K-fold 3 : 49.140625\n",
      "K-fold 4 : 51.536458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.236979166666664\n",
      "K-fold 1 : 51.106770833333336\n",
      "K-fold 2 : 51.11328125\n",
      "K-fold 3 : 51.458333333333336\n",
      "K-fold 4 : 51.0546875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.078125\n",
      "K-fold 1 : 51.171875\n",
      "K-fold 2 : 51.223958333333336\n",
      "K-fold 3 : 50.859375\n",
      "K-fold 4 : 51.588541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.984375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6929649725556374\n",
      "K-fold 1 : 0.6930821786324183\n",
      "K-fold 2 : 0.6930892482399941\n",
      "K-fold 3 : 0.6930414294203122\n",
      "K-fold 4 : 0.6932300498088201\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693451871474584\n",
      "K-fold 1 : 0.6929335812727611\n",
      "K-fold 2 : 0.6929705123106639\n",
      "K-fold 3 : 0.6932259261608124\n",
      "K-fold 4 : 0.6927241722742716\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6927329783638319\n",
      "K-fold 1 : 0.6928998867670695\n",
      "K-fold 2 : 0.6929761971036593\n",
      "K-fold 3 : 0.6928344582517941\n",
      "K-fold 4 : 0.6929402326544126\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931457440058391\n",
      "K-fold 1 : 0.6928723394870758\n",
      "K-fold 2 : 0.6928451259930929\n",
      "K-fold 3 : 0.6929971357186635\n",
      "K-fold 4 : 0.6926742037137349\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929069097836813\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.03515625\n",
      "K-fold 1 : 49.84375\n",
      "K-fold 2 : 50.657552083333336\n",
      "K-fold 3 : 51.165364583333336\n",
      "K-fold 4 : 50.68359375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.114583333333336\n",
      "K-fold 1 : 51.640625\n",
      "K-fold 2 : 51.40625\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.07421875\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.126302083333336\n",
      "K-fold 3 : 51.673177083333336\n",
      "K-fold 4 : 51.204427083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.640625\n",
      "K-fold 2 : 51.40625\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 50.729166666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6930635750293732\n",
      "K-fold 1 : 0.6932203322649002\n",
      "K-fold 2 : 0.6930881217122078\n",
      "K-fold 3 : 0.6929715543985366\n",
      "K-fold 4 : 0.6931782399614652\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934339006741842\n",
      "K-fold 1 : 0.6928905228773753\n",
      "K-fold 2 : 0.6928298036257426\n",
      "K-fold 3 : 0.6931864301363627\n",
      "K-fold 4 : 0.6930505037307739\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929071376721064\n",
      "K-fold 1 : 0.6929769436518352\n",
      "K-fold 2 : 0.6929539635777473\n",
      "K-fold 3 : 0.6925938780109088\n",
      "K-fold 4 : 0.6928896849354108\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929904441038768\n",
      "K-fold 1 : 0.6926098585128784\n",
      "K-fold 2 : 0.6927516420682271\n",
      "K-fold 3 : 0.6931384881337483\n",
      "K-fold 4 : 0.6930408159891764\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929062497615814\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.5078125\n",
      "K-fold 1 : 51.26953125\n",
      "K-fold 2 : 50.475260416666664\n",
      "K-fold 3 : 51.15234375\n",
      "K-fold 4 : 51.184895833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 49.791666666666664\n",
      "K-fold 2 : 51.901041666666664\n",
      "K-fold 3 : 48.229166666666664\n",
      "K-fold 4 : 50.130208333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.295572916666664\n",
      "K-fold 2 : 50.99609375\n",
      "K-fold 3 : 51.15234375\n",
      "K-fold 4 : 51.223958333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 50.208333333333336\n",
      "K-fold 2 : 51.901041666666664\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 50.130208333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.05729166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932376732428869\n",
      "K-fold 1 : 0.6929812942941983\n",
      "K-fold 2 : 0.6931078031659126\n",
      "K-fold 3 : 0.6929461235801379\n",
      "K-fold 4 : 0.6929717396696409\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928809682528178\n",
      "K-fold 1 : 0.6935820142428081\n",
      "K-fold 2 : 0.6926236848036448\n",
      "K-fold 3 : 0.6938604871431987\n",
      "K-fold 4 : 0.6931709726651509\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929458210865657\n",
      "K-fold 1 : 0.6927855571111043\n",
      "K-fold 2 : 0.6929023817181588\n",
      "K-fold 3 : 0.6929461235801379\n",
      "K-fold 4 : 0.6928381418188413\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928192178408304\n",
      "K-fold 1 : 0.6931387265523274\n",
      "K-fold 2 : 0.6924249033133189\n",
      "K-fold 3 : 0.6925256152947744\n",
      "K-fold 4 : 0.6931430657704671\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928103057543437\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-01_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.09375\n",
      "K-fold 2 : 51.022135416666664\n",
      "K-fold 3 : 50.9375\n",
      "K-fold 4 : 50.279947916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.494791666666664\n",
      "K-fold 1 : 50.078125\n",
      "K-fold 2 : 49.21875\n",
      "K-fold 3 : 51.484375\n",
      "K-fold 4 : 52.03125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.1328125\n",
      "K-fold 1 : 51.497395833333336\n",
      "K-fold 2 : 51.204427083333336\n",
      "K-fold 3 : 51.080729166666664\n",
      "K-fold 4 : 51.15234375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.494791666666664\n",
      "K-fold 1 : 50.078125\n",
      "K-fold 2 : 50.78125\n",
      "K-fold 3 : 51.484375\n",
      "K-fold 4 : 52.03125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6928622931241989\n",
      "K-fold 1 : 0.6929634322722753\n",
      "K-fold 2 : 0.6930762320756912\n",
      "K-fold 3 : 0.6931453153491021\n",
      "K-fold 4 : 0.6931157072385152\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938057482242584\n",
      "K-fold 1 : 0.6931529541810354\n",
      "K-fold 2 : 0.6931544542312622\n",
      "K-fold 3 : 0.6927764892578125\n",
      "K-fold 4 : 0.6924881478150685\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928622931241989\n",
      "K-fold 1 : 0.6926773781577746\n",
      "K-fold 2 : 0.6929101874430974\n",
      "K-fold 3 : 0.6929224262634913\n",
      "K-fold 4 : 0.6929202536741893\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693098231156667\n",
      "K-fold 1 : 0.6931459546089173\n",
      "K-fold 2 : 0.69302512605985\n",
      "K-fold 3 : 0.6927065889040629\n",
      "K-fold 4 : 0.6923317551612854\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928615311781565\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.071614583333336\n",
      "K-fold 1 : 50.72265625\n",
      "K-fold 2 : 62.005208333333336\n",
      "K-fold 3 : 50.338541666666664\n",
      "K-fold 4 : 73.26171875\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.4375\n",
      "K-fold 1 : 49.53125\n",
      "K-fold 2 : 60.234375\n",
      "K-fold 3 : 51.536458333333336\n",
      "K-fold 4 : 73.984375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.087239583333336\n",
      "K-fold 1 : 51.40625\n",
      "K-fold 2 : 62.057291666666664\n",
      "K-fold 3 : 52.578125\n",
      "K-fold 4 : 73.359375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.744791666666664\n",
      "K-fold 1 : 50.46875\n",
      "K-fold 2 : 60.416666666666664\n",
      "K-fold 3 : 55.052083333333336\n",
      "K-fold 4 : 74.16666666666667\n",
      "---------------------------------\n",
      "Average best validation accuracy: 58.369791666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935623437166214\n",
      "K-fold 1 : 0.6932489896814028\n",
      "K-fold 2 : 0.6064879854520162\n",
      "K-fold 3 : 0.6943680544694265\n",
      "K-fold 4 : 0.4874820021291574\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6939403573671977\n",
      "K-fold 1 : 0.6954100847244262\n",
      "K-fold 2 : 0.6205568532148997\n",
      "K-fold 3 : 0.6929498434066772\n",
      "K-fold 4 : 0.49090472559134163\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931480025251706\n",
      "K-fold 1 : 0.6926878988742828\n",
      "K-fold 2 : 0.6052617823084195\n",
      "K-fold 3 : 0.6916178653637568\n",
      "K-fold 4 : 0.48732663989067077\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6921052674452464\n",
      "K-fold 1 : 0.6931034048398336\n",
      "K-fold 2 : 0.6109706342220307\n",
      "K-fold 3 : 0.6907045741875967\n",
      "K-fold 4 : 0.48424846430619556\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6342264690001806\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.0\n",
      "K-fold 1 : 50.1953125\n",
      "K-fold 2 : 49.8046875\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.846354166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.307291666666664\n",
      "K-fold 1 : 49.661458333333336\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.640625\n",
      "K-fold 4 : 50.807291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.0546875\n",
      "K-fold 1 : 51.315104166666664\n",
      "K-fold 2 : 51.106770833333336\n",
      "K-fold 3 : 51.0546875\n",
      "K-fold 4 : 51.276041666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.692708333333336\n",
      "K-fold 1 : 50.338541666666664\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.640625\n",
      "K-fold 4 : 50.807291666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.109375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935558239618937\n",
      "K-fold 1 : 0.6933289979894955\n",
      "K-fold 2 : 0.6941977004210155\n",
      "K-fold 3 : 0.6935690104961395\n",
      "K-fold 4 : 0.6931705350677172\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.695316751797994\n",
      "K-fold 1 : 0.6937585413455963\n",
      "K-fold 2 : 0.6930000106493632\n",
      "K-fold 3 : 0.6930526971817017\n",
      "K-fold 4 : 0.6955960988998413\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931947315732638\n",
      "K-fold 1 : 0.6929772933324178\n",
      "K-fold 2 : 0.6931282227238019\n",
      "K-fold 3 : 0.6931394845247268\n",
      "K-fold 4 : 0.6929755667845409\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6925741155942281\n",
      "K-fold 1 : 0.6931244711081187\n",
      "K-fold 2 : 0.6929192066192627\n",
      "K-fold 3 : 0.6926092942555745\n",
      "K-fold 4 : 0.6930168747901917\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928487924734752\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 66.31510416666667\n",
      "K-fold 1 : 50.319010416666664\n",
      "K-fold 2 : 50.631510416666664\n",
      "K-fold 3 : 50.364583333333336\n",
      "K-fold 4 : 50.807291666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 65.859375\n",
      "K-fold 1 : 50.260416666666664\n",
      "K-fold 2 : 50.46875\n",
      "K-fold 3 : 51.848958333333336\n",
      "K-fold 4 : 49.947916666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 67.17447916666667\n",
      "K-fold 1 : 51.263020833333336\n",
      "K-fold 2 : 51.2109375\n",
      "K-fold 3 : 50.852864583333336\n",
      "K-fold 4 : 51.341145833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 77.65625\n",
      "K-fold 1 : 51.328125\n",
      "K-fold 2 : 50.625\n",
      "K-fold 3 : 51.927083333333336\n",
      "K-fold 4 : 50.46875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 56.40104166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.4794594379762808\n",
      "K-fold 1 : 0.6942662447690964\n",
      "K-fold 2 : 0.693449524541696\n",
      "K-fold 3 : 0.6941227162877719\n",
      "K-fold 4 : 0.6908337270220121\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.4797224273284276\n",
      "K-fold 1 : 0.6945521732171377\n",
      "K-fold 2 : 0.6931080083052318\n",
      "K-fold 3 : 0.6929073472817738\n",
      "K-fold 4 : 0.6911060055096944\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.4742054837445418\n",
      "K-fold 1 : 0.6930706416567166\n",
      "K-fold 2 : 0.6929306363066038\n",
      "K-fold 3 : 0.6931425789992015\n",
      "K-fold 4 : 0.6900975008805593\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.47714102566242217\n",
      "K-fold 1 : 0.6929949978987376\n",
      "K-fold 2 : 0.6931002974510193\n",
      "K-fold 3 : 0.6924059311548869\n",
      "K-fold 4 : 0.6898226082324982\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6490929720799128\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.026041666666664\n",
      "K-fold 1 : 50.6640625\n",
      "K-fold 2 : 50.130208333333336\n",
      "K-fold 3 : 50.319010416666664\n",
      "K-fold 4 : 50.09765625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 52.005208333333336\n",
      "K-fold 1 : 49.244791666666664\n",
      "K-fold 2 : 50.234375\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 52.005208333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.002604166666664\n",
      "K-fold 1 : 51.236979166666664\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.1875\n",
      "K-fold 1 : 50.833333333333336\n",
      "K-fold 2 : 50.494791666666664\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 52.03125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.13541666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935764759778976\n",
      "K-fold 1 : 0.6933852131168048\n",
      "K-fold 2 : 0.693416972955068\n",
      "K-fold 3 : 0.6947329481442769\n",
      "K-fold 4 : 0.6947694639364879\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6925431172053019\n",
      "K-fold 1 : 0.6947355588277181\n",
      "K-fold 2 : 0.6935088276863098\n",
      "K-fold 3 : 0.693355401357015\n",
      "K-fold 4 : 0.692936098575592\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931523611148198\n",
      "K-fold 1 : 0.6930627763271332\n",
      "K-fold 2 : 0.6929124201337497\n",
      "K-fold 3 : 0.6930435746908188\n",
      "K-fold 4 : 0.6932182485858599\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6923434774080912\n",
      "K-fold 1 : 0.6929643829663594\n",
      "K-fold 2 : 0.693135263522466\n",
      "K-fold 3 : 0.6931438068548839\n",
      "K-fold 4 : 0.6923470119635264\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927867885430654\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 87.25260416666667\n",
      "K-fold 1 : 87.79947916666667\n",
      "K-fold 2 : 91.11979166666667\n",
      "K-fold 3 : 95.78125\n",
      "K-fold 4 : 66.11979166666667\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 93.64583333333333\n",
      "K-fold 1 : 84.89583333333333\n",
      "K-fold 2 : 92.21354166666667\n",
      "K-fold 3 : 95.65104166666667\n",
      "K-fold 4 : 65.05208333333333\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 88.4375\n",
      "K-fold 1 : 88.50911458333333\n",
      "K-fold 2 : 91.15234375\n",
      "K-fold 3 : 95.87890625\n",
      "K-fold 4 : 72.60416666666667\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.77604166666667\n",
      "K-fold 1 : 93.4375\n",
      "K-fold 2 : 92.21354166666667\n",
      "K-fold 3 : 95.91145833333333\n",
      "K-fold 4 : 80.98958333333333\n",
      "---------------------------------\n",
      "Average best validation accuracy: 91.265625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.3004656909654538\n",
      "K-fold 1 : 0.32096604965627196\n",
      "K-fold 2 : 0.2680355167637269\n",
      "K-fold 3 : 0.19725642955551545\n",
      "K-fold 4 : 0.4836178461710612\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.2964183007677396\n",
      "K-fold 1 : 0.34260241985321044\n",
      "K-fold 2 : 0.24704849223295847\n",
      "K-fold 3 : 0.20789775997400284\n",
      "K-fold 4 : 0.5015320738156637\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2972021979590257\n",
      "K-fold 1 : 0.31652190486590065\n",
      "K-fold 2 : 0.2586687152584394\n",
      "K-fold 3 : 0.19365039002150297\n",
      "K-fold 4 : 0.4814057908952236\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.28278010835250217\n",
      "K-fold 1 : 0.31410137663284937\n",
      "K-fold 2 : 0.24704849223295847\n",
      "K-fold 3 : 0.185721259812514\n",
      "K-fold 4 : 0.48062734405199686\n",
      "---------------------------------\n",
      "Average best validation loss: 0.30205571621656413\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.3671875\n",
      "K-fold 1 : 50.423177083333336\n",
      "K-fold 2 : 60.104166666666664\n",
      "K-fold 3 : 50.17578125\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.588541666666664\n",
      "K-fold 2 : 60.416666666666664\n",
      "K-fold 3 : 50.260416666666664\n",
      "K-fold 4 : 51.432291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.3671875\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 61.315104166666664\n",
      "K-fold 3 : 51.334635416666664\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.989583333333336\n",
      "K-fold 1 : 51.588541666666664\n",
      "K-fold 2 : 60.703125\n",
      "K-fold 3 : 50.598958333333336\n",
      "K-fold 4 : 51.432291666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 53.0625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6937683686614037\n",
      "K-fold 1 : 0.6942626838882764\n",
      "K-fold 2 : 0.5802611713608106\n",
      "K-fold 3 : 0.6935087362925212\n",
      "K-fold 4 : 0.6936671788493792\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930095752080282\n",
      "K-fold 1 : 0.6927127500375112\n",
      "K-fold 2 : 0.5827079395453135\n",
      "K-fold 3 : 0.6931349317232768\n",
      "K-fold 4 : 0.6930199682712554\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931024879217148\n",
      "K-fold 1 : 0.6931902741392454\n",
      "K-fold 2 : 0.5770994288225969\n",
      "K-fold 3 : 0.6930021484692891\n",
      "K-fold 4 : 0.6931689888238907\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929615457852681\n",
      "K-fold 1 : 0.6926429728666942\n",
      "K-fold 2 : 0.5768112301826477\n",
      "K-fold 3 : 0.6930919686953226\n",
      "K-fold 4 : 0.6927336156368256\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6696482666333516\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 86.27604166666667\n",
      "K-fold 1 : 50.501302083333336\n",
      "K-fold 2 : 94.50520833333333\n",
      "K-fold 3 : 93.60677083333333\n",
      "K-fold 4 : 50.755208333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 83.203125\n",
      "K-fold 1 : 51.744791666666664\n",
      "K-fold 2 : 96.015625\n",
      "K-fold 3 : 92.08333333333333\n",
      "K-fold 4 : 49.375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 86.59505208333333\n",
      "K-fold 1 : 51.236979166666664\n",
      "K-fold 2 : 94.921875\n",
      "K-fold 3 : 93.72395833333333\n",
      "K-fold 4 : 51.6796875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 93.69791666666667\n",
      "K-fold 1 : 52.630208333333336\n",
      "K-fold 2 : 96.11979166666667\n",
      "K-fold 3 : 92.890625\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 77.25520833333334\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.29387066327035427\n",
      "K-fold 1 : 0.6936093305548032\n",
      "K-fold 2 : 0.2291091895972689\n",
      "K-fold 3 : 0.22114131630708775\n",
      "K-fold 4 : 0.6950460026661555\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.30415640473365785\n",
      "K-fold 1 : 0.6917482952276865\n",
      "K-fold 2 : 0.20731476371486982\n",
      "K-fold 3 : 0.25772890249888103\n",
      "K-fold 4 : 0.6947584589322408\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2918516314278046\n",
      "K-fold 1 : 0.6911328037579855\n",
      "K-fold 2 : 0.21910682370265325\n",
      "K-fold 3 : 0.21570909495155016\n",
      "K-fold 4 : 0.6929859419663748\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2852986574172974\n",
      "K-fold 1 : 0.6908538818359375\n",
      "K-fold 2 : 0.19721555213133493\n",
      "K-fold 3 : 0.23019916887084643\n",
      "K-fold 4 : 0.6930452744166057\n",
      "---------------------------------\n",
      "Average best validation loss: 0.4193225069344044\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-05_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.169270833333336\n",
      "K-fold 1 : 49.811197916666664\n",
      "K-fold 2 : 90.45572916666667\n",
      "K-fold 3 : 50.611979166666664\n",
      "K-fold 4 : 51.302083333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.104166666666664\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 90.41666666666667\n",
      "K-fold 3 : 51.328125\n",
      "K-fold 4 : 50.494791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.204427083333336\n",
      "K-fold 1 : 51.399739583333336\n",
      "K-fold 2 : 90.57942708333333\n",
      "K-fold 3 : 51.022135416666664\n",
      "K-fold 4 : 51.54296875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 51.510416666666664\n",
      "K-fold 2 : 90.41666666666667\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 50.807291666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.166666666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.697094485660394\n",
      "K-fold 1 : 0.6938256437579791\n",
      "K-fold 2 : 0.2812896070381006\n",
      "K-fold 3 : 0.6939080764849981\n",
      "K-fold 4 : 0.6936706279714903\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934896151224772\n",
      "K-fold 1 : 0.6929257929325103\n",
      "K-fold 2 : 0.3463330760598183\n",
      "K-fold 3 : 0.6928746978441874\n",
      "K-fold 4 : 0.7065251966317495\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931471079587936\n",
      "K-fold 1 : 0.6929450392723083\n",
      "K-fold 2 : 0.2704433458546797\n",
      "K-fold 3 : 0.6932459180553754\n",
      "K-fold 4 : 0.6929817522565523\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930536190668742\n",
      "K-fold 1 : 0.6929257929325103\n",
      "K-fold 2 : 0.26229217151800793\n",
      "K-fold 3 : 0.6927943587303161\n",
      "K-fold 4 : 0.6930668314297994\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6068265547355016\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 50.13671875\n",
      "K-fold 2 : 50.475260416666664\n",
      "K-fold 3 : 50.423177083333336\n",
      "K-fold 4 : 49.700520833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 51.536458333333336\n",
      "K-fold 2 : 50.260416666666664\n",
      "K-fold 3 : 50.598958333333336\n",
      "K-fold 4 : 48.671875\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.4453125\n",
      "K-fold 1 : 51.07421875\n",
      "K-fold 2 : 51.399739583333336\n",
      "K-fold 3 : 51.19140625\n",
      "K-fold 4 : 51.080729166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 52.1875\n",
      "K-fold 2 : 51.09375\n",
      "K-fold 3 : 51.09375\n",
      "K-fold 4 : 51.640625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.42708333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693406255543232\n",
      "K-fold 1 : 0.6936501378814379\n",
      "K-fold 2 : 0.6936259796222051\n",
      "K-fold 3 : 0.6937924216190974\n",
      "K-fold 4 : 0.693980318804582\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6969729204972585\n",
      "K-fold 1 : 0.6926786522070567\n",
      "K-fold 2 : 0.6938406805197398\n",
      "K-fold 3 : 0.6930497964223226\n",
      "K-fold 4 : 0.6931501944859823\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932247623801231\n",
      "K-fold 1 : 0.6932292635242144\n",
      "K-fold 2 : 0.6930060346921285\n",
      "K-fold 3 : 0.693072909116745\n",
      "K-fold 4 : 0.6931487873196602\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928045789400736\n",
      "K-fold 1 : 0.6922485987345378\n",
      "K-fold 2 : 0.6929248988628387\n",
      "K-fold 3 : 0.6929267187913258\n",
      "K-fold 4 : 0.6925700426101684\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926949675877889\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.358072916666664\n",
      "K-fold 1 : 50.852864583333336\n",
      "K-fold 2 : 51.25\n",
      "K-fold 3 : 50.390625\n",
      "K-fold 4 : 50.05859375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.666666666666664\n",
      "K-fold 1 : 49.791666666666664\n",
      "K-fold 2 : 50.703125\n",
      "K-fold 3 : 48.151041666666664\n",
      "K-fold 4 : 50.442708333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.243489583333336\n",
      "K-fold 1 : 51.360677083333336\n",
      "K-fold 2 : 51.38671875\n",
      "K-fold 3 : 51.692708333333336\n",
      "K-fold 4 : 51.419270833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.666666666666664\n",
      "K-fold 1 : 50.286458333333336\n",
      "K-fold 2 : 50.703125\n",
      "K-fold 3 : 51.848958333333336\n",
      "K-fold 4 : 50.442708333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.989583333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6938136498133342\n",
      "K-fold 1 : 0.6935469562808673\n",
      "K-fold 2 : 0.6943029880523681\n",
      "K-fold 3 : 0.6934457699457804\n",
      "K-fold 4 : 0.6940327435731888\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927322447299957\n",
      "K-fold 1 : 0.6934577981630962\n",
      "K-fold 2 : 0.693501623471578\n",
      "K-fold 3 : 0.6944307088851929\n",
      "K-fold 4 : 0.6934735357761384\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930652439594269\n",
      "K-fold 1 : 0.6929475540916125\n",
      "K-fold 2 : 0.6930336286624272\n",
      "K-fold 3 : 0.6928667172789573\n",
      "K-fold 4 : 0.6928739562630654\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6925160884857178\n",
      "K-fold 1 : 0.6931384364763896\n",
      "K-fold 2 : 0.692985725402832\n",
      "K-fold 3 : 0.6924633105595907\n",
      "K-fold 4 : 0.6931080162525177\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928423154354095\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 50.397135416666664\n",
      "K-fold 2 : 50.1953125\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 50.032552083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.78125\n",
      "K-fold 1 : 50.9375\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 50.546875\n",
      "K-fold 4 : 51.458333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 51.171875\n",
      "K-fold 2 : 51.100260416666664\n",
      "K-fold 3 : 51.412760416666664\n",
      "K-fold 4 : 50.970052083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.057291666666664\n",
      "K-fold 1 : 51.302083333333336\n",
      "K-fold 2 : 51.927083333333336\n",
      "K-fold 3 : 51.328125\n",
      "K-fold 4 : 51.692708333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.661458333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.694577639301618\n",
      "K-fold 1 : 0.6943499917785326\n",
      "K-fold 2 : 0.6936819821596145\n",
      "K-fold 3 : 0.6939362714687983\n",
      "K-fold 4 : 0.6943924913803736\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929544587930043\n",
      "K-fold 1 : 0.6930342058340708\n",
      "K-fold 2 : 0.6927693406740825\n",
      "K-fold 3 : 0.6931597729523976\n",
      "K-fold 4 : 0.6928215503692627\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932201599081357\n",
      "K-fold 1 : 0.693493777513504\n",
      "K-fold 2 : 0.6933375140031178\n",
      "K-fold 3 : 0.6933880979816119\n",
      "K-fold 4 : 0.6933847392598788\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6926674127578736\n",
      "K-fold 1 : 0.6928034961223603\n",
      "K-fold 2 : 0.6926938692728678\n",
      "K-fold 3 : 0.6927852094173431\n",
      "K-fold 4 : 0.6924616257349651\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692682322661082\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.8984375\n",
      "K-fold 1 : 50.768229166666664\n",
      "K-fold 2 : 49.04296875\n",
      "K-fold 3 : 50.68359375\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.765625\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 52.135416666666664\n",
      "K-fold 3 : 50.885416666666664\n",
      "K-fold 4 : 49.036458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.555989583333336\n",
      "K-fold 1 : 51.295572916666664\n",
      "K-fold 2 : 51.080729166666664\n",
      "K-fold 3 : 51.15234375\n",
      "K-fold 4 : 51.282552083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.416666666666664\n",
      "K-fold 1 : 51.223958333333336\n",
      "K-fold 2 : 52.135416666666664\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.317708333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934563338756561\n",
      "K-fold 1 : 0.6932797893881798\n",
      "K-fold 2 : 0.6945452049374581\n",
      "K-fold 3 : 0.6934840669234593\n",
      "K-fold 4 : 0.6956375792622567\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6952873051166535\n",
      "K-fold 1 : 0.692997686068217\n",
      "K-fold 2 : 0.6924155493577321\n",
      "K-fold 3 : 0.6929908593495687\n",
      "K-fold 4 : 0.7168365160624186\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928988188505173\n",
      "K-fold 1 : 0.6930485809842746\n",
      "K-fold 2 : 0.6932617545127868\n",
      "K-fold 3 : 0.6929939409097036\n",
      "K-fold 4 : 0.6931472380956014\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931362469991048\n",
      "K-fold 1 : 0.6928784489631653\n",
      "K-fold 2 : 0.6922135551770529\n",
      "K-fold 3 : 0.6929908593495687\n",
      "K-fold 4 : 0.6928790628910064\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928196346759796\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 91.97916666666667\n",
      "K-fold 1 : 50.247395833333336\n",
      "K-fold 2 : 50.99609375\n",
      "K-fold 3 : 49.9609375\n",
      "K-fold 4 : 50.638020833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 91.22395833333333\n",
      "K-fold 1 : 49.609375\n",
      "K-fold 2 : 48.307291666666664\n",
      "K-fold 3 : 49.192708333333336\n",
      "K-fold 4 : 49.453125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 92.18098958333333\n",
      "K-fold 1 : 51.223958333333336\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.1328125\n",
      "K-fold 4 : 51.23046875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 92.734375\n",
      "K-fold 1 : 51.458333333333336\n",
      "K-fold 2 : 52.03125\n",
      "K-fold 3 : 51.432291666666664\n",
      "K-fold 4 : 51.770833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 59.885416666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.27968897062043346\n",
      "K-fold 1 : 0.6959552814563116\n",
      "K-fold 2 : 0.6948244561751683\n",
      "K-fold 3 : 0.6954467301567395\n",
      "K-fold 4 : 0.6951460152864456\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.27848782887061435\n",
      "K-fold 1 : 0.6947244008382162\n",
      "K-fold 2 : 0.6959006647268932\n",
      "K-fold 3 : 0.7052853246529897\n",
      "K-fold 4 : 0.6995569904645283\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.2724564138799906\n",
      "K-fold 1 : 0.6937092592318853\n",
      "K-fold 2 : 0.6937657997012139\n",
      "K-fold 3 : 0.6936660533150037\n",
      "K-fold 4 : 0.6934420769413312\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.2670164028803507\n",
      "K-fold 1 : 0.6928713023662567\n",
      "K-fold 2 : 0.6924070239067077\n",
      "K-fold 3 : 0.6928732911745707\n",
      "K-fold 4 : 0.6923561453819275\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6075048331419628\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.514322916666664\n",
      "K-fold 1 : 50.436197916666664\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 50.553385416666664\n",
      "K-fold 4 : 50.403645833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 48.515625\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 50.0\n",
      "K-fold 4 : 51.510416666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.321614583333336\n",
      "K-fold 1 : 51.100260416666664\n",
      "K-fold 2 : 51.256510416666664\n",
      "K-fold 3 : 51.477864583333336\n",
      "K-fold 4 : 50.95703125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.380208333333336\n",
      "K-fold 1 : 51.510416666666664\n",
      "K-fold 2 : 51.380208333333336\n",
      "K-fold 3 : 50.546875\n",
      "K-fold 4 : 51.588541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.28125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934970840811729\n",
      "K-fold 1 : 0.6934583271543185\n",
      "K-fold 2 : 0.693671491742134\n",
      "K-fold 3 : 0.6931684558590253\n",
      "K-fold 4 : 0.6948603630065918\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693184886376063\n",
      "K-fold 1 : 0.693278435866038\n",
      "K-fold 2 : 0.6931600133577983\n",
      "K-fold 3 : 0.6936619440714519\n",
      "K-fold 4 : 0.7061358213424682\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931294977664948\n",
      "K-fold 1 : 0.6932114894191425\n",
      "K-fold 2 : 0.6931030044953028\n",
      "K-fold 3 : 0.6930634458859761\n",
      "K-fold 4 : 0.693121130267779\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928791860739391\n",
      "K-fold 1 : 0.6927012622356414\n",
      "K-fold 2 : 0.6929730753103892\n",
      "K-fold 3 : 0.6931335389614105\n",
      "K-fold 4 : 0.6926097532113393\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928593631585439\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.924479166666664\n",
      "K-fold 1 : 50.201822916666664\n",
      "K-fold 2 : 50.696614583333336\n",
      "K-fold 3 : 50.592447916666664\n",
      "K-fold 4 : 49.720052083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.713541666666664\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 49.661458333333336\n",
      "K-fold 3 : 47.630208333333336\n",
      "K-fold 4 : 51.328125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.321614583333336\n",
      "K-fold 1 : 51.139322916666664\n",
      "K-fold 2 : 51.40625\n",
      "K-fold 3 : 50.91796875\n",
      "K-fold 4 : 51.328125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 51.510416666666664\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 52.578125\n",
      "K-fold 4 : 51.640625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.59375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6948245838284492\n",
      "K-fold 1 : 0.6953912114103635\n",
      "K-fold 2 : 0.6948710029323896\n",
      "K-fold 3 : 0.6952505017320315\n",
      "K-fold 4 : 0.6942277828852336\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934722065925598\n",
      "K-fold 1 : 0.6931204696496328\n",
      "K-fold 2 : 0.6937280019124349\n",
      "K-fold 3 : 0.6951960682868957\n",
      "K-fold 4 : 0.6934920728206635\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6942217151323954\n",
      "K-fold 1 : 0.694198872645696\n",
      "K-fold 2 : 0.6944362660249074\n",
      "K-fold 3 : 0.6942862773935\n",
      "K-fold 4 : 0.6942084714770317\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928043484687805\n",
      "K-fold 1 : 0.6927579045295715\n",
      "K-fold 2 : 0.6928772707780202\n",
      "K-fold 3 : 0.6918878098328908\n",
      "K-fold 4 : 0.6923018554846446\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6925258378187815\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-05_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.123697916666664\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 50.026041666666664\n",
      "K-fold 3 : 50.559895833333336\n",
      "K-fold 4 : 50.21484375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 47.682291666666664\n",
      "K-fold 1 : 50.130208333333336\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 50.989583333333336\n",
      "K-fold 4 : 51.432291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.91796875\n",
      "K-fold 1 : 51.236979166666664\n",
      "K-fold 2 : 51.38671875\n",
      "K-fold 3 : 51.236979166666664\n",
      "K-fold 4 : 51.2109375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.604166666666664\n",
      "K-fold 1 : 51.875\n",
      "K-fold 2 : 51.380208333333336\n",
      "K-fold 3 : 51.119791666666664\n",
      "K-fold 4 : 51.796875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.75520833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6949846511085828\n",
      "K-fold 1 : 0.6944487969080607\n",
      "K-fold 2 : 0.694087423880895\n",
      "K-fold 3 : 0.6950549612442652\n",
      "K-fold 4 : 0.6946812316775322\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6991397182146708\n",
      "K-fold 1 : 0.7049507002035776\n",
      "K-fold 2 : 0.693585354089737\n",
      "K-fold 3 : 0.6973372956116994\n",
      "K-fold 4 : 0.6927450080712636\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933951482176781\n",
      "K-fold 1 : 0.693477925658226\n",
      "K-fold 2 : 0.6934030766288439\n",
      "K-fold 3 : 0.6935364335775376\n",
      "K-fold 4 : 0.6934817964831989\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6919491032759348\n",
      "K-fold 1 : 0.6925982713699341\n",
      "K-fold 2 : 0.693098513285319\n",
      "K-fold 3 : 0.6928379654884338\n",
      "K-fold 4 : 0.6924743135770162\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6925916333993276\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.94140625\n",
      "K-fold 1 : 50.598958333333336\n",
      "K-fold 2 : 50.95703125\n",
      "K-fold 3 : 50.4296875\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 49.713541666666664\n",
      "K-fold 2 : 50.364583333333336\n",
      "K-fold 3 : 50.572916666666664\n",
      "K-fold 4 : 48.567708333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.11328125\n",
      "K-fold 1 : 51.354166666666664\n",
      "K-fold 2 : 51.184895833333336\n",
      "K-fold 3 : 51.204427083333336\n",
      "K-fold 4 : 51.15234375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.458333333333336\n",
      "K-fold 1 : 51.927083333333336\n",
      "K-fold 2 : 50.9375\n",
      "K-fold 3 : 51.328125\n",
      "K-fold 4 : 52.890625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.708333333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6950550655523936\n",
      "K-fold 1 : 0.6938302670915921\n",
      "K-fold 2 : 0.6936533004045486\n",
      "K-fold 3 : 0.6941825985908509\n",
      "K-fold 4 : 0.6941705634196599\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693459153175354\n",
      "K-fold 1 : 0.6939164996147156\n",
      "K-fold 2 : 0.6931704521179199\n",
      "K-fold 3 : 0.6930687606334687\n",
      "K-fold 4 : 0.6936073998610178\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929715861876805\n",
      "K-fold 1 : 0.6930836667617162\n",
      "K-fold 2 : 0.6929999326666196\n",
      "K-fold 3 : 0.6930216923356056\n",
      "K-fold 4 : 0.693341375887394\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929370363553365\n",
      "K-fold 1 : 0.6927933653195699\n",
      "K-fold 2 : 0.6930052161216735\n",
      "K-fold 3 : 0.6927831113338471\n",
      "K-fold 4 : 0.6923615097999573\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927760477860769\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.872395833333336\n",
      "K-fold 1 : 50.0\n",
      "K-fold 2 : 50.227864583333336\n",
      "K-fold 3 : 51.11328125\n",
      "K-fold 4 : 50.611979166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.192708333333336\n",
      "K-fold 1 : 51.484375\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 49.895833333333336\n",
      "K-fold 4 : 51.432291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.2890625\n",
      "K-fold 1 : 50.8203125\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 51.42578125\n",
      "K-fold 4 : 51.041666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.807291666666664\n",
      "K-fold 1 : 51.484375\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 51.432291666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.979166666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932030315200488\n",
      "K-fold 1 : 0.6933700328071912\n",
      "K-fold 2 : 0.693474834660689\n",
      "K-fold 3 : 0.6932685022552808\n",
      "K-fold 4 : 0.6933064113060633\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931970477104187\n",
      "K-fold 1 : 0.6930584847927094\n",
      "K-fold 2 : 0.6929393529891967\n",
      "K-fold 3 : 0.6932193915049235\n",
      "K-fold 4 : 0.6928064982096355\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930116727948189\n",
      "K-fold 1 : 0.6929888611038526\n",
      "K-fold 2 : 0.6929979513088862\n",
      "K-fold 3 : 0.6929468994339307\n",
      "K-fold 4 : 0.6930139611164728\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930175244808197\n",
      "K-fold 1 : 0.6927064637343089\n",
      "K-fold 2 : 0.6929298202196758\n",
      "K-fold 3 : 0.693145485719045\n",
      "K-fold 4 : 0.692707230647405\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929013049602508\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.729166666666664\n",
      "K-fold 1 : 50.657552083333336\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.950520833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.15625\n",
      "K-fold 1 : 51.067708333333336\n",
      "K-fold 2 : 49.21875\n",
      "K-fold 3 : 52.03125\n",
      "K-fold 4 : 48.411458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.178385416666664\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.295572916666664\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 51.419270833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.703125\n",
      "K-fold 1 : 51.666666666666664\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 52.526041666666664\n",
      "K-fold 4 : 52.083333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.59895833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6944159458080927\n",
      "K-fold 1 : 0.6940060794353485\n",
      "K-fold 2 : 0.6940192023913065\n",
      "K-fold 3 : 0.6950827146569888\n",
      "K-fold 4 : 0.6943996459245682\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938338498274486\n",
      "K-fold 1 : 0.7022221287091573\n",
      "K-fold 2 : 0.6939054747422536\n",
      "K-fold 3 : 0.692909707625707\n",
      "K-fold 4 : 0.6951338450113932\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933091054360072\n",
      "K-fold 1 : 0.693298743168513\n",
      "K-fold 2 : 0.6932976737618446\n",
      "K-fold 3 : 0.6933363864819209\n",
      "K-fold 4 : 0.6931670357783636\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930426061153412\n",
      "K-fold 1 : 0.6927526692549387\n",
      "K-fold 2 : 0.6928966184457143\n",
      "K-fold 3 : 0.6922154247760772\n",
      "K-fold 4 : 0.6923488358656565\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926512308915456\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.970052083333336\n",
      "K-fold 1 : 50.143229166666664\n",
      "K-fold 2 : 50.260416666666664\n",
      "K-fold 3 : 50.17578125\n",
      "K-fold 4 : 50.01953125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.572916666666664\n",
      "K-fold 1 : 48.645833333333336\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 51.458333333333336\n",
      "K-fold 4 : 49.427083333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.360677083333336\n",
      "K-fold 1 : 51.061197916666664\n",
      "K-fold 2 : 51.2890625\n",
      "K-fold 3 : 51.022135416666664\n",
      "K-fold 4 : 51.204427083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.572916666666664\n",
      "K-fold 1 : 51.354166666666664\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 51.458333333333336\n",
      "K-fold 4 : 50.572916666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931686868270238\n",
      "K-fold 1 : 0.6939308275779088\n",
      "K-fold 2 : 0.6933334882060687\n",
      "K-fold 3 : 0.693537500500679\n",
      "K-fold 4 : 0.6936809291442235\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938378791014354\n",
      "K-fold 1 : 0.6933995028336842\n",
      "K-fold 2 : 0.6934194743633271\n",
      "K-fold 3 : 0.6927752594153086\n",
      "K-fold 4 : 0.6942433436711629\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930020357171695\n",
      "K-fold 1 : 0.693128289282322\n",
      "K-fold 2 : 0.6929611191153526\n",
      "K-fold 3 : 0.6930980260173479\n",
      "K-fold 4 : 0.6929987847805024\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693081396818161\n",
      "K-fold 1 : 0.6927804132302602\n",
      "K-fold 2 : 0.6929810424645741\n",
      "K-fold 3 : 0.6927217880884806\n",
      "K-fold 4 : 0.6929883380730947\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692910595734914\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 50.533854166666664\n",
      "K-fold 2 : 50.748697916666664\n",
      "K-fold 3 : 50.436197916666664\n",
      "K-fold 4 : 50.078125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 52.421875\n",
      "K-fold 1 : 49.166666666666664\n",
      "K-fold 2 : 49.453125\n",
      "K-fold 3 : 47.942708333333336\n",
      "K-fold 4 : 48.515625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 51.9140625\n",
      "K-fold 2 : 51.399739583333336\n",
      "K-fold 3 : 50.944010416666664\n",
      "K-fold 4 : 51.302083333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.760416666666664\n",
      "K-fold 1 : 52.213541666666664\n",
      "K-fold 2 : 51.171875\n",
      "K-fold 3 : 52.317708333333336\n",
      "K-fold 4 : 52.473958333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.1875\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939589301745097\n",
      "K-fold 1 : 0.6942202508449554\n",
      "K-fold 2 : 0.6932164981961251\n",
      "K-fold 3 : 0.6959829385081927\n",
      "K-fold 4 : 0.6955735107262929\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6924866835276285\n",
      "K-fold 1 : 0.6942529280980428\n",
      "K-fold 2 : 0.6938937505086263\n",
      "K-fold 3 : 0.6938924670219422\n",
      "K-fold 4 : 0.6934081713358561\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932465513547261\n",
      "K-fold 1 : 0.6933107053240141\n",
      "K-fold 2 : 0.6932164981961251\n",
      "K-fold 3 : 0.6934827004869779\n",
      "K-fold 4 : 0.6932384719451269\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6911594331264496\n",
      "K-fold 1 : 0.6924538572629293\n",
      "K-fold 2 : 0.693019280831019\n",
      "K-fold 3 : 0.6924565394719442\n",
      "K-fold 4 : 0.6920099298159281\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692219808101654\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.833333333333336\n",
      "K-fold 1 : 51.19140625\n",
      "K-fold 2 : 50.540364583333336\n",
      "K-fold 3 : 50.514322916666664\n",
      "K-fold 4 : 50.397135416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.713541666666664\n",
      "K-fold 1 : 52.34375\n",
      "K-fold 2 : 50.15625\n",
      "K-fold 3 : 51.71875\n",
      "K-fold 4 : 49.0625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.484375\n",
      "K-fold 1 : 51.19140625\n",
      "K-fold 2 : 51.30859375\n",
      "K-fold 3 : 50.95703125\n",
      "K-fold 4 : 51.321614583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.286458333333336\n",
      "K-fold 1 : 52.708333333333336\n",
      "K-fold 2 : 50.15625\n",
      "K-fold 3 : 51.71875\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.161458333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933078075448672\n",
      "K-fold 1 : 0.6932678495844206\n",
      "K-fold 2 : 0.6932303393880527\n",
      "K-fold 3 : 0.6933457841475804\n",
      "K-fold 4 : 0.693308554093043\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6942234754562377\n",
      "K-fold 1 : 0.6925137182076772\n",
      "K-fold 2 : 0.6932295779387156\n",
      "K-fold 3 : 0.6929890910784403\n",
      "K-fold 4 : 0.6931586106618245\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928878506024678\n",
      "K-fold 1 : 0.6932137385010719\n",
      "K-fold 2 : 0.6930254394809405\n",
      "K-fold 3 : 0.693156682451566\n",
      "K-fold 4 : 0.6930686498681704\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931312302748363\n",
      "K-fold 1 : 0.692048293352127\n",
      "K-fold 2 : 0.6931402047475179\n",
      "K-fold 3 : 0.6925563712914785\n",
      "K-fold 4 : 0.6928949395815531\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927542078495026\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.17578125\n",
      "K-fold 1 : 50.345052083333336\n",
      "K-fold 2 : 51.295572916666664\n",
      "K-fold 3 : 50.729166666666664\n",
      "K-fold 4 : 50.364583333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.880208333333336\n",
      "K-fold 1 : 50.729166666666664\n",
      "K-fold 2 : 48.958333333333336\n",
      "K-fold 3 : 50.46875\n",
      "K-fold 4 : 52.109375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.354166666666664\n",
      "K-fold 1 : 51.048177083333336\n",
      "K-fold 2 : 51.373697916666664\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 51.19140625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.265625\n",
      "K-fold 1 : 52.291666666666664\n",
      "K-fold 2 : 52.057291666666664\n",
      "K-fold 3 : 52.8125\n",
      "K-fold 4 : 52.239583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.33333333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.695327351987362\n",
      "K-fold 1 : 0.6972957129279772\n",
      "K-fold 2 : 0.6938727964957555\n",
      "K-fold 3 : 0.6939166426658631\n",
      "K-fold 4 : 0.6953474665681522\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6963635444641113\n",
      "K-fold 1 : 0.6938747107982636\n",
      "K-fold 2 : 0.704975293080012\n",
      "K-fold 3 : 0.6936625321706136\n",
      "K-fold 4 : 0.694079335530599\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6939735700686772\n",
      "K-fold 1 : 0.6936588620146116\n",
      "K-fold 2 : 0.6934609457850456\n",
      "K-fold 3 : 0.6939121057589849\n",
      "K-fold 4 : 0.693821441133817\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928633232911428\n",
      "K-fold 1 : 0.6924679358800252\n",
      "K-fold 2 : 0.692789367834727\n",
      "K-fold 3 : 0.6925057748953501\n",
      "K-fold 4 : 0.6923890888690949\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926030981540681\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-05_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.9609375\n",
      "K-fold 1 : 50.83984375\n",
      "K-fold 2 : 50.52734375\n",
      "K-fold 3 : 50.15625\n",
      "K-fold 4 : 51.0546875\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.640625\n",
      "K-fold 1 : 50.46875\n",
      "K-fold 2 : 47.1875\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 50.182291666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 51.295572916666664\n",
      "K-fold 2 : 51.03515625\n",
      "K-fold 3 : 51.471354166666664\n",
      "K-fold 4 : 51.360677083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.640625\n",
      "K-fold 1 : 50.46875\n",
      "K-fold 2 : 52.8125\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.1875\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933911631504694\n",
      "K-fold 1 : 0.693152949710687\n",
      "K-fold 2 : 0.6934263070424398\n",
      "K-fold 3 : 0.6937433362007142\n",
      "K-fold 4 : 0.6931322187185287\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929926991462707\n",
      "K-fold 1 : 0.693120143810908\n",
      "K-fold 2 : 0.6936531364917755\n",
      "K-fold 3 : 0.6932756185531617\n",
      "K-fold 4 : 0.6941520790259044\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929303109645844\n",
      "K-fold 1 : 0.6929788122574488\n",
      "K-fold 2 : 0.6931018074353535\n",
      "K-fold 3 : 0.6929371222853661\n",
      "K-fold 4 : 0.6929040019710858\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6925438781579335\n",
      "K-fold 1 : 0.693120143810908\n",
      "K-fold 2 : 0.6915645043055216\n",
      "K-fold 3 : 0.693009748061498\n",
      "K-fold 4 : 0.6931369344393412\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926750417550405\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.9609375\n",
      "K-fold 1 : 50.338541666666664\n",
      "K-fold 2 : 49.772135416666664\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.1953125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 47.578125\n",
      "K-fold 1 : 49.401041666666664\n",
      "K-fold 2 : 51.796875\n",
      "K-fold 3 : 49.765625\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.95703125\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.302083333333336\n",
      "K-fold 3 : 51.458333333333336\n",
      "K-fold 4 : 51.399739583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.421875\n",
      "K-fold 1 : 50.598958333333336\n",
      "K-fold 2 : 51.796875\n",
      "K-fold 3 : 50.234375\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.067708333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935628458857537\n",
      "K-fold 1 : 0.6931591555476189\n",
      "K-fold 2 : 0.6938127994537353\n",
      "K-fold 3 : 0.6932457079490025\n",
      "K-fold 4 : 0.6931767125924428\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6940388003985087\n",
      "K-fold 1 : 0.6932652215162913\n",
      "K-fold 2 : 0.6927148362000783\n",
      "K-fold 3 : 0.6954139014085133\n",
      "K-fold 4 : 0.6937367796897889\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931380093097687\n",
      "K-fold 1 : 0.6929171005884807\n",
      "K-fold 2 : 0.6929519678155581\n",
      "K-fold 3 : 0.692743199567\n",
      "K-fold 4 : 0.6928925504287083\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6919721325238546\n",
      "K-fold 1 : 0.6930660923322042\n",
      "K-fold 2 : 0.6924951871236166\n",
      "K-fold 3 : 0.6931364814440409\n",
      "K-fold 4 : 0.6931174496809641\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927574686209361\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.436197916666664\n",
      "K-fold 1 : 50.384114583333336\n",
      "K-fold 2 : 50.09765625\n",
      "K-fold 3 : 50.5859375\n",
      "K-fold 4 : 50.123697916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 50.052083333333336\n",
      "K-fold 2 : 48.958333333333336\n",
      "K-fold 3 : 51.588541666666664\n",
      "K-fold 4 : 51.822916666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.334635416666664\n",
      "K-fold 1 : 51.295572916666664\n",
      "K-fold 2 : 51.165364583333336\n",
      "K-fold 3 : 51.184895833333336\n",
      "K-fold 4 : 50.95703125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 50.052083333333336\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.588541666666664\n",
      "K-fold 4 : 51.822916666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.994791666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932738080620766\n",
      "K-fold 1 : 0.6932294090588887\n",
      "K-fold 2 : 0.6931411862373352\n",
      "K-fold 3 : 0.6933353404204051\n",
      "K-fold 4 : 0.6933291256427765\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931418597698211\n",
      "K-fold 1 : 0.6932091375192007\n",
      "K-fold 2 : 0.6933362503846486\n",
      "K-fold 3 : 0.6926994403203328\n",
      "K-fold 4 : 0.692813124259313\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929210300246874\n",
      "K-fold 1 : 0.6929300010204316\n",
      "K-fold 2 : 0.692936368783315\n",
      "K-fold 3 : 0.6930205384890239\n",
      "K-fold 4 : 0.6930712292591731\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931032439072927\n",
      "K-fold 1 : 0.6931466559569041\n",
      "K-fold 2 : 0.6929310778776805\n",
      "K-fold 3 : 0.6926428993542989\n",
      "K-fold 4 : 0.692482574780782\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928612903753917\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.7421875\n",
      "K-fold 1 : 50.625\n",
      "K-fold 2 : 50.123697916666664\n",
      "K-fold 3 : 50.631510416666664\n",
      "K-fold 4 : 50.260416666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.197916666666664\n",
      "K-fold 1 : 50.989583333333336\n",
      "K-fold 2 : 51.40625\n",
      "K-fold 3 : 49.583333333333336\n",
      "K-fold 4 : 50.390625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.23046875\n",
      "K-fold 1 : 51.09375\n",
      "K-fold 2 : 50.95703125\n",
      "K-fold 3 : 51.243489583333336\n",
      "K-fold 4 : 51.790364583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.692708333333336\n",
      "K-fold 1 : 50.989583333333336\n",
      "K-fold 2 : 51.40625\n",
      "K-fold 3 : 50.885416666666664\n",
      "K-fold 4 : 50.390625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.07291666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932214026649793\n",
      "K-fold 1 : 0.69343434770902\n",
      "K-fold 2 : 0.6933690438667933\n",
      "K-fold 3 : 0.6932962929209073\n",
      "K-fold 4 : 0.6934473971525829\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933963318665822\n",
      "K-fold 1 : 0.6931188066800436\n",
      "K-fold 2 : 0.6927535613377889\n",
      "K-fold 3 : 0.6931801001230876\n",
      "K-fold 4 : 0.6931153118610383\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929399395982424\n",
      "K-fold 1 : 0.6929924796024959\n",
      "K-fold 2 : 0.692813225587209\n",
      "K-fold 3 : 0.6929434542854627\n",
      "K-fold 4 : 0.692758836845557\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928308924039205\n",
      "K-fold 1 : 0.6929311414559682\n",
      "K-fold 2 : 0.6927488187948863\n",
      "K-fold 3 : 0.6929599285125733\n",
      "K-fold 4 : 0.6930940330028534\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929129628340404\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.09765625\n",
      "K-fold 1 : 50.110677083333336\n",
      "K-fold 2 : 50.423177083333336\n",
      "K-fold 3 : 50.846354166666664\n",
      "K-fold 4 : 49.993489583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.90625\n",
      "K-fold 1 : 48.28125\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 49.973958333333336\n",
      "K-fold 4 : 48.125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.334635416666664\n",
      "K-fold 1 : 50.91796875\n",
      "K-fold 2 : 51.451822916666664\n",
      "K-fold 3 : 51.236979166666664\n",
      "K-fold 4 : 50.930989583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.09375\n",
      "K-fold 1 : 51.71875\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 50.026041666666664\n",
      "K-fold 4 : 51.875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.984375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6931833565235138\n",
      "K-fold 1 : 0.6933303654193879\n",
      "K-fold 2 : 0.693310319383939\n",
      "K-fold 3 : 0.6937790458401044\n",
      "K-fold 4 : 0.693737847606341\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932243605454763\n",
      "K-fold 1 : 0.6950479368368785\n",
      "K-fold 2 : 0.6931667526563009\n",
      "K-fold 3 : 0.694117150704066\n",
      "K-fold 4 : 0.6933517714341482\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929477696617444\n",
      "K-fold 1 : 0.6930188313126564\n",
      "K-fold 2 : 0.6928739632169406\n",
      "K-fold 3 : 0.6928811172644297\n",
      "K-fold 4 : 0.693136473496755\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692907989025116\n",
      "K-fold 1 : 0.6925563553969065\n",
      "K-fold 2 : 0.6931389033794403\n",
      "K-fold 3 : 0.693147087097168\n",
      "K-fold 4 : 0.6924439271291097\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928388524055481\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.026041666666664\n",
      "K-fold 1 : 49.84375\n",
      "K-fold 2 : 50.05859375\n",
      "K-fold 3 : 50.91796875\n",
      "K-fold 4 : 50.559895833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.411458333333336\n",
      "K-fold 1 : 48.411458333333336\n",
      "K-fold 2 : 50.598958333333336\n",
      "K-fold 3 : 49.296875\n",
      "K-fold 4 : 50.390625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.490885416666664\n",
      "K-fold 1 : 50.859375\n",
      "K-fold 2 : 51.263020833333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 51.11328125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.744791666666664\n",
      "K-fold 1 : 51.692708333333336\n",
      "K-fold 2 : 52.239583333333336\n",
      "K-fold 3 : 51.640625\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.66666666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934977451960246\n",
      "K-fold 1 : 0.6939577008287112\n",
      "K-fold 2 : 0.6935855135321617\n",
      "K-fold 3 : 0.6934130142132441\n",
      "K-fold 4 : 0.6932978481054306\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933494011561075\n",
      "K-fold 1 : 0.6947986006736755\n",
      "K-fold 2 : 0.6932707746823629\n",
      "K-fold 3 : 0.6936957001686096\n",
      "K-fold 4 : 0.6931504507859548\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6928421556949615\n",
      "K-fold 1 : 0.692956734697024\n",
      "K-fold 2 : 0.6928462197383245\n",
      "K-fold 3 : 0.6930019547541936\n",
      "K-fold 4 : 0.6929801056782404\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6925738612810771\n",
      "K-fold 1 : 0.6926417609055837\n",
      "K-fold 2 : 0.6930262684822083\n",
      "K-fold 3 : 0.6929399232069652\n",
      "K-fold 4 : 0.6930857221285502\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928535072008769\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.384114583333336\n",
      "K-fold 1 : 50.930989583333336\n",
      "K-fold 2 : 50.397135416666664\n",
      "K-fold 3 : 49.733072916666664\n",
      "K-fold 4 : 49.830729166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.0625\n",
      "K-fold 1 : 50.208333333333336\n",
      "K-fold 2 : 50.885416666666664\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 51.484375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.477864583333336\n",
      "K-fold 1 : 51.490885416666664\n",
      "K-fold 2 : 51.048177083333336\n",
      "K-fold 3 : 51.321614583333336\n",
      "K-fold 4 : 51.106770833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 50.208333333333336\n",
      "K-fold 2 : 50.885416666666664\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 51.484375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932523985703786\n",
      "K-fold 1 : 0.6929402882854144\n",
      "K-fold 2 : 0.6934232329328854\n",
      "K-fold 3 : 0.693476461370786\n",
      "K-fold 4 : 0.6936029175917308\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938356757164001\n",
      "K-fold 1 : 0.693140834569931\n",
      "K-fold 2 : 0.6930577099323273\n",
      "K-fold 3 : 0.6929719050725301\n",
      "K-fold 4 : 0.6927206655343373\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929365073641142\n",
      "K-fold 1 : 0.6928641731540363\n",
      "K-fold 2 : 0.6930412039160728\n",
      "K-fold 3 : 0.6930452262361845\n",
      "K-fold 4 : 0.692955814798673\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929714361826579\n",
      "K-fold 1 : 0.6931386590003967\n",
      "K-fold 2 : 0.6929910222689311\n",
      "K-fold 3 : 0.6927804768085479\n",
      "K-fold 4 : 0.6927066922187806\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929176572958629\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.670572916666664\n",
      "K-fold 1 : 50.72265625\n",
      "K-fold 2 : 50.553385416666664\n",
      "K-fold 3 : 50.364583333333336\n",
      "K-fold 4 : 49.9609375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.807291666666664\n",
      "K-fold 1 : 50.234375\n",
      "K-fold 2 : 51.796875\n",
      "K-fold 3 : 50.807291666666664\n",
      "K-fold 4 : 51.09375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.19140625\n",
      "K-fold 1 : 51.334635416666664\n",
      "K-fold 2 : 50.9375\n",
      "K-fold 3 : 51.028645833333336\n",
      "K-fold 4 : 51.321614583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.807291666666664\n",
      "K-fold 1 : 50.755208333333336\n",
      "K-fold 2 : 52.161458333333336\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 51.09375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.19791666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693159656226635\n",
      "K-fold 1 : 0.6934287056326867\n",
      "K-fold 2 : 0.6932651822765669\n",
      "K-fold 3 : 0.693629356722037\n",
      "K-fold 4 : 0.6939719085892041\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931451598803202\n",
      "K-fold 1 : 0.6930838227272034\n",
      "K-fold 2 : 0.6924990673859914\n",
      "K-fold 3 : 0.6931218524773916\n",
      "K-fold 4 : 0.6935881237188976\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930107946197192\n",
      "K-fold 1 : 0.6928829739491145\n",
      "K-fold 2 : 0.6930284549792608\n",
      "K-fold 3 : 0.6929465889930725\n",
      "K-fold 4 : 0.6930254484216373\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929117063681285\n",
      "K-fold 1 : 0.6930788318316142\n",
      "K-fold 2 : 0.692369653781255\n",
      "K-fold 3 : 0.692911567290624\n",
      "K-fold 4 : 0.6928444226582845\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928232363859812\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-05_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 50.716145833333336\n",
      "K-fold 2 : 50.403645833333336\n",
      "K-fold 3 : 50.123697916666664\n",
      "K-fold 4 : 49.680989583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 49.661458333333336\n",
      "K-fold 2 : 48.515625\n",
      "K-fold 3 : 48.958333333333336\n",
      "K-fold 4 : 51.5625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.080729166666664\n",
      "K-fold 1 : 51.471354166666664\n",
      "K-fold 2 : 51.184895833333336\n",
      "K-fold 3 : 51.100260416666664\n",
      "K-fold 4 : 51.399739583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 50.338541666666664\n",
      "K-fold 2 : 51.484375\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 51.5625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.10937499999999\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6934867804249127\n",
      "K-fold 1 : 0.693194198111693\n",
      "K-fold 2 : 0.693267851571242\n",
      "K-fold 3 : 0.6935248906413715\n",
      "K-fold 4 : 0.6936337952812512\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929319421450297\n",
      "K-fold 1 : 0.6943070193131765\n",
      "K-fold 2 : 0.6934087832768758\n",
      "K-fold 3 : 0.6934572160243988\n",
      "K-fold 4 : 0.6927420636018117\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930311610301335\n",
      "K-fold 1 : 0.6927837952971458\n",
      "K-fold 2 : 0.6929505864779154\n",
      "K-fold 3 : 0.6930657332142194\n",
      "K-fold 4 : 0.6929169033964475\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928963939348857\n",
      "K-fold 1 : 0.6931242763996124\n",
      "K-fold 2 : 0.6927065511544546\n",
      "K-fold 3 : 0.6929301579793294\n",
      "K-fold 4 : 0.6926588733990987\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928632505734761\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.013020833333336\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 50.221354166666664\n",
      "K-fold 3 : 49.791666666666664\n",
      "K-fold 4 : 50.618489583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.401041666666664\n",
      "K-fold 1 : 51.848958333333336\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 50.364583333333336\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.145833333333336\n",
      "K-fold 1 : 51.34765625\n",
      "K-fold 2 : 51.080729166666664\n",
      "K-fold 3 : 51.4453125\n",
      "K-fold 4 : 51.15234375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.598958333333336\n",
      "K-fold 1 : 51.875\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 50.546875\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.05729166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6940497140089671\n",
      "K-fold 1 : 0.6939502110083898\n",
      "K-fold 2 : 0.6935427218675614\n",
      "K-fold 3 : 0.6949619288245837\n",
      "K-fold 4 : 0.6944478293259938\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6933108290036519\n",
      "K-fold 1 : 0.6927800873915354\n",
      "K-fold 2 : 0.6954972783724467\n",
      "K-fold 3 : 0.6938191572825114\n",
      "K-fold 4 : 0.6929840246836344\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932320669293404\n",
      "K-fold 1 : 0.6934848924477895\n",
      "K-fold 2 : 0.6932462687293689\n",
      "K-fold 3 : 0.6931271036465962\n",
      "K-fold 4 : 0.6930892457564671\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930754323800404\n",
      "K-fold 1 : 0.6924633344014486\n",
      "K-fold 2 : 0.6928954700628916\n",
      "K-fold 3 : 0.6931206107139587\n",
      "K-fold 4 : 0.692902398109436\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692891449133555\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.876302083333336\n",
      "K-fold 1 : 50.006510416666664\n",
      "K-fold 2 : 50.364583333333336\n",
      "K-fold 3 : 50.4296875\n",
      "K-fold 4 : 49.82421875\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.588541666666664\n",
      "K-fold 2 : 49.088541666666664\n",
      "K-fold 3 : 49.244791666666664\n",
      "K-fold 4 : 47.8125\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.243489583333336\n",
      "K-fold 1 : 51.223958333333336\n",
      "K-fold 2 : 51.184895833333336\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 51.022135416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 51.588541666666664\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.755208333333336\n",
      "K-fold 4 : 52.1875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.27604166666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6947102362910906\n",
      "K-fold 1 : 0.693864868581295\n",
      "K-fold 2 : 0.69533246109883\n",
      "K-fold 3 : 0.6953157285849253\n",
      "K-fold 4 : 0.6942986095945041\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930351555347443\n",
      "K-fold 1 : 0.695649246374766\n",
      "K-fold 2 : 0.6955078562100728\n",
      "K-fold 3 : 0.6990592181682587\n",
      "K-fold 4 : 0.6948511242866516\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930823937058449\n",
      "K-fold 1 : 0.6932428389787674\n",
      "K-fold 2 : 0.693179372449716\n",
      "K-fold 3 : 0.6930888523658116\n",
      "K-fold 4 : 0.6933960258960724\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929714302221934\n",
      "K-fold 1 : 0.6926424324512481\n",
      "K-fold 2 : 0.6929813722769419\n",
      "K-fold 3 : 0.6930332660675049\n",
      "K-fold 4 : 0.6921899239222209\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927636849880219\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.837239583333336\n",
      "K-fold 1 : 50.99609375\n",
      "K-fold 2 : 49.74609375\n",
      "K-fold 3 : 50.7421875\n",
      "K-fold 4 : 51.4453125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.739583333333336\n",
      "K-fold 1 : 49.84375\n",
      "K-fold 2 : 49.114583333333336\n",
      "K-fold 3 : 52.604166666666664\n",
      "K-fold 4 : 49.114583333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.497395833333336\n",
      "K-fold 1 : 51.490885416666664\n",
      "K-fold 2 : 51.25\n",
      "K-fold 3 : 51.009114583333336\n",
      "K-fold 4 : 51.4453125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.380208333333336\n",
      "K-fold 1 : 51.432291666666664\n",
      "K-fold 2 : 51.458333333333336\n",
      "K-fold 3 : 52.604166666666664\n",
      "K-fold 4 : 52.135416666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.802083333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6948292111357053\n",
      "K-fold 1 : 0.6937990407148997\n",
      "K-fold 2 : 0.6939254467686017\n",
      "K-fold 3 : 0.6942044367392858\n",
      "K-fold 4 : 0.6936951796213786\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934648593266804\n",
      "K-fold 1 : 0.693940148750941\n",
      "K-fold 2 : 0.693996932109197\n",
      "K-fold 3 : 0.6923479457696279\n",
      "K-fold 4 : 0.6933961888154347\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931185613075892\n",
      "K-fold 1 : 0.6932333831985792\n",
      "K-fold 2 : 0.6929179559151332\n",
      "K-fold 3 : 0.6932680169741313\n",
      "K-fold 4 : 0.6933208242058754\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930416285991668\n",
      "K-fold 1 : 0.6915643016497294\n",
      "K-fold 2 : 0.6906474947929382\n",
      "K-fold 3 : 0.6918460090955099\n",
      "K-fold 4 : 0.692661996682485\n",
      "---------------------------------\n",
      "Average best validation loss: 0.691952286163966\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.46875\n",
      "K-fold 1 : 50.169270833333336\n",
      "K-fold 2 : 50.3515625\n",
      "K-fold 3 : 50.201822916666664\n",
      "K-fold 4 : 50.338541666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.09375\n",
      "K-fold 1 : 49.036458333333336\n",
      "K-fold 2 : 51.302083333333336\n",
      "K-fold 3 : 49.635416666666664\n",
      "K-fold 4 : 48.854166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.944010416666664\n",
      "K-fold 1 : 51.0546875\n",
      "K-fold 2 : 51.061197916666664\n",
      "K-fold 3 : 51.184895833333336\n",
      "K-fold 4 : 51.178385416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.119791666666664\n",
      "K-fold 1 : 50.963541666666664\n",
      "K-fold 2 : 51.302083333333336\n",
      "K-fold 3 : 50.494791666666664\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.00520833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693849932650725\n",
      "K-fold 1 : 0.6975355342030525\n",
      "K-fold 2 : 0.6973449359337489\n",
      "K-fold 3 : 0.7251293048262596\n",
      "K-fold 4 : 0.6941621551911036\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6935998439788819\n",
      "K-fold 1 : 0.6945133010546366\n",
      "K-fold 2 : 0.692914605140686\n",
      "K-fold 3 : 0.6945179104804993\n",
      "K-fold 4 : 0.6959969023863475\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931458522876104\n",
      "K-fold 1 : 0.6932435870170593\n",
      "K-fold 2 : 0.6930904512604078\n",
      "K-fold 3 : 0.6931886101762453\n",
      "K-fold 4 : 0.6933051784833272\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929081281026205\n",
      "K-fold 1 : 0.6929614782333374\n",
      "K-fold 2 : 0.6928080519040426\n",
      "K-fold 3 : 0.6931208471457163\n",
      "K-fold 4 : 0.6928849498430888\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929366910457612\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.05859375\n",
      "K-fold 1 : 49.973958333333336\n",
      "K-fold 2 : 50.1953125\n",
      "K-fold 3 : 51.080729166666664\n",
      "K-fold 4 : 50.390625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.536458333333336\n",
      "K-fold 1 : 51.875\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 48.671875\n",
      "K-fold 4 : 50.130208333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.158854166666664\n",
      "K-fold 1 : 51.302083333333336\n",
      "K-fold 2 : 51.555989583333336\n",
      "K-fold 3 : 51.256510416666664\n",
      "K-fold 4 : 51.315104166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.057291666666664\n",
      "K-fold 1 : 52.526041666666664\n",
      "K-fold 2 : 50.729166666666664\n",
      "K-fold 3 : 51.432291666666664\n",
      "K-fold 4 : 50.364583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.421875\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6955161586403846\n",
      "K-fold 1 : 0.695006304482619\n",
      "K-fold 2 : 0.6941900844375293\n",
      "K-fold 3 : 0.6945663705468178\n",
      "K-fold 4 : 0.7004033337036769\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927004079023997\n",
      "K-fold 1 : 0.6943020383516948\n",
      "K-fold 2 : 0.6933625976244608\n",
      "K-fold 3 : 0.696497372786204\n",
      "K-fold 4 : 0.6960868219534556\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931997711459795\n",
      "K-fold 1 : 0.6934174433350563\n",
      "K-fold 2 : 0.6932583664854367\n",
      "K-fold 3 : 0.6934054722388585\n",
      "K-fold 4 : 0.6934250409404437\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6923017541567484\n",
      "K-fold 1 : 0.6915902157624563\n",
      "K-fold 2 : 0.6929844816525778\n",
      "K-fold 3 : 0.6927206099033356\n",
      "K-fold 4 : 0.6930948833624522\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6925383889675141\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.338541666666664\n",
      "K-fold 1 : 50.475260416666664\n",
      "K-fold 2 : 50.09765625\n",
      "K-fold 3 : 50.794270833333336\n",
      "K-fold 4 : 50.696614583333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.651041666666664\n",
      "K-fold 1 : 51.458333333333336\n",
      "K-fold 2 : 51.927083333333336\n",
      "K-fold 3 : 50.104166666666664\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.341145833333336\n",
      "K-fold 1 : 51.0546875\n",
      "K-fold 2 : 50.872395833333336\n",
      "K-fold 3 : 51.373697916666664\n",
      "K-fold 4 : 51.217447916666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.651041666666664\n",
      "K-fold 1 : 51.458333333333336\n",
      "K-fold 2 : 52.109375\n",
      "K-fold 3 : 50.104166666666664\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.05208333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6986485923329989\n",
      "K-fold 1 : 0.6950624118248622\n",
      "K-fold 2 : 0.7006582652529081\n",
      "K-fold 3 : 0.7054463927944501\n",
      "K-fold 4 : 0.7096415817737579\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930631001790365\n",
      "K-fold 1 : 0.6927229384581248\n",
      "K-fold 2 : 0.6925619562466939\n",
      "K-fold 3 : 0.6932695786158244\n",
      "K-fold 4 : 0.6930672883987427\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931669265031815\n",
      "K-fold 1 : 0.6934296627839406\n",
      "K-fold 2 : 0.6934185793002446\n",
      "K-fold 3 : 0.6932417705655098\n",
      "K-fold 4 : 0.6933406998713811\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930626273155213\n",
      "K-fold 1 : 0.6927227000395457\n",
      "K-fold 2 : 0.6923250158627828\n",
      "K-fold 3 : 0.6931412378946941\n",
      "K-fold 4 : 0.6929713765780131\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928445915381114\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 51.061197916666664\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 49.876302083333336\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.690104166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 50.78125\n",
      "K-fold 2 : 50.3125\n",
      "K-fold 3 : 51.171875\n",
      "K-fold 4 : 51.119791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.087239583333336\n",
      "K-fold 1 : 51.23046875\n",
      "K-fold 2 : 51.334635416666664\n",
      "K-fold 3 : 51.432291666666664\n",
      "K-fold 4 : 51.42578125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.083333333333336\n",
      "K-fold 1 : 52.057291666666664\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 51.432291666666664\n",
      "K-fold 4 : 51.614583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.640625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6967330714066823\n",
      "K-fold 1 : 0.6966063375274341\n",
      "K-fold 2 : 0.6970656737685204\n",
      "K-fold 3 : 0.6948189939061801\n",
      "K-fold 4 : 0.6977959707379341\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6928366045157115\n",
      "K-fold 1 : 0.6930478433767955\n",
      "K-fold 2 : 0.69799076517423\n",
      "K-fold 3 : 0.6929119487603506\n",
      "K-fold 4 : 0.6928430954615276\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6935521716872851\n",
      "K-fold 1 : 0.6937065223852793\n",
      "K-fold 2 : 0.693131655951341\n",
      "K-fold 3 : 0.6936705579360326\n",
      "K-fold 4 : 0.6913378521800041\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927105963230134\n",
      "K-fold 1 : 0.692716646194458\n",
      "K-fold 2 : 0.6929284671942393\n",
      "K-fold 3 : 0.6927577912807464\n",
      "K-fold 4 : 0.6839528501033783\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6910132702191671\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-1_alpha_0-0001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.260416666666664\n",
      "K-fold 1 : 50.0390625\n",
      "K-fold 2 : 50.598958333333336\n",
      "K-fold 3 : 50.520833333333336\n",
      "K-fold 4 : 50.592447916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.895833333333336\n",
      "K-fold 1 : 49.53125\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.640625\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.165364583333336\n",
      "K-fold 1 : 51.393229166666664\n",
      "K-fold 2 : 51.015625\n",
      "K-fold 3 : 51.184895833333336\n",
      "K-fold 4 : 51.263020833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.135416666666664\n",
      "K-fold 1 : 50.885416666666664\n",
      "K-fold 2 : 53.854166666666664\n",
      "K-fold 3 : 51.848958333333336\n",
      "K-fold 4 : 50.911458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.927083333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6945338030656178\n",
      "K-fold 1 : 0.6987892051537832\n",
      "K-fold 2 : 0.6944425617655118\n",
      "K-fold 3 : 0.6939116602142652\n",
      "K-fold 4 : 0.7050278440117836\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6965304553508759\n",
      "K-fold 1 : 0.6940860986709595\n",
      "K-fold 2 : 0.6930506805578868\n",
      "K-fold 3 : 0.6926039695739746\n",
      "K-fold 4 : 0.6933603088061014\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6936885888377825\n",
      "K-fold 1 : 0.6931428571542104\n",
      "K-fold 2 : 0.6935438419381778\n",
      "K-fold 3 : 0.6935804814100266\n",
      "K-fold 4 : 0.6934392427404722\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692363957564036\n",
      "K-fold 1 : 0.6931023836135864\n",
      "K-fold 2 : 0.6925538698832194\n",
      "K-fold 3 : 0.6923748115698497\n",
      "K-fold 4 : 0.692976309855779\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926742664972941\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.442708333333336\n",
      "K-fold 1 : 49.947916666666664\n",
      "K-fold 2 : 50.462239583333336\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 49.850260416666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.432291666666664\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 48.671875\n",
      "K-fold 3 : 50.963541666666664\n",
      "K-fold 4 : 50.494791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.419270833333336\n",
      "K-fold 1 : 51.302083333333336\n",
      "K-fold 2 : 50.930989583333336\n",
      "K-fold 3 : 51.1328125\n",
      "K-fold 4 : 51.438802083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.03125\n",
      "K-fold 1 : 51.354166666666664\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 51.25\n",
      "K-fold 4 : 51.692708333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.59375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6966646159688632\n",
      "K-fold 1 : 0.6944563299417496\n",
      "K-fold 2 : 0.6941800067822138\n",
      "K-fold 3 : 0.6937736734747887\n",
      "K-fold 4 : 0.6940930863221486\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6972542603810629\n",
      "K-fold 1 : 0.6931009272734324\n",
      "K-fold 2 : 0.6933501521746318\n",
      "K-fold 3 : 0.6932524224122365\n",
      "K-fold 4 : 0.6933889289697012\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6935369705160459\n",
      "K-fold 1 : 0.6933233295877774\n",
      "K-fold 2 : 0.6934276630481084\n",
      "K-fold 3 : 0.6935810625553132\n",
      "K-fold 4 : 0.6935361052552859\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927078425884247\n",
      "K-fold 1 : 0.6928151110808055\n",
      "K-fold 2 : 0.6927392800649007\n",
      "K-fold 3 : 0.6929433564345042\n",
      "K-fold 4 : 0.6926926791667938\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927796538670858\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.338541666666664\n",
      "K-fold 1 : 50.533854166666664\n",
      "K-fold 2 : 50.455729166666664\n",
      "K-fold 3 : 50.625\n",
      "K-fold 4 : 50.690104166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.244791666666664\n",
      "K-fold 1 : 49.739583333333336\n",
      "K-fold 2 : 48.411458333333336\n",
      "K-fold 3 : 51.614583333333336\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.3671875\n",
      "K-fold 1 : 51.19140625\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.022135416666664\n",
      "K-fold 4 : 51.178385416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.755208333333336\n",
      "K-fold 1 : 51.041666666666664\n",
      "K-fold 2 : 51.614583333333336\n",
      "K-fold 3 : 51.953125\n",
      "K-fold 4 : 50.651041666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.203125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6936608562866847\n",
      "K-fold 1 : 0.6997396906216939\n",
      "K-fold 2 : 0.6961485559741656\n",
      "K-fold 3 : 0.6939967413743336\n",
      "K-fold 4 : 0.6948402548829714\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6938203374544779\n",
      "K-fold 1 : 0.6931488116582235\n",
      "K-fold 2 : 0.6949959337711334\n",
      "K-fold 3 : 0.6926336308320363\n",
      "K-fold 4 : 0.6931429922580719\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931166832645734\n",
      "K-fold 1 : 0.6932884062329928\n",
      "K-fold 2 : 0.693280790746212\n",
      "K-fold 3 : 0.6933521260817845\n",
      "K-fold 4 : 0.6932519420981407\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930287718772888\n",
      "K-fold 1 : 0.6927515784899394\n",
      "K-fold 2 : 0.6925662179787954\n",
      "K-fold 3 : 0.6925991078217825\n",
      "K-fold 4 : 0.6930624524752299\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928016257286072\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.48828125\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 50.755208333333336\n",
      "K-fold 3 : 50.29296875\n",
      "K-fold 4 : 49.7265625\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 49.921875\n",
      "K-fold 2 : 50.182291666666664\n",
      "K-fold 3 : 49.947916666666664\n",
      "K-fold 4 : 51.822916666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.048177083333336\n",
      "K-fold 1 : 51.204427083333336\n",
      "K-fold 2 : 51.516927083333336\n",
      "K-fold 3 : 51.022135416666664\n",
      "K-fold 4 : 51.165364583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.432291666666664\n",
      "K-fold 1 : 52.083333333333336\n",
      "K-fold 2 : 51.5625\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 52.213541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.8125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6948242848118146\n",
      "K-fold 1 : 0.6968365147709846\n",
      "K-fold 2 : 0.6941094656785329\n",
      "K-fold 3 : 0.6947414989272753\n",
      "K-fold 4 : 0.6980256309111913\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6942049145698548\n",
      "K-fold 1 : 0.6936462084452312\n",
      "K-fold 2 : 0.693163267771403\n",
      "K-fold 3 : 0.6940747618675231\n",
      "K-fold 4 : 0.7016932010650635\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6939506863554319\n",
      "K-fold 1 : 0.6937509914239247\n",
      "K-fold 2 : 0.6936696211496989\n",
      "K-fold 3 : 0.6938516994317373\n",
      "K-fold 4 : 0.6939327215154966\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927574078241984\n",
      "K-fold 1 : 0.6928667445977529\n",
      "K-fold 2 : 0.692828635374705\n",
      "K-fold 3 : 0.692716779311498\n",
      "K-fold 4 : 0.6922198394934337\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926778813203176\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.670572916666664\n",
      "K-fold 1 : 50.104166666666664\n",
      "K-fold 2 : 49.772135416666664\n",
      "K-fold 3 : 51.080729166666664\n",
      "K-fold 4 : 50.234375\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.869791666666664\n",
      "K-fold 1 : 47.864583333333336\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.614583333333336\n",
      "K-fold 4 : 50.208333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.809895833333336\n",
      "K-fold 1 : 51.048177083333336\n",
      "K-fold 2 : 51.58203125\n",
      "K-fold 3 : 51.11328125\n",
      "K-fold 4 : 51.048177083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 52.135416666666664\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 51.614583333333336\n",
      "K-fold 4 : 51.145833333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.328125\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6938452740510305\n",
      "K-fold 1 : 0.6940828705827395\n",
      "K-fold 2 : 0.6998165006438891\n",
      "K-fold 3 : 0.6936207806070646\n",
      "K-fold 4 : 0.6936362947026888\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6946944177150727\n",
      "K-fold 1 : 0.6936598281065623\n",
      "K-fold 2 : 0.6930923144022624\n",
      "K-fold 3 : 0.692840717236201\n",
      "K-fold 4 : 0.693598731358846\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930798987547556\n",
      "K-fold 1 : 0.693388265868028\n",
      "K-fold 2 : 0.6931136980652809\n",
      "K-fold 3 : 0.6933948511878649\n",
      "K-fold 4 : 0.6931845267613729\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931333899497986\n",
      "K-fold 1 : 0.6922117789586385\n",
      "K-fold 2 : 0.6928894857565562\n",
      "K-fold 3 : 0.6925552686055502\n",
      "K-fold 4 : 0.6929919918378195\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927563830216726\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.3515625\n",
      "K-fold 1 : 50.481770833333336\n",
      "K-fold 2 : 50.0\n",
      "K-fold 3 : 50.696614583333336\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.973958333333336\n",
      "K-fold 1 : 50.520833333333336\n",
      "K-fold 2 : 49.375\n",
      "K-fold 3 : 51.901041666666664\n",
      "K-fold 4 : 51.588541666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.158854166666664\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.25\n",
      "K-fold 3 : 50.911458333333336\n",
      "K-fold 4 : 51.11328125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.161458333333336\n",
      "K-fold 1 : 51.223958333333336\n",
      "K-fold 2 : 51.979166666666664\n",
      "K-fold 3 : 52.421875\n",
      "K-fold 4 : 51.848958333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.927083333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6955166205763816\n",
      "K-fold 1 : 0.6977930833896001\n",
      "K-fold 2 : 0.6974270274241765\n",
      "K-fold 3 : 0.6988045776883761\n",
      "K-fold 4 : 0.7001963118712108\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6972303271293641\n",
      "K-fold 1 : 0.6938963671525319\n",
      "K-fold 2 : 0.6948661565780639\n",
      "K-fold 3 : 0.6923796792825063\n",
      "K-fold 4 : 0.6930809338887532\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6946348567803701\n",
      "K-fold 1 : 0.694302898645401\n",
      "K-fold 2 : 0.6940704897046089\n",
      "K-fold 3 : 0.6947562739253044\n",
      "K-fold 4 : 0.6946069811781247\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6918163319428762\n",
      "K-fold 1 : 0.6929502010345459\n",
      "K-fold 2 : 0.692828236023585\n",
      "K-fold 3 : 0.691911780834198\n",
      "K-fold 4 : 0.6925240695476532\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6924061238765716\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.29296875\n",
      "K-fold 1 : 50.416666666666664\n",
      "K-fold 2 : 50.611979166666664\n",
      "K-fold 3 : 50.182291666666664\n",
      "K-fold 4 : 50.377604166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 49.21875\n",
      "K-fold 2 : 49.322916666666664\n",
      "K-fold 3 : 49.036458333333336\n",
      "K-fold 4 : 48.4375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.067708333333336\n",
      "K-fold 1 : 51.282552083333336\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 51.09375\n",
      "K-fold 4 : 51.223958333333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 51.09375\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 51.536458333333336\n",
      "K-fold 4 : 51.614583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.442708333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6942078063885371\n",
      "K-fold 1 : 0.6972502171993256\n",
      "K-fold 2 : 0.693873297671477\n",
      "K-fold 3 : 0.6956021542350451\n",
      "K-fold 4 : 0.6976447562376659\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6930356760819752\n",
      "K-fold 1 : 0.6969536383946736\n",
      "K-fold 2 : 0.693356865644455\n",
      "K-fold 3 : 0.6936219294865926\n",
      "K-fold 4 : 0.6934611479441325\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6933326408267021\n",
      "K-fold 1 : 0.6934327383836111\n",
      "K-fold 2 : 0.6934408764044444\n",
      "K-fold 3 : 0.6934298152724901\n",
      "K-fold 4 : 0.6934241687258085\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929462949434916\n",
      "K-fold 1 : 0.6928266882896423\n",
      "K-fold 2 : 0.6928745726744334\n",
      "K-fold 3 : 0.6927807112534841\n",
      "K-fold 4 : 0.6923699875672659\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927596509456635\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.329427083333336\n",
      "K-fold 1 : 50.247395833333336\n",
      "K-fold 2 : 49.84375\n",
      "K-fold 3 : 50.423177083333336\n",
      "K-fold 4 : 50.611979166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.859375\n",
      "K-fold 1 : 50.651041666666664\n",
      "K-fold 2 : 50.9375\n",
      "K-fold 3 : 52.239583333333336\n",
      "K-fold 4 : 49.947916666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.263020833333336\n",
      "K-fold 1 : 51.399739583333336\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.061197916666664\n",
      "K-fold 4 : 51.03515625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.484375\n",
      "K-fold 1 : 52.083333333333336\n",
      "K-fold 2 : 51.380208333333336\n",
      "K-fold 3 : 52.630208333333336\n",
      "K-fold 4 : 51.354166666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.786458333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.7029184579849244\n",
      "K-fold 1 : 0.7042896836996079\n",
      "K-fold 2 : 0.6967911223570505\n",
      "K-fold 3 : 0.699005647500356\n",
      "K-fold 4 : 0.7072836940487226\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931431531906128\n",
      "K-fold 1 : 0.6958986183007558\n",
      "K-fold 2 : 0.6929133216540019\n",
      "K-fold 3 : 0.6927840153376261\n",
      "K-fold 4 : 0.6930428147315979\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6957892060279847\n",
      "K-fold 1 : 0.6945995092391968\n",
      "K-fold 2 : 0.6949925323327383\n",
      "K-fold 3 : 0.6950229172905286\n",
      "K-fold 4 : 0.6954783961176872\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929008364677429\n",
      "K-fold 1 : 0.6919732491175333\n",
      "K-fold 2 : 0.6928235828876496\n",
      "K-fold 3 : 0.6920726160208385\n",
      "K-fold 4 : 0.6928921004136404\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6925324769814809\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-1_alpha_0-001_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.651041666666664\n",
      "K-fold 1 : 50.397135416666664\n",
      "K-fold 2 : 50.188802083333336\n",
      "K-fold 3 : 50.29296875\n",
      "K-fold 4 : 50.611979166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.635416666666664\n",
      "K-fold 1 : 50.15625\n",
      "K-fold 2 : 51.822916666666664\n",
      "K-fold 3 : 51.380208333333336\n",
      "K-fold 4 : 51.276041666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.38671875\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 51.03515625\n",
      "K-fold 3 : 51.536458333333336\n",
      "K-fold 4 : 51.165364583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.276041666666664\n",
      "K-fold 1 : 51.5625\n",
      "K-fold 2 : 51.979166666666664\n",
      "K-fold 3 : 51.744791666666664\n",
      "K-fold 4 : 51.71875\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.65625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.708469113210837\n",
      "K-fold 1 : 0.6963503330945968\n",
      "K-fold 2 : 0.6983107546965281\n",
      "K-fold 3 : 0.700875676671664\n",
      "K-fold 4 : 0.6955140575766563\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6969247599442799\n",
      "K-fold 1 : 0.6933743675549825\n",
      "K-fold 2 : 0.6936109205087025\n",
      "K-fold 3 : 0.6928041458129883\n",
      "K-fold 4 : 0.6928562581539154\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693557246029377\n",
      "K-fold 1 : 0.6944112971425056\n",
      "K-fold 2 : 0.6937953030069669\n",
      "K-fold 3 : 0.6938699245452881\n",
      "K-fold 4 : 0.6940023968617122\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929851214090983\n",
      "K-fold 1 : 0.6930222392082215\n",
      "K-fold 2 : 0.6922091603279114\n",
      "K-fold 3 : 0.6927651723225912\n",
      "K-fold 4 : 0.692792143424352\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692754767338435\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.934895833333336\n",
      "K-fold 1 : 50.46875\n",
      "K-fold 2 : 50.377604166666664\n",
      "K-fold 3 : 49.309895833333336\n",
      "K-fold 4 : 50.970052083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.520833333333336\n",
      "K-fold 1 : 50.260416666666664\n",
      "K-fold 2 : 52.161458333333336\n",
      "K-fold 3 : 52.734375\n",
      "K-fold 4 : 51.119791666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.321614583333336\n",
      "K-fold 1 : 51.30859375\n",
      "K-fold 2 : 50.91796875\n",
      "K-fold 3 : 50.904947916666664\n",
      "K-fold 4 : 51.373697916666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.041666666666664\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 52.604166666666664\n",
      "K-fold 3 : 52.760416666666664\n",
      "K-fold 4 : 51.640625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.859375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939149205883344\n",
      "K-fold 1 : 0.6953165208299955\n",
      "K-fold 2 : 0.6949134732286135\n",
      "K-fold 3 : 0.6948519418636958\n",
      "K-fold 4 : 0.6939822748303414\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6934379557768504\n",
      "K-fold 1 : 0.7015453755855561\n",
      "K-fold 2 : 0.6923990964889526\n",
      "K-fold 3 : 0.6917448202768962\n",
      "K-fold 4 : 0.6935143351554871\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693536580602328\n",
      "K-fold 1 : 0.6935050820310911\n",
      "K-fold 2 : 0.6937481860319773\n",
      "K-fold 3 : 0.6939466739694278\n",
      "K-fold 4 : 0.6932401816050212\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.692922854423523\n",
      "K-fold 1 : 0.6930196662743886\n",
      "K-fold 2 : 0.6920458296934764\n",
      "K-fold 3 : 0.6915075798829396\n",
      "K-fold 4 : 0.6925521274407704\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6924096115430196\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.305989583333336\n",
      "K-fold 1 : 50.442708333333336\n",
      "K-fold 2 : 50.68359375\n",
      "K-fold 3 : 49.78515625\n",
      "K-fold 4 : 50.436197916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.572916666666664\n",
      "K-fold 1 : 51.276041666666664\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.458333333333336\n",
      "K-fold 4 : 49.427083333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.256510416666664\n",
      "K-fold 1 : 50.78125\n",
      "K-fold 2 : 51.243489583333336\n",
      "K-fold 3 : 51.009114583333336\n",
      "K-fold 4 : 51.321614583333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.572916666666664\n",
      "K-fold 1 : 51.40625\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.510416666666664\n",
      "K-fold 4 : 50.572916666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.010416666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6936071783304214\n",
      "K-fold 1 : 0.6938160479068756\n",
      "K-fold 2 : 0.6933282633622487\n",
      "K-fold 3 : 0.6943055947621664\n",
      "K-fold 4 : 0.6935101752479871\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.695450093348821\n",
      "K-fold 1 : 0.6928231696287791\n",
      "K-fold 2 : 0.6952677349249522\n",
      "K-fold 3 : 0.6928208708763123\n",
      "K-fold 4 : 0.6938315033912659\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930756067236264\n",
      "K-fold 1 : 0.6932750925421715\n",
      "K-fold 2 : 0.6932557692130407\n",
      "K-fold 3 : 0.6932176182667414\n",
      "K-fold 4 : 0.6932040741046269\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930778980255127\n",
      "K-fold 1 : 0.6928219377994538\n",
      "K-fold 2 : 0.6929513057072957\n",
      "K-fold 3 : 0.6927217324574788\n",
      "K-fold 4 : 0.6930836796760559\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929313107331594\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.29296875\n",
      "K-fold 1 : 50.240885416666664\n",
      "K-fold 2 : 49.772135416666664\n",
      "K-fold 3 : 50.1953125\n",
      "K-fold 4 : 50.169270833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.53125\n",
      "K-fold 1 : 49.453125\n",
      "K-fold 2 : 51.380208333333336\n",
      "K-fold 3 : 49.0625\n",
      "K-fold 4 : 50.598958333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.15234375\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 51.061197916666664\n",
      "K-fold 3 : 50.989583333333336\n",
      "K-fold 4 : 51.19140625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.067708333333336\n",
      "K-fold 1 : 52.317708333333336\n",
      "K-fold 2 : 51.692708333333336\n",
      "K-fold 3 : 51.875\n",
      "K-fold 4 : 52.578125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.90625\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6962224423885346\n",
      "K-fold 1 : 0.6966804673274358\n",
      "K-fold 2 : 0.6993044873078664\n",
      "K-fold 3 : 0.7174815252423287\n",
      "K-fold 4 : 0.706913065413634\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693696133295695\n",
      "K-fold 1 : 0.6931762595971426\n",
      "K-fold 2 : 0.6937485198179881\n",
      "K-fold 3 : 0.713801646232605\n",
      "K-fold 4 : 0.7025337060292561\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693716099858284\n",
      "K-fold 1 : 0.6938943058252335\n",
      "K-fold 2 : 0.6936798999706905\n",
      "K-fold 3 : 0.6937328586975734\n",
      "K-fold 4 : 0.6934869483113288\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929397682348887\n",
      "K-fold 1 : 0.692516682545344\n",
      "K-fold 2 : 0.6925679047902426\n",
      "K-fold 3 : 0.6927524705727895\n",
      "K-fold 4 : 0.6921419858932495\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6925837624073029\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.3515625\n",
      "K-fold 1 : 50.729166666666664\n",
      "K-fold 2 : 50.651041666666664\n",
      "K-fold 3 : 49.869791666666664\n",
      "K-fold 4 : 50.416666666666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 50.546875\n",
      "K-fold 2 : 48.463541666666664\n",
      "K-fold 3 : 50.703125\n",
      "K-fold 4 : 51.536458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.471354166666664\n",
      "K-fold 1 : 51.25\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 51.145833333333336\n",
      "K-fold 4 : 51.119791666666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.546875\n",
      "K-fold 1 : 50.546875\n",
      "K-fold 2 : 51.536458333333336\n",
      "K-fold 3 : 51.041666666666664\n",
      "K-fold 4 : 51.536458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.04166666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6936504632234574\n",
      "K-fold 1 : 0.6934109459320704\n",
      "K-fold 2 : 0.6934523815910022\n",
      "K-fold 3 : 0.6940372849504153\n",
      "K-fold 4 : 0.6935931613047918\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6982862969239553\n",
      "K-fold 1 : 0.6930874109268188\n",
      "K-fold 2 : 0.6959708909193675\n",
      "K-fold 3 : 0.6942713797092438\n",
      "K-fold 4 : 0.692679355541865\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930445159475008\n",
      "K-fold 1 : 0.6930794691046079\n",
      "K-fold 2 : 0.6931811918814977\n",
      "K-fold 3 : 0.6930369228124619\n",
      "K-fold 4 : 0.6931661774714788\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930908997853596\n",
      "K-fold 1 : 0.6930874109268188\n",
      "K-fold 2 : 0.6925357898076375\n",
      "K-fold 3 : 0.6930485566457113\n",
      "K-fold 4 : 0.6925826748212178\n",
      "---------------------------------\n",
      "Average best validation loss: 0.692869066397349\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.739583333333336\n",
      "K-fold 1 : 49.82421875\n",
      "K-fold 2 : 50.944010416666664\n",
      "K-fold 3 : 50.748697916666664\n",
      "K-fold 4 : 50.1953125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.104166666666664\n",
      "K-fold 1 : 50.859375\n",
      "K-fold 2 : 49.036458333333336\n",
      "K-fold 3 : 51.145833333333336\n",
      "K-fold 4 : 48.75\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.139322916666664\n",
      "K-fold 1 : 51.0546875\n",
      "K-fold 2 : 51.38671875\n",
      "K-fold 3 : 51.25\n",
      "K-fold 4 : 51.178385416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.067708333333336\n",
      "K-fold 1 : 53.567708333333336\n",
      "K-fold 2 : 52.630208333333336\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 51.510416666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 52.026041666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6981278051932652\n",
      "K-fold 1 : 0.6951377153396606\n",
      "K-fold 2 : 0.7011843348542849\n",
      "K-fold 3 : 0.6959606597820918\n",
      "K-fold 4 : 0.6959340711434682\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929878572622935\n",
      "K-fold 1 : 0.6927749454975128\n",
      "K-fold 2 : 0.7219415823618571\n",
      "K-fold 3 : 0.6934478044509887\n",
      "K-fold 4 : 0.694967919588089\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6932922472556432\n",
      "K-fold 1 : 0.693552594880263\n",
      "K-fold 2 : 0.6939801628390948\n",
      "K-fold 3 : 0.6933735877275466\n",
      "K-fold 4 : 0.693328990538915\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929878572622935\n",
      "K-fold 1 : 0.6913207391897838\n",
      "K-fold 2 : 0.6924664735794067\n",
      "K-fold 3 : 0.6927056928475698\n",
      "K-fold 4 : 0.6929542402426402\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6924870006243389\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.72265625\n",
      "K-fold 1 : 49.869791666666664\n",
      "K-fold 2 : 50.95703125\n",
      "K-fold 3 : 50.091145833333336\n",
      "K-fold 4 : 49.53125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.260416666666664\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.197916666666664\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 47.838541666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.061197916666664\n",
      "K-fold 1 : 51.061197916666664\n",
      "K-fold 2 : 51.139322916666664\n",
      "K-fold 3 : 51.197916666666664\n",
      "K-fold 4 : 50.9375\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.260416666666664\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.432291666666664\n",
      "K-fold 3 : 50.130208333333336\n",
      "K-fold 4 : 52.161458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.020833333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932772010564804\n",
      "K-fold 1 : 0.6940516461928685\n",
      "K-fold 2 : 0.6933764263987541\n",
      "K-fold 3 : 0.6939821774760883\n",
      "K-fold 4 : 1.2500158260265986\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6942438026269276\n",
      "K-fold 1 : 0.6928964555263519\n",
      "K-fold 2 : 0.6928611675898234\n",
      "K-fold 3 : 0.6940425376097361\n",
      "K-fold 4 : 0.9195546249548594\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930016189813614\n",
      "K-fold 1 : 0.6932670762141545\n",
      "K-fold 2 : 0.6930217067400615\n",
      "K-fold 3 : 0.6930786957343419\n",
      "K-fold 4 : 0.6932252516349157\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931080957253773\n",
      "K-fold 1 : 0.6928667724132538\n",
      "K-fold 2 : 0.6928487261136372\n",
      "K-fold 3 : 0.6931438048680624\n",
      "K-fold 4 : 0.6922126789887746\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928360156218212\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.091145833333336\n",
      "K-fold 1 : 50.221354166666664\n",
      "K-fold 2 : 50.110677083333336\n",
      "K-fold 3 : 50.208333333333336\n",
      "K-fold 4 : 50.442708333333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.661458333333336\n",
      "K-fold 1 : 49.375\n",
      "K-fold 2 : 47.96875\n",
      "K-fold 3 : 50.078125\n",
      "K-fold 4 : 49.479166666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.9765625\n",
      "K-fold 1 : 51.38671875\n",
      "K-fold 2 : 50.989583333333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 51.1328125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.979166666666664\n",
      "K-fold 1 : 51.770833333333336\n",
      "K-fold 2 : 52.65625\n",
      "K-fold 3 : 51.927083333333336\n",
      "K-fold 4 : 50.989583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.864583333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6989974950750669\n",
      "K-fold 1 : 0.6994181608160337\n",
      "K-fold 2 : 0.6976035013794899\n",
      "K-fold 3 : 0.6987534110744794\n",
      "K-fold 4 : 0.6947978898882866\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6954733073711395\n",
      "K-fold 1 : 0.6937716325124105\n",
      "K-fold 2 : 0.7057634115219116\n",
      "K-fold 3 : 0.6932767192522685\n",
      "K-fold 4 : 0.6937118589878082\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6943621436754862\n",
      "K-fold 1 : 0.6946253692110379\n",
      "K-fold 2 : 0.6940291513999303\n",
      "K-fold 3 : 0.6938884009917577\n",
      "K-fold 4 : 0.6938217009107271\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6924867610136668\n",
      "K-fold 1 : 0.6929531256357829\n",
      "K-fold 2 : 0.6923332810401917\n",
      "K-fold 3 : 0.692830350001653\n",
      "K-fold 4 : 0.6930837015310923\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6927374438444774\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-1_alpha_0-01_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.052083333333336\n",
      "K-fold 1 : 50.696614583333336\n",
      "K-fold 2 : 50.065104166666664\n",
      "K-fold 3 : 50.989583333333336\n",
      "K-fold 4 : 49.811197916666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.807291666666664\n",
      "K-fold 1 : 51.71875\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.416666666666664\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.477864583333336\n",
      "K-fold 1 : 51.061197916666664\n",
      "K-fold 2 : 51.067708333333336\n",
      "K-fold 3 : 51.15234375\n",
      "K-fold 4 : 51.0546875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.71875\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.416666666666664\n",
      "K-fold 4 : 51.015625\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.98958333333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6941941757996877\n",
      "K-fold 1 : 15.082827288409074\n",
      "K-fold 2 : 0.6935917596022289\n",
      "K-fold 3 : 0.6933372711141904\n",
      "K-fold 4 : 0.7334863935907682\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6936155299345652\n",
      "K-fold 1 : 48.28125\n",
      "K-fold 2 : 0.6930059671401978\n",
      "K-fold 3 : 0.6931266824404398\n",
      "K-fold 4 : 0.6981047332286835\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.693158303697904\n",
      "K-fold 1 : 0.6931606565912565\n",
      "K-fold 2 : 0.6931195964415868\n",
      "K-fold 3 : 0.6931381210684776\n",
      "K-fold 4 : 0.6931203956405322\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6930168191591899\n",
      "K-fold 1 : 0.692551189661026\n",
      "K-fold 2 : 0.6929814020792643\n",
      "K-fold 3 : 0.6931098441282908\n",
      "K-fold 4 : 0.6925447722276051\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928408054510753\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_24_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.533854166666664\n",
      "K-fold 1 : 50.598958333333336\n",
      "K-fold 2 : 50.703125\n",
      "K-fold 3 : 50.188802083333336\n",
      "K-fold 4 : 50.221354166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.817708333333336\n",
      "K-fold 1 : 51.067708333333336\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 50.416666666666664\n",
      "K-fold 4 : 51.5625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.236979166666664\n",
      "K-fold 1 : 51.09375\n",
      "K-fold 2 : 50.904947916666664\n",
      "K-fold 3 : 51.62109375\n",
      "K-fold 4 : 50.813802083333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.885416666666664\n",
      "K-fold 1 : 51.71875\n",
      "K-fold 2 : 51.770833333333336\n",
      "K-fold 3 : 51.692708333333336\n",
      "K-fold 4 : 52.604166666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.734375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6939556906620662\n",
      "K-fold 1 : 0.6934724484880765\n",
      "K-fold 2 : 0.6932382722695668\n",
      "K-fold 3 : 0.693653495113055\n",
      "K-fold 4 : 0.6934612408280373\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.69316086769104\n",
      "K-fold 1 : 0.693004862467448\n",
      "K-fold 2 : 0.6927351693312327\n",
      "K-fold 3 : 0.6932287653287251\n",
      "K-fold 4 : 0.6930884857972462\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930293237169584\n",
      "K-fold 1 : 0.6931222806374232\n",
      "K-fold 2 : 0.6932129179437955\n",
      "K-fold 3 : 0.692728961010774\n",
      "K-fold 4 : 0.6930724635720253\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.693050330877304\n",
      "K-fold 1 : 0.6928559164206187\n",
      "K-fold 2 : 0.6925258775552113\n",
      "K-fold 3 : 0.6930596748987834\n",
      "K-fold 4 : 0.6926233232021332\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928230245908102\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_24_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.130208333333336\n",
      "K-fold 1 : 50.68359375\n",
      "K-fold 2 : 50.44921875\n",
      "K-fold 3 : 50.078125\n",
      "K-fold 4 : 50.143229166666664\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 50.260416666666664\n",
      "K-fold 2 : 48.229166666666664\n",
      "K-fold 3 : 48.776041666666664\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.25\n",
      "K-fold 1 : 51.42578125\n",
      "K-fold 2 : 50.983072916666664\n",
      "K-fold 3 : 51.106770833333336\n",
      "K-fold 4 : 51.263020833333336\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.328125\n",
      "K-fold 1 : 50.260416666666664\n",
      "K-fold 2 : 51.770833333333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.286458333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.973958333333336\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6935533036788305\n",
      "K-fold 1 : 0.6939548258980115\n",
      "K-fold 2 : 0.6942392980058988\n",
      "K-fold 3 : 0.6935419569412867\n",
      "K-fold 4 : 0.693950263162454\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6927987337112427\n",
      "K-fold 1 : 0.6952674369017283\n",
      "K-fold 2 : 0.6957434177398681\n",
      "K-fold 3 : 0.6935273587703705\n",
      "K-fold 4 : 0.6937278310457865\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929752906163533\n",
      "K-fold 1 : 0.6928770924607913\n",
      "K-fold 2 : 0.6930118054151535\n",
      "K-fold 3 : 0.6930762847264608\n",
      "K-fold 4 : 0.6930504297216733\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927943527698517\n",
      "K-fold 1 : 0.693133662144343\n",
      "K-fold 2 : 0.6925199568271637\n",
      "K-fold 3 : 0.6928475598494211\n",
      "K-fold 4 : 0.6931308031082153\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928852669397989\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_48_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.338541666666664\n",
      "K-fold 1 : 50.56640625\n",
      "K-fold 2 : 50.188802083333336\n",
      "K-fold 3 : 50.384114583333336\n",
      "K-fold 4 : 49.86328125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 48.880208333333336\n",
      "K-fold 1 : 48.645833333333336\n",
      "K-fold 2 : 51.380208333333336\n",
      "K-fold 3 : 50.46875\n",
      "K-fold 4 : 50.625\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.3671875\n",
      "K-fold 1 : 50.859375\n",
      "K-fold 2 : 51.041666666666664\n",
      "K-fold 3 : 51.321614583333336\n",
      "K-fold 4 : 51.080729166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.822916666666664\n",
      "K-fold 1 : 51.536458333333336\n",
      "K-fold 2 : 51.614583333333336\n",
      "K-fold 3 : 50.859375\n",
      "K-fold 4 : 50.78125\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.32291666666667\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.69407875786225\n",
      "K-fold 1 : 0.6935686940948168\n",
      "K-fold 2 : 0.6936523209015528\n",
      "K-fold 3 : 0.6936615521709124\n",
      "K-fold 4 : 0.6937242671847343\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.693270468711853\n",
      "K-fold 1 : 0.6947564979394277\n",
      "K-fold 2 : 0.6927664657433827\n",
      "K-fold 3 : 0.6932487467924754\n",
      "K-fold 4 : 0.6964572509129842\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930520663658778\n",
      "K-fold 1 : 0.6931288386384646\n",
      "K-fold 2 : 0.6932689706484477\n",
      "K-fold 3 : 0.693132650355498\n",
      "K-fold 4 : 0.6929072201251983\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6928115208943685\n",
      "K-fold 1 : 0.6927125155925751\n",
      "K-fold 2 : 0.6926666676998139\n",
      "K-fold 3 : 0.6931020776430766\n",
      "K-fold 4 : 0.6929812292257945\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928548022111256\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_48_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.813802083333336\n",
      "K-fold 1 : 49.778645833333336\n",
      "K-fold 2 : 50.208333333333336\n",
      "K-fold 3 : 49.518229166666664\n",
      "K-fold 4 : 50.345052083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 49.583333333333336\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.223958333333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.555989583333336\n",
      "K-fold 1 : 51.1328125\n",
      "K-fold 2 : 50.924479166666664\n",
      "K-fold 3 : 50.989583333333336\n",
      "K-fold 4 : 51.412760416666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.416666666666664\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.223958333333336\n",
      "K-fold 3 : 51.223958333333336\n",
      "K-fold 4 : 50.885416666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693571508427461\n",
      "K-fold 1 : 0.6936063259840012\n",
      "K-fold 2 : 0.6936635906497638\n",
      "K-fold 3 : 0.6934898902972539\n",
      "K-fold 4 : 0.6936746234695117\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6931784907976787\n",
      "K-fold 1 : 0.6933770080407461\n",
      "K-fold 2 : 0.6928475975990296\n",
      "K-fold 3 : 0.6928897122542064\n",
      "K-fold 4 : 0.6940316339333852\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930698280533155\n",
      "K-fold 1 : 0.693003053466479\n",
      "K-fold 2 : 0.693133311967055\n",
      "K-fold 3 : 0.6929909075299899\n",
      "K-fold 4 : 0.6929133365551631\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931126316388448\n",
      "K-fold 1 : 0.6928970217704773\n",
      "K-fold 2 : 0.6928475300470988\n",
      "K-fold 3 : 0.6928475419680278\n",
      "K-fold 4 : 0.6929904282093048\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6929390307267507\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_96_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.143229166666664\n",
      "K-fold 1 : 50.065104166666664\n",
      "K-fold 2 : 49.837239583333336\n",
      "K-fold 3 : 49.778645833333336\n",
      "K-fold 4 : 50.501302083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 47.734375\n",
      "K-fold 1 : 49.817708333333336\n",
      "K-fold 2 : 51.953125\n",
      "K-fold 3 : 50.625\n",
      "K-fold 4 : 49.84375\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 50.859375\n",
      "K-fold 1 : 51.497395833333336\n",
      "K-fold 2 : 50.983072916666664\n",
      "K-fold 3 : 51.380208333333336\n",
      "K-fold 4 : 51.23046875\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 52.317708333333336\n",
      "K-fold 1 : 51.302083333333336\n",
      "K-fold 2 : 51.979166666666664\n",
      "K-fold 3 : 51.770833333333336\n",
      "K-fold 4 : 51.848958333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.84375\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6933094933629036\n",
      "K-fold 1 : 0.6935999249418576\n",
      "K-fold 2 : 0.6938963413238526\n",
      "K-fold 3 : 0.6938268591960272\n",
      "K-fold 4 : 0.693413200477759\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.7002163310845693\n",
      "K-fold 1 : 0.6932892799377441\n",
      "K-fold 2 : 0.6923880656560262\n",
      "K-fold 3 : 0.6957636674245199\n",
      "K-fold 4 : 0.6968795994917552\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6931305542588234\n",
      "K-fold 1 : 0.6929945727189382\n",
      "K-fold 2 : 0.6931490048766136\n",
      "K-fold 3 : 0.6930775294701258\n",
      "K-fold 4 : 0.693063473701477\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6920491456985474\n",
      "K-fold 1 : 0.693116561571757\n",
      "K-fold 2 : 0.6921633064746857\n",
      "K-fold 3 : 0.6930101176102956\n",
      "K-fold 4 : 0.6930252174536388\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926728697617849\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_96_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 50.904947916666664\n",
      "K-fold 1 : 49.733072916666664\n",
      "K-fold 2 : 49.817708333333336\n",
      "K-fold 3 : 50.572916666666664\n",
      "K-fold 4 : 50.169270833333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.3125\n",
      "K-fold 1 : 48.854166666666664\n",
      "K-fold 2 : 51.796875\n",
      "K-fold 3 : 49.973958333333336\n",
      "K-fold 4 : 51.588541666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.321614583333336\n",
      "K-fold 1 : 51.69921875\n",
      "K-fold 2 : 51.119791666666664\n",
      "K-fold 3 : 51.354166666666664\n",
      "K-fold 4 : 51.080729166666664\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.3125\n",
      "K-fold 1 : 51.145833333333336\n",
      "K-fold 2 : 51.796875\n",
      "K-fold 3 : 50.026041666666664\n",
      "K-fold 4 : 51.588541666666664\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6932669897874196\n",
      "K-fold 1 : 0.6938650886217753\n",
      "K-fold 2 : 0.6936465308070183\n",
      "K-fold 3 : 0.6935284594694774\n",
      "K-fold 4 : 0.6943693846464157\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6941090385119121\n",
      "K-fold 1 : 0.693331907192866\n",
      "K-fold 2 : 0.6925047556559245\n",
      "K-fold 3 : 0.6937441051006317\n",
      "K-fold 4 : 0.6927014231681824\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930626317858696\n",
      "K-fold 1 : 0.692815541724364\n",
      "K-fold 2 : 0.6931139310201009\n",
      "K-fold 3 : 0.6930545677741369\n",
      "K-fold 4 : 0.6928948546449344\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6931276679039001\n",
      "K-fold 1 : 0.6928846140702566\n",
      "K-fold 2 : 0.6925013542175293\n",
      "K-fold 3 : 0.6931470414002736\n",
      "K-fold 4 : 0.6926425258318584\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6928606406847636\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_1_hidden_size_192_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.94140625\n",
      "K-fold 1 : 50.716145833333336\n",
      "K-fold 2 : 50.911458333333336\n",
      "K-fold 3 : 50.377604166666664\n",
      "K-fold 4 : 51.11328125\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.963541666666664\n",
      "K-fold 1 : 51.796875\n",
      "K-fold 2 : 49.739583333333336\n",
      "K-fold 3 : 51.796875\n",
      "K-fold 4 : 50.572916666666664\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.106770833333336\n",
      "K-fold 1 : 51.119791666666664\n",
      "K-fold 2 : 51.640625\n",
      "K-fold 3 : 50.911458333333336\n",
      "K-fold 4 : 51.11328125\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 51.015625\n",
      "K-fold 1 : 52.03125\n",
      "K-fold 2 : 51.614583333333336\n",
      "K-fold 3 : 52.135416666666664\n",
      "K-fold 4 : 50.989583333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 51.557291666666664\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.693485650420189\n",
      "K-fold 1 : 0.6931866784890492\n",
      "K-fold 2 : 0.6933307806650798\n",
      "K-fold 3 : 0.6946018233895301\n",
      "K-fold 4 : 0.6933996975421906\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6932400504748026\n",
      "K-fold 1 : 0.6929666380087535\n",
      "K-fold 2 : 0.6938761572043101\n",
      "K-fold 3 : 0.6955822666486104\n",
      "K-fold 4 : 0.6930863976478576\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6929474671681722\n",
      "K-fold 1 : 0.6930107221007347\n",
      "K-fold 2 : 0.6929246604442596\n",
      "K-fold 3 : 0.6931812743345896\n",
      "K-fold 4 : 0.6930066054066022\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6927877068519592\n",
      "K-fold 1 : 0.6924917340278626\n",
      "K-fold 2 : 0.6926612039407094\n",
      "K-fold 3 : 0.692478750149409\n",
      "K-fold 4 : 0.6930684626102448\n",
      "---------------------------------\n",
      "Average best validation loss: 0.6926975715160368\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "n_12_num_hidden_2_hidden_size_192_lr_0-1_alpha_0-1_batch_size_128_num_epochs_100\n",
      "---------------------------------\n",
      "Training accuracy (last epoch)\n",
      "K-fold 0 : 49.615885416666664\n",
      "K-fold 1 : 49.895833333333336\n",
      "K-fold 2 : 50.416666666666664\n",
      "K-fold 3 : 49.739583333333336\n",
      "K-fold 4 : 49.485677083333336\n",
      "---------------------------------\n",
      "Validation accuracy (last epoch)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 49.192708333333336\n",
      "K-fold 2 : 51.953125\n",
      "K-fold 3 : 50.338541666666664\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Training accuracy (best)\n",
      "K-fold 0 : 51.165364583333336\n",
      "K-fold 1 : 51.575520833333336\n",
      "K-fold 2 : 51.341145833333336\n",
      "K-fold 3 : 51.145833333333336\n",
      "K-fold 4 : 51.34765625\n",
      "---------------------------------\n",
      "Validation accuracy (best)\n",
      "K-fold 0 : 50.9375\n",
      "K-fold 1 : 50.807291666666664\n",
      "K-fold 2 : 51.953125\n",
      "K-fold 3 : 50.338541666666664\n",
      "K-fold 4 : 50.833333333333336\n",
      "---------------------------------\n",
      "Average best validation accuracy: 50.97395833333333\n",
      "---------------------------------\n",
      "Training loss (last epoch)\n",
      "K-fold 0 : 0.6938690423965455\n",
      "K-fold 1 : 0.6937663793563843\n",
      "K-fold 2 : 0.6939130877455075\n",
      "K-fold 3 : 0.693975235025088\n",
      "K-fold 4 : 0.6935648883382479\n",
      "---------------------------------\n",
      "Validation loss (last epoch)\n",
      "K-fold 0 : 0.6929719805717468\n",
      "K-fold 1 : 0.6943708101908366\n",
      "K-fold 2 : 0.6925846060117086\n",
      "K-fold 3 : 0.6931305507818858\n",
      "K-fold 4 : 0.6933748185634613\n",
      "---------------------------------\n",
      "Training loss best\n",
      "K-fold 0 : 0.6930008788903554\n",
      "K-fold 1 : 0.6929547255237897\n",
      "K-fold 2 : 0.6930504336953163\n",
      "K-fold 3 : 0.6929984430472056\n",
      "K-fold 4 : 0.6930379847685496\n",
      "---------------------------------\n",
      "Validation loss (best)\n",
      "K-fold 0 : 0.6929719805717468\n",
      "K-fold 1 : 0.6930169641971589\n",
      "K-fold 2 : 0.6923842847347259\n",
      "K-fold 3 : 0.6931242744127909\n",
      "K-fold 4 : 0.6930084566275279\n",
      "---------------------------------\n",
      "Average best validation loss: 0.69290119210879\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# File path to store results\n",
    "csv_file_path = f\"hyperparameter_tuning_results-{n}.csv\"\n",
    "\n",
    "# Function to check if the hyperparameter combination already exists in CSV\n",
    "def is_hyperparameter_row_present(hyperparameters, existing_rows):\n",
    "    hyperparameter_tuple = tuple(sorted({\n",
    "        key: str(val) for key, val in  hyperparameters.items()\n",
    "    }.items()))\n",
    "    return hyperparameter_tuple in existing_rows\n",
    "\n",
    "# Initialize an empty set to store processed hyperparameter combinations\n",
    "existing_rows = set()\n",
    "\n",
    "# Check if the CSV file already exists and load existing rows\n",
    "if os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # Read the headers and rows from the existing file\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            # Convert each row back into a dictionary of hyperparameters\n",
    "            row_dict = dict(zip(headers, row))\n",
    "            row_dict.pop(\"val_acc\")\n",
    "            row_dict.pop(\"val_loss\")\n",
    "            # Create a hashable tuple for checking if the row already exists\n",
    "            existing_rows.add(tuple(sorted(row_dict.items())))\n",
    "\n",
    "# Iterate through hyperparameter combinations\n",
    "for lr in lr_values:\n",
    "    for alpha in alpha_values:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            for num_hidden in num_hidden_layers:\n",
    "                hyperparameters = {\n",
    "                    \"num_hidden\": num_hidden,\n",
    "                    \"hidden_size\": hidden_layer_size,\n",
    "                    \"lr\": lr, \n",
    "                    \"alpha\": alpha, \n",
    "                    \"batch_size\": 128, \n",
    "                    \"num_epochs\": 100\n",
    "                }\n",
    "\n",
    "                # Check if this combination has already been processed\n",
    "                if is_hyperparameter_row_present(hyperparameters, existing_rows):\n",
    "                    print(f\"Skipping already processed hyperparameter combination: {hyperparameters}\")\n",
    "                    continue  # Skip to the next combination\n",
    "\n",
    "                # Compute the result (training the model)\n",
    "                val_acc, val_loss = model_training(hyperparameters)\n",
    "\n",
    "                # Prepare the result row\n",
    "                result_row = {**hyperparameters, \"val_acc\": val_acc, \"val_loss\": val_loss}\n",
    "\n",
    "                # Append the result to the CSV file\n",
    "                with open(csv_file_path, mode='a', newline='') as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=result_row.keys())\n",
    "                    \n",
    "                    # Write header only if the file is empty (first write)\n",
    "                    if f.tell() == 0:\n",
    "                        writer.writeheader()\n",
    "                    \n",
    "                    writer.writerow(result_row)\n",
    "\n",
    "                # Add this combination to the existing_rows set to avoid recalculation in future runs\n",
    "                existing_rows.add(tuple(sorted(hyperparameters.items())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
